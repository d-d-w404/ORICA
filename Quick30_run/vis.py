# vis_stream_orica.py
# Re-implementation of vis_stream_ORICA in Python using pylsl and matplotlib

import numpy as np
import matplotlib.pyplot as plt
from pylsl import StreamInlet, resolve_byprop
from matplotlib.animation import FuncAnimation
import time
from scipy.signal import butter, lfilter
from scipy.signal import butter, filtfilt
from PyQt5.QtWidgets import (QApplication, QWidget, QVBoxLayout, QPushButton,
                             QComboBox, QLabel, QLineEdit, QHBoxLayout)
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas

from PyQt5.QtWidgets import QGroupBox
import sys
import numpy as np
import mne
from pyprep.prep_pipeline import PrepPipeline
from PyQt5.QtWidgets import QCheckBox
from asrpy import ASR
import numpy as np
import mne

from scipy.signal import welch
import threading

from scipy.special import expit
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
import joblib


from sklearn.decomposition import FastICA


#this is the main project currently


class LSLStreamReceiver:
    def __init__(self, stream_type='EEG', time_range=5):
        self.stream_type = stream_type
        self.time_range = time_range
        self.inlet = None
        self.srate = None
        self.nbchan = None
        self.buffer = None
        self.chan_labels = []
        self.channel_range = []

        self.channel_manager=None
        self.cutoff = (0.5, 45)

        # ASR
        self.use_asr = False
        self.asr_calibrated = False
        self.asr_calibration_buffer = None
        self.prep_reference = None


        self.raw_buffer = None  # å­˜æ”¾æœª ASR çš„ bandpass-only å†å²æ•°æ®

        self.analysis_callbacks = []  # å­˜æ”¾æ‰€æœ‰å›è°ƒåˆ†æå‡½æ•°

        # åœ¨çº¿å›å½’æ¨¡å‹ï¼ˆæƒ…ç»ªå¼ºåº¦ï¼‰
        # self.online_model = SGDRegressor(learning_rate='adaptive', eta0=0.01)
        # self.scaler = StandardScaler()
        # self.first_fit_done = False
        # self.first_fit_lock = threading.Lock()  # ğŸ”’ åŠ é”


        #ORICA
        self.orica = None

    def register_analysis_callback(self, callback_fn):
        """æ³¨å†Œä¸€ä¸ªå‡½æ•°ç”¨äºå¤„ç†æ¯æ¬¡æ›´æ–°åçš„æ•°æ®æ®µ chunk"""
        self.analysis_callbacks.append(callback_fn)

    def find_and_open_stream(self):
        print(f"Searching for LSL stream with type = '{self.stream_type}'...")
        streams = resolve_byprop('type', self.stream_type, timeout=5)

        if not streams:
            raise RuntimeError(f"No LSL stream with type '{self.stream_type}' found.")

        self.inlet = StreamInlet(streams[0])
        info = self.inlet.info()

        print("=== StreamInfo XML description ===")
        print(self.inlet.info().as_xml())

        info = self.inlet.info()
        self.channel_manager = ChannelManager(info)

        self.srate = int(info.nominal_srate())
        self.nbchan = info.channel_count()

        # chs = info.desc().child('channels').child('channel')
        # all_labels = []
        # for _ in range(self.nbchan):
        #     label = chs.child_value('label')
        #     all_labels.append(label if label else f"Ch {_+1}")
        #     chs = chs.next_sibling()
        #
        # # self.chan_labels = all_labels.copy()
        # # self.enabled = [True] * len(self.chan_labels)  # â† æ·»åŠ è¿™è¡Œï¼Œæ ‡è®°æ¯ä¸ªé€šé“æ˜¯å¦å¯ç”¨
        #
        # exclude_keywords = ['TRIGGER', 'ACC', 'ExG', 'Packet', 'A2','O2','Oz']
        # for i, label in enumerate(all_labels):
        #     if not any(keyword in label for keyword in exclude_keywords):
        #         self.chan_labels.append(label)
        #         self.channel_range.append(i)


        # æˆ–è€…è‡ªå®šä¹‰æ’é™¤æŸäº›å…³é”®è¯
        exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','A2']
        self.chan_labels = self.channel_manager.get_labels_excluding_keywords(exclude)
        self.channel_range = self.channel_manager.get_indices_excluding_keywords(exclude)

        # print(self.chan_labels)
        # print(self.channel_range)
        #è¿™é‡Œçš„self.channel_range å¯¹åº”äº†æ¯ä¸€ä¸ªself.chan_labelsæ ‡ç­¾çš„åºå·
        #å‡å¦‚æˆ‘åœ¨ä¸Šé¢çš„excludeä¸­å»æ‰äº†O2,é‚£ä¹ˆO2è¿™ä¸ªlabelä»¥åŠä»–çš„åºå·éƒ½ä¼šè¢«åˆ é™¤ã€‚

        self.nbchan = len(self.channel_range)
        self.buffer = np.zeros((info.channel_count(), self.srate * self.time_range))

        #for the comparing stream
        self.raw_buffer = np.zeros((info.channel_count(), self.srate * self.time_range))

        print(f"Stream opened: {info.channel_count()} channels at {self.srate} Hz")
        print(f"Using {self.nbchan} EEG channels: {self.chan_labels}")



        # âœ… åˆå§‹åŒ– ORICA
        self.orica = ORICAProcessor(
            n_components=len(self.channel_range),
            max_samples=self.srate * 3
        )
        print("âœ… ORICA processor initialized.")

    def pull_and_update_buffer(self):
        samples, timestamps = self.inlet.pull_chunk(timeout=0.0)
        if timestamps:
            chunk = np.array(samples).T  # shape: (channels, samples)


            # #step 0: replace woring channels with means
            # print("before")
            # print(np.array(chunk).shape)
            # chunk = clean_bad_channels(chunk, labels=self.chan_labels)
            # print("after")
            # print(np.array(chunk).shape)

            # Step 1: Bandpass or highpass filter
            chunk = eeg_filter(chunk, self.srate, cutoff=self.cutoff)


            # âœ… æ›´æ–°åŸå§‹æ»¤æ³¢åçš„ bufferï¼ˆraw_bufferï¼‰
            self.last_unclean_chunk = chunk.copy()
            if self.raw_buffer is not None:
                self.raw_buffer = np.roll(self.raw_buffer, -chunk.shape[1], axis=1)
                self.raw_buffer[:, -chunk.shape[1]:] = self.last_unclean_chunk



            # Step X: ORICA å»çœ¼åŠ¨ä¼ªå½±
            #print(np.array(chunk[self.channel_range, :]).shape)#(29, 64)
            #print(np.array(chunk).shape)#(37, 64)
            # if self.orica.update_buffer(chunk[self.channel_range, :]):#è¾“å‡ºtrueçš„åŒæ—¶ï¼Œæ›´æ–°äº†çª—å£
            #     if self.orica.fit(self.orica.data_buffer):
            #         chunk[self.channel_range, :] = self.orica.transform(chunk[self.channel_range, :])





            # Step 2
            if self.use_asr:
                chunk = self.apply_pyprep_asr(chunk)

            # Step 3: Update ring buffer
            num_new = chunk.shape[1]
            self.buffer = np.roll(self.buffer, -num_new, axis=1)
            self.buffer[:, -num_new:] = chunk

            # âœ… Step 4: å›è°ƒåˆ†æå‡½æ•°ï¼Œè¾“å…¥æ˜¯å½“å‰æœ€æ–°çš„ chunk æ•°æ®
            #å½“æ‰§è¡Œåˆ°è¿™é‡Œçš„æ—¶å€™å°±ä¼šè§¦å‘å›è°ƒå‡½æ•°ï¼Œè¿è¡Œtryä¸‹é¢çš„å†…å®¹
            # for fn in self.analysis_callbacks:
            #     try:
            #         fn(chunk=self.buffer[self.channel_range, :],  # æ¸…æ´—åçš„
            #            raw=self.raw_buffer[self.channel_range, :],  # ä»… bandpass
            #            srate=self.srate,
            #            labels=self.chan_labels)
            #     except Exception as e:
            #         print(f"âŒ å›è°ƒåˆ†æå‡½æ•°é”™è¯¯: {e}")



            # åœ¨ä½ çš„ update_plot æˆ– pull_and_update_buffer ä¹‹åï¼š
            for fn in self.analysis_callbacks:
                try:
                    thread = threading.Thread(
                        target=fn,
                        kwargs=dict(
                            chunk=self.buffer[self.channel_range, :],
                            raw=self.raw_buffer[self.channel_range, :],
                            srate=self.srate,
                            labels=self.chan_labels
                        )
                    )
                    thread.start()
                except Exception as e:
                    print(f"âŒ å›è°ƒåˆ†æå‡½æ•°é”™è¯¯: {e}")

    def print_latest_channel_values(self):
        pass
        # print("--- EEG Channel Values (last column) ---")
        # for i, ch in enumerate(self.channel_range):
        #     label = self.chan_labels[i]
        #     value = self.buffer[ch, -1]
        #     rms = np.sqrt(np.mean(self.buffer[ch]**2))
        #     print(f"{label}: {value:.2f} (RMS: {rms:.2f})")

    def apply_pyprep_asr(self, chunk):
        try:
            if not self.asr_calibrated:
                # ğŸ”„ Step 1: æ”¶é›†é™æ¯æ•°æ®è¿›è¡Œæ ¡å‡†
                if self.asr_calibration_buffer is None:
                    self.asr_calibration_buffer = chunk.copy()
                else:
                    self.asr_calibration_buffer = np.concatenate(
                        (self.asr_calibration_buffer, chunk), axis=1
                    )

                if self.asr_calibration_buffer.shape[1] >= self.srate * 20:
                    print("â³ Calibrating ASR...")

                    # â• åˆ›å»º Raw å¯¹è±¡ç”¨äºæ ¡å‡†
                    info = mne.create_info(
                        ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                        sfreq=self.srate,
                        ch_types=["eeg"] * len(self.channel_range)
                    )
                    x=self.channel_manager.get_labels_by_indices(self.channel_range)
                    # print("X" * 30)
                    # print(x)
                    # print("X" * 30)

                    raw = mne.io.RawArray(
                        self.asr_calibration_buffer[self.channel_range, :], info
                    )

                    #
                    # print(self.asr_calibration_buffer[self.channel_range, :])
                    # print("Selected shape:", self.buffer[self.channel_range, :].shape)
                    # print("Selected labels:", self.chan_labels)

                    raw.set_montage("standard_1020")

                    # ğŸ”§ åˆå§‹åŒ–å¹¶æ ¡å‡† ASR å®ä¾‹
                    self.asr_instance = ASR(
                        sfreq=self.srate,

                        cutoff=3,
                        win_len=0.5,
                        win_overlap=0.66,
                        blocksize=self.srate
                    )

                    self.asr_instance.fit(raw)

                    self.asr_calibrated = True
                    self.asr_calibration_buffer = None
                    print("âœ… ASRpy calibrated successfully.")

            else:
                # ğŸ”„ Step 2: å®æ—¶æ¸…æ´—æ•°æ®
                info = mne.create_info(
                    ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                    sfreq=self.srate,
                    ch_types=["eeg"] * len(self.channel_range)
                )
                raw_chunk = mne.io.RawArray(chunk[self.channel_range, :], info)
                raw_chunk.set_montage("standard_1020")

                cleaned_raw = self.asr_instance.transform(raw_chunk)
                chunk[self.channel_range, :] = cleaned_raw.get_data()

        except Exception as e:
            print("âŒ Error in apply_pyprep_asr:", e)

        return chunk

    # def apply_pyprep_asr(self, chunk):
    #     if not self.asr_calibrated:
    #         if self.asr_calibration_buffer is None:
    #             self.asr_calibration_buffer = chunk.copy()
    #         else:
    #             self.asr_calibration_buffer = np.concatenate((self.asr_calibration_buffer, chunk), axis=1)
    #
    #         if self.asr_calibration_buffer.shape[1] >= self.srate * 10:
    #             try:
    #                 info = mne.create_info(
    #                     ch_names=[self.chan_labels[i] for i in range(len(self.channel_range))],
    #                     sfreq=self.srate,
    #                     ch_types=["eeg"] * len(self.channel_range)
    #                 )
    #                 raw = mne.io.RawArray(self.asr_calibration_buffer[self.channel_range, :], info)
    #                 raw.set_montage("standard_1020")
    #
    #                 prep = PrepPipeline(raw, {
    #                     "ref_chs": raw.ch_names,
    #                     "reref_chs": raw.ch_names,
    #                     "line_freqs": [50]
    #                 }, montage="standard_1020")
    #
    #                 prep.fit()
    #                 self.prep_reference = prep
    #                 self.asr_calibrated = True
    #                 print("âœ… pyPREP ASR calibrated.")
    #                 self.asr_calibration_buffer = None
    #             except Exception as e:
    #                 print("âŒ ASR calibration failed:", e)
    #     else:
    #         try:
    #             info = mne.create_info(
    #                 ch_names=[self.chan_labels[i] for i in range(len(self.channel_range))],
    #                 sfreq=self.srate,
    #                 ch_types=["eeg"] * len(self.channel_range)
    #             )
    #             raw_chunk = mne.io.RawArray(chunk[self.channel_range, :], info)
    #             raw_chunk.set_montage("standard_1020")
    #
    #             prep = PrepPipeline(raw_chunk, {
    #                 "ref_chs": raw_chunk.ch_names,
    #                 "reref_chs": raw_chunk.ch_names,
    #                 "line_freqs": [50]
    #             }, montage="standard_1020")
    #
    #             prep.fit()
    #             clean_data = prep.raw.get_data()
    #             chunk[self.channel_range, :] = clean_data
    #         except Exception as e:
    #             print("âŒ pyPREP ASR cleaning failed:", e)
    #
    #     return chunk


from ORICA import ORICA


class ORICAProcessor:
    def __init__(self, n_components=None, max_samples=1000):
        self.n_components = n_components
        self.max_samples = max_samples
        self.ica = None
        self.data_buffer = None
        self.eog_indices = []  # indices of components identified as eye artifacts

    def fit(self, data):
        """Fit ICA on the buffered EEG data"""
        assert data.shape[0] == self.n_components, f"Expected {self.n_components} channels, got {data.shape[0]}"

        if data.shape[1] < self.max_samples:
            return False  # Not enough data yet


        # ica = FastICA(n_components=self.n_components or data.shape[0],#éƒ½æ˜¯29ä¸€æ ·çš„
        #               max_iter=2000, tol=1e-3, random_state=42)
        #
        # sources = ica.fit_transform(data.T)

        print("dog")
        self.ica = ORICA(n_components=min(self.n_components, data.shape[0]), learning_rate=0.001)

        print("dog")
        sources = self.ica.fit_transform(data.T).T  # shape: (components, samples)

        print("dog")

        self.identify_eye_artifacts(sources.T)
        return True

    # def identify_eye_artifacts(self, components):
    #     """Heuristic: identify eye components as those with high frontal power and low frequency"""
    #     self.eog_indices = []
    #     for i, comp in enumerate(components):
    #         power = np.sum(comp ** 2)
    #         if power > np.percentile([np.sum(c ** 2) for c in components], 90):
    #             self.eog_indices.append(i)
    #
    #     print("EOG artifact:",self.eog_indices)

    def identify_eye_artifacts(self, components):
        powers = np.sum(components ** 2, axis=1)  # æ¯ä¸ªåˆ†é‡çš„æ€»èƒ½é‡
        threshold = np.percentile(powers, 90)
        self.eog_indices = [i for i, p in enumerate(powers) if p > threshold]

        print("EOG artifact indices (filtered):", self.eog_indices)

    def transform(self, new_data):
        if self.ica is None:
            return new_data

        sources = self.ica.transform(new_data.T)
        sources[:, self.eog_indices] = 0  # Zero out EOG components
        cleaned = self.ica.inverse_transform(sources)
        return cleaned.T

    def update_buffer(self, new_chunk):
        if self.data_buffer is None:
            self.data_buffer = new_chunk
        else:
            self.data_buffer = np.concatenate([self.data_buffer, new_chunk], axis=1)
            if self.data_buffer.shape[1] > self.max_samples:
                self.data_buffer = self.data_buffer[:, -self.max_samples:]

        print(np.array(self.data_buffer).shape)

        return self.data_buffer.shape[1] >= self.max_samples




class LSLStreamVisualizer:
    def __init__(self, receiver: LSLStreamReceiver,
                 data_scale=150,
                 sampling_rate=100,
                 refresh_rate=10,
                 reref=False):

        self.receiver = receiver
        self.data_scale = data_scale
        self.sampling_rate = sampling_rate
        self.refresh_rate = refresh_rate
        self.reref = reref

        self.fig, self.ax = plt.subplots()
        self.lines = []
        self.last_print_time = time.time()

    # def update_plot(self, frame):
    #     self.receiver.pull_and_update_buffer()
    #
    #     plotdata = self.receiver.buffer[self.receiver.channel_range, ::int(self.receiver.srate/self.sampling_rate)]
    #     plotdata = plotdata - np.mean(plotdata, axis=1, keepdims=True)
    #     plotoffsets = np.arange(len(self.receiver.channel_range))[:, None] * self.data_scale
    #     plotdata += plotoffsets
    #
    #     self.ax.clear()
    #     self.ax.set_title(f"LSL Stream Type: {self.receiver.stream_type}")
    #     self.ax.set_xlabel("Time (samples)")
    #     self.ax.set_ylabel("Channels")
    #     self.ax.set_yticks(plotoffsets[:, 0])
    #     ylabels = [self.receiver.chan_labels[i] for i in range(len(self.receiver.channel_range))]
    #     self.ax.set_yticklabels(ylabels)
    #     self.ax.set_ylim(-self.data_scale, plotoffsets[-1][0] + self.data_scale)
    #     self.ax.plot(plotdata.T, linewidth=0.5)
    #
    #     current_time = time.time()
    #     if current_time - self.last_print_time >= 5.0:
    #         self.receiver.print_latest_channel_values()
    #         self.last_print_time = current_time

    def update_plot(self, frame):
        self.receiver.pull_and_update_buffer()

        # === Step 1: è·å– ASR æ¸…æ´—åçš„æ•°æ®
        clean_data = self.receiver.buffer[self.receiver.channel_range, ::int(self.receiver.srate / self.sampling_rate)]
        clean_data = clean_data - np.mean(clean_data, axis=1, keepdims=True)

        # === Step 2: è·å– bandpass-only æ•°æ®
        raw_data = self.receiver.raw_buffer[self.receiver.channel_range,
                   ::int(self.receiver.srate / self.sampling_rate)]
        raw_data = raw_data - np.mean(raw_data, axis=1, keepdims=True)

        # âœ… Step 2.1: å¯¹é½ä¸¤ä¸ªæ•°æ®é•¿åº¦ï¼ˆé˜²æ­¢çº¢çº¿å¤ªçŸ­ï¼‰
        min_len = min(clean_data.shape[1], raw_data.shape[1])
        clean_data = clean_data[:, -min_len:]
        raw_data = raw_data[:, -min_len:]

        # === Step 3: æ·»åŠ å‚ç›´åç§»é‡
        offsets = np.arange(len(self.receiver.channel_range))[:, None] * self.data_scale
        clean_data += offsets
        raw_data += offsets

        # === Step 4: ç»˜å›¾
        self.ax.clear()
        self.ax.set_title(f"LSL Stream Type: {self.receiver.stream_type}")
        self.ax.set_xlabel("Time (samples)")
        self.ax.set_ylabel("Channels")
        self.ax.set_yticks(offsets[:, 0])
        ylabels = [self.receiver.chan_labels[i] for i in range(len(self.receiver.channel_range))]
        self.ax.set_yticklabels(ylabels)
        self.ax.set_ylim(-self.data_scale, offsets[-1][0] + self.data_scale)

        # è“è‰²çº¿ï¼šASR æ¸…æ´—åçš„ EEG
        self.ax.plot(clean_data.T, color='blue', linewidth=0.6)

        # çº¢è‰²è™šçº¿ï¼šåªç»è¿‡ bandpass çš„ EEG
        self.ax.plot(raw_data.T, color='red', linewidth=0.4, linestyle='--')



        # å¯é€‰ï¼šå®šæœŸæ‰“å°æœ€æ–°å€¼
        current_time = time.time()
        if current_time - self.last_print_time >= 5.0:
            self.receiver.print_latest_channel_values()
            self.last_print_time = current_time

    def start(self):
        self.receiver.find_and_open_stream()
        self.ani = FuncAnimation(self.fig, self.update_plot, interval=1000/self.refresh_rate)




def clean_bad_channels(chunk, labels=None, threshold_uv=200):
    """æ£€æµ‹å¹¶æ›¿æ¢æ‰å¯èƒ½æ–­è§¦çš„é€šé“ï¼ˆè¿‡å¤§æ³¢åŠ¨ï¼‰"""
    stds = np.std(chunk, axis=1)
    bad_indices = np.where(stds > threshold_uv)[0]

    if len(bad_indices) > 0:
        good_channels = [i for i in range(chunk.shape[0]) if i not in bad_indices]
        if good_channels:
            mean_signal = np.mean(chunk[good_channels, :], axis=0)
            for i in bad_indices:
                chunk[i, :] = mean_signal

            # è¾“å‡ºé€šé“åè€Œä¸æ˜¯ç´¢å¼•
            if labels:
                bad_names = [labels[i] for i in bad_indices]
                print(f"âš ï¸ æ›¿æ¢äº†å¼‚å¸¸é€šé“: {bad_names}")
            else:
                print(f"âš ï¸ æ›¿æ¢äº†å¼‚å¸¸é€šé“: ç´¢å¼• {bad_indices}")
    return chunk





# EEGæ»¤æ³¢å‡½æ•°


#IIR
def eeg_filter(data, srate, cutoff=0.5, order=2):
    nyq = 0.5 * srate
    if isinstance(cutoff, (list, tuple)) and len(cutoff) == 2:
        low, high = cutoff
        if low == 0:
            mode = 'low'
            normal_cutoff = high / nyq
        elif high == 0:
            mode = 'high'
            normal_cutoff = low / nyq
        else:
            mode = 'band'
            normal_cutoff = [low / nyq, high / nyq]
    else:
        return data  # ä¸å¤„ç†éæ³• cutoff æ ¼å¼

    b, a = butter(order, normal_cutoff, btype=mode, analog=False)
    return filtfilt(b, a, data, axis=1)


def analyze_bandpower(chunk, raw, srate, labels, gui=None):
    try:
        freqs, psd = welch(chunk, fs=srate, nperseg=srate, axis=1)
        band_dict = {}
        for band, (fmin, fmax) in {
            'delta': (1, 4),
            'theta': (4, 8),
            'alpha': (8, 13),
            'beta': (13, 30),
            'gamma': (30, 45)
        }.items():
            idx = (freqs >= fmin) & (freqs <= fmax)
            if np.any(idx):
                band_dict[band] = float(np.mean(psd[:, idx]))

        if gui and gui.bandpower_plot:
            gui.bandpower_plot.update_bandpower(band_dict)

    except Exception as e:
        print("âŒ analyze_bandpower é”™è¯¯:", e)







import time



def heavy_analysis(chunk, raw, srate, labels):
    t0 = time.time()



    #time.sleep(2)  # ç­‰å¾… 2 ç§’

    #print("ğŸ§ª [é‡è®¡ç®—å¼€å§‹]")

    try:
        # === Step 0: è¾“å…¥æ£€æŸ¥ ===
        if not isinstance(chunk, np.ndarray) or chunk.ndim != 2:
            print("â— chunk éæ³•ï¼Œè·³è¿‡åˆ†æã€‚shape:", np.shape(chunk))
            return
        if not isinstance(raw, np.ndarray) or raw.ndim != 2:
            print("â— raw éæ³•ï¼Œè·³è¿‡åˆ†æã€‚shape:", np.shape(raw))
            return
        if chunk.shape[1] < srate:
            print("âš ï¸ æ•°æ®ä¸è¶³ 1 ç§’ï¼Œè·³è¿‡")
            return


        # === Step 1: bandpower ===
        for data_name, data in zip(['cleaned', 'raw'], [chunk, raw]):

            #print("data.shape =",data.shape)#data.shape = (29, 2500)
            #print(srate)
            freqs,psd  = welch(data, fs=srate, nperseg=srate, axis=1)
            #print("psd.shape =", psd.shape)  # psd.shape = (29,251)
            #ä»£è¡¨äº†29ä¸ªé€šé“ï¼Œåœ¨251ä¸ªé¢‘ç‡ä¸Šçš„åŠŸç‡å¯†åº¦å€¼
            #åç»­ç›´æ¥å¯¹ psd[:, 8:13] â†’ æ±‚ alpha æ³¢æ®µçš„èƒ½é‡
            #print(psd)

            #print("freqs.shape =", freqs.shape)  # freqs.shape = (251,)
            #print(freqs)


            for band, (fmin, fmax) in {
                'delta': (1, 4),
                'theta': (4, 8),
                'alpha': (8, 13),
                'beta': (13, 30),
                'gamma': (30, 45)
            }.items():
                idx = (freqs >= fmin) & (freqs <= fmax)
                if not np.any(idx):
                    print(f"âš ï¸ Band {band} not found in freqs, skipping.")
                    continue
                band_power = np.mean(psd[:, idx], axis=1)#è®¡ç®—æ¯ä¸ªé€šé“åœ¨è¯¥é¢‘æ®µçš„å¹³å‡åŠŸç‡
                #print(f"{data_name} | {band} power: {np.mean(band_power):.2f}")

        # === Step 2: Hjorth å‚æ•° ===
        def compute_hjorth(data):
            d1 = np.diff(data, axis=1)#æ±‚å¯¼ï¼ˆaxis=1ï¼Œå¯¹è¡Œï¼‰ ä¿¡å·å˜åŒ–é€Ÿåº¦
            d2 = np.diff(d1, axis=1)#ä¿¡å·å˜åŒ–åŠ é€Ÿåº¦
            activity = np.var(data, axis=1)#æŒ¯å¹…é«˜ â†’ æ´»åŠ¨å¼ºï¼›æ¯”å¦‚è§‰é†’æ—¶è„‘ç”µ activity è¾ƒå¤§ã€‚
            mobility = np.sqrt(np.var(d1, axis=1) / activity)#è¶Šé«˜çš„ mobilityï¼Œè¡¨ç¤ºè„‘ç”µè¶Šæ´»è·ƒäºé«˜é¢‘æ®µï¼Œå¦‚ betaã€gammaã€‚
            complexity = np.sqrt(np.var(d2, axis=1) / np.var(d1, axis=1))#é«˜å¤æ‚åº¦å¯èƒ½è¡¨ç¤ºæ³¨æ„åŠ›è½¬ç§»ã€æ€ç»´æ´»è·ƒã€æ„ŸçŸ¥çªå˜ç­‰ã€‚
            return activity, mobility, complexity

        hjorth_act, hjorth_mob, hjorth_comp = compute_hjorth(chunk)

        # === Step 3: åæ–¹å·®çŸ©é˜µç‰¹å¾å€¼åˆ†è§£ ===
        cov = np.cov(chunk)
        eigvals, eigvecs = np.linalg.eigh(cov)
        eigvals = np.sort(eigvals)[::-1]

        # === Step 4: æ„é€ ç‰¹å¾ + å‡åˆ†ç±» ===
        dummy_features = np.concatenate([hjorth_act, eigvals[:10]])
        dummy_prediction = int(np.sum(dummy_features) % 3)  # å‡è£…æœ‰ä¸ªåˆ†ç±»å™¨

        t1 = time.time()
        #print(f"âœ… [é‡è®¡ç®—å®Œæˆ] è€—æ—¶: {(t1 - t0) * 1000:.1f} msï¼Œé¢„æµ‹ç±»: {dummy_prediction}")

    except Exception as e:
        print("âŒ heavy_analysis é”™è¯¯:", e)


import threading
import numpy as np
from scipy.signal import welch
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler

class RealTimeRegressor:
    def __init__(self, gui=None):
        self.model = SGDRegressor(learning_rate='adaptive', eta0=0.01)
        self.scaler = StandardScaler()
        self.first_fit_done = False
        self.lock = threading.Lock()

        self.latest_prediction = 0.0
        self.gui = gui  # â¬…ï¸ GUI å®ä¾‹ï¼Œç”¨äºæ›´æ–°é¢„æµ‹æ˜¾ç¤º
        self.last_input_x = None

        self.feature_buffer = []  # ç‰¹å¾ç¼“å­˜
        self.max_pretrain_samples = 20  # é‡‡æ ·é˜ˆå€¼

    def extract_features(self, chunk, srate):
        d1 = np.diff(chunk, axis=1)
        d2 = np.diff(d1, axis=1)
        activity = np.var(chunk, axis=1)
        mobility = np.sqrt(np.var(d1, axis=1) / activity)
        complexity = np.sqrt(np.var(d2, axis=1) / np.var(d1, axis=1))

        freqs, psd = welch(chunk, fs=srate, nperseg=srate, axis=1)
        features = list(activity) + list(mobility) + list(complexity)

        for fmin, fmax in [(1, 4), (4, 8), (8, 13), (13, 30), (30, 45)]:
            idx = (freqs >= fmin) & (freqs <= fmax)
            bandpower = np.mean(psd[:, idx], axis=1)
            features.extend(bandpower)

        return np.array(features).reshape(1, -1)

    def callback(self, chunk, raw, srate, labels):
        try:
            x = self.extract_features(chunk, srate)
            self.last_input_x = x

            if not self.first_fit_done:
                self.feature_buffer.append(x)
                print(f"ğŸ“¦ æ”¶é›†ä¸­: {len(self.feature_buffer)}/{self.max_pretrain_samples}")

                # é€šçŸ¥ GUI æ¿€æ´»è¯„åˆ†è¾“å…¥
                if len(self.feature_buffer) >= self.max_pretrain_samples and self.gui:
                    self.gui.enable_initial_rating_ui(True)
                return

            # === å®æ—¶é¢„æµ‹ ===
            x_scaled = self.scaler.transform(x)
            pred = self.model.predict(x_scaled)[0]
            self.latest_prediction = pred
            if self.gui:
                self.gui.update_prediction_display(pred)

        except Exception as e:
            print("âŒ å®æ—¶å›å½’é”™è¯¯:", e)

    def init_model_with_label(self, y_init):
        """ç”± GUI æäº¤åˆå§‹è¯„åˆ†åè°ƒç”¨"""
        if len(self.feature_buffer) < self.max_pretrain_samples:
            print("âŒ ç‰¹å¾ä¸è¶³ï¼Œæ— æ³•åˆå§‹åŒ–æ¨¡å‹")
            return

        X = np.vstack(self.feature_buffer)
        y = np.full((X.shape[0],), y_init)
        self.scaler.fit(X)
        X_scaled = self.scaler.transform(X)
        self.model.partial_fit(X_scaled, y)

        self.first_fit_done = True
        self.feature_buffer.clear()
        print("âœ… åˆå§‹æ¨¡å‹å·²å®Œæˆè®­ç»ƒ")

    def update_with_feedback(self, y):
        if not self.first_fit_done:
            print("âš ï¸ æ¨¡å‹æœªåˆå§‹åŒ–")
            return
        if self.last_input_x is None:
            print("âš ï¸ å°šæ— æœ€æ–°ç‰¹å¾è¾“å…¥")
            return
        x_scaled = self.scaler.transform(self.last_input_x)
        self.model.partial_fit(x_scaled, [y])
        print("âœ… æ¨¡å‹å·²é€šè¿‡åé¦ˆå€¼æ›´æ–°")



class RealTimeAttentionEstimator:
    def __init__(self, gui=None,receiver=None):
        self.gui = gui
        self.history = []
        self.max_history = 30  # å¹³æ»‘ç”¨çš„å†å²çª—å£
        self.receiver=receiver

    def extract_attention_score(self, chunk, srate):
        # âœ… Step 0: é€‰æ‹©ç‰¹å®šé€šé“è¿›è¡Œ bandpowerï¼ˆå¦‚ AF7=0, AF8=1ï¼‰

        selected_channels_name=['F7','F8','T7','T8','Fpz']
        selected_channels = self.receiver.channel_manager.get_indices_by_labels(selected_channels_name)
        #print(selected_channels)# æ›¿æ¢æˆä½ æƒ³ç”¨çš„é€šé“ç´¢å¼•
        chunk = chunk[selected_channels, :]  # åªä¿ç•™æ„Ÿå…´è¶£é€šé“
        if chunk.shape[0] != 5:
            raise ValueError("âŒ æ‰¾ä¸åˆ°æ‰€æœ‰æŒ‡å®šé€šé“ï¼šFpz, F7, F8, T7, T8")

        ref = chunk[0, :]  # Fpz æ˜¯ç¬¬ä¸€ä¸ªé€šé“
        chunk = chunk[1:, :] - ref  # å°†å…¶ä½™é€šé“å‡å» Fpzï¼Œå®ç° re-referencing




        # Step 1: Hjorth å‚æ•°
        d1 = np.diff(chunk, axis=1)
        d2 = np.diff(d1, axis=1)
        activity = np.mean(np.var(chunk, axis=1))
        complexity = np.mean(np.sqrt(np.var(d2, axis=1) / np.var(d1, axis=1)))

        # Step 2: é¢‘æ®µåŠŸç‡
        freqs, psd = welch(chunk, fs=srate, nperseg=srate, axis=1)
        def band_power(fmin, fmax):
            idx = (freqs >= fmin) & (freqs <= fmax)
            return np.mean(psd[:, idx])

        alpha = band_power(8, 13)
        theta = band_power(4, 8)
        beta = band_power(13, 30)
        gamma = band_power(30, 45)

        # #Step 3: å½’ä¸€åŒ– Attention Scoreï¼ˆå¯è°ƒæƒé‡ï¼‰
        # score = (
        #     -alpha * 0.6 +   # alpha â†“ è¡¨ç¤ºé›†ä¸­
        #     +theta * 0.2    # theta â†‘
        #     +beta * 0.5
        #     #+gamma * 0.3
        #     # +activity * 0.1 -
        #     # complexity * 0.2
        # )
        #
        # print(score)
        #
        # normalized = float(expit(score))  # sigmoid(score)
        # print(normalized)
        # return normalized

        # Step 3: æ³¨æ„åŠ›æ‰“åˆ†é€»è¾‘
        epsilon = 1e-6
        # NeuroChat æ ¸å¿ƒå…¬å¼ï¼šEngagement Index = Î² / (Î± + Î¸)
        engagement = (beta + epsilon) / (alpha + theta + epsilon)

        # æ·»åŠ æ»‘åŠ¨çª—å£å¹³å‡ï¼ˆç”¨äºå¹³æ»‘æ³¨æ„åŠ›ï¼‰
        self.history.append(engagement)
        if len(self.history) > self.max_history:
            self.history.pop(0)
        # engagement_avg = np.mean(self.history)
        #
        # # Normalize with assumed calibration range (å»ºè®®ä¹‹åæ›¿æ¢ä¸ºå®é™…çš„ E_min å’Œ E_max)
        # E_min = 0.2
        # E_max = 1.2
        # normalized = (engagement_avg - E_min) / (E_max - E_min + epsilon)
        # normalized = float(np.clip(normalized, 0.0, 1.0))

        engagement = (beta + epsilon) / (alpha + theta + epsilon)

        self.history.append(engagement)
        if len(self.history) > self.max_history:
            self.history.pop(0)
        engagement_avg = np.mean(self.history)

        # âš ï¸ ç”¨å†å²æœ€å¤§æœ€å°å€¼ä»£æ›¿é™æ€ E_min/E_maxï¼ˆæ›´çµæ•ï¼‰
        E_min = min(self.history)
        E_max = max(self.history)
        range_ = max(E_max - E_min, epsilon)  # é¿å…é™¤ä»¥ 0
        normalized = (engagement_avg - E_min) / range_
        normalized = float(np.clip(normalized, 0.0, 1.0))

        print(
            f"[Attention] alpha={alpha:.2f}, theta={theta:.2f}, beta={beta:.2f}, engagement_avg={engagement_avg:.2f}, norm={normalized:.2f}")
        return normalized

    def callback(self, chunk, raw, srate, labels):
        try:
            score = self.extract_attention_score(chunk, srate)
            #print(score)
            #self.history.append(score)
            if len(self.history) > self.max_history:
                self.history.pop(0)

            smoothed = np.mean(self.history)

            if self.gui:
                self.gui.update_attention_circle(smoothed)

        except Exception as e:
            print("âŒ æ³¨æ„åŠ›è¯„åˆ†é”™è¯¯:", e)







from PyQt5.QtCore import QTimer, QRect, QPoint, QPointF, Qt
from PyQt5.QtGui import QColor, QPainter, QFont
import numpy as np
import random

class AttentionBallWindow(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸ¯ Attention Ball View")
        self.resize(800, 600)
        self.ball_pos = QPoint(400, 300)
        self.ball_radius = 30
        self.color = QColor("gray")
        self.score = 0.0
        self.velocity = QPointF(0, 0)

        # åˆå§‹åŒ–è¡¨è¾¾å¼ä¸æ˜¾ç¤ºæ§åˆ¶
        self.current_expression = ""
        self.current_result = ""
        self.showing_result = False

        # å°çƒæ¼‚ç§»è®¡æ—¶å™¨
        self.timer = QTimer()
        self.timer.timeout.connect(self.move_ball)
        self.timer.start(16)



    def show_result(self):
        self.showing_result = True
        self.update()

    def move_ball(self):
        jitter = 0.5*(0.1+abs(max(0,(1.0 - self.score))))
        ax = np.random.uniform(-jitter, jitter) * 5
        ay = np.random.uniform(-jitter, jitter) * 5
        self.velocity += QPointF(ax, ay)
        max_speed = 12.0
        self.velocity.setX(np.clip(self.velocity.x(), -max_speed, max_speed))
        self.velocity.setY(np.clip(self.velocity.y(), -max_speed, max_speed))
        self.ball_pos += QPoint(int(self.velocity.x()), int(self.velocity.y()))
        margin = self.ball_radius
        self.ball_pos.setX(np.clip(self.ball_pos.x(), margin, self.width() - margin))
        self.ball_pos.setY(np.clip(self.ball_pos.y(), margin, self.height() - margin))
        self.velocity *= 0.92
        self.update()

    def update_attention(self, score):
        self.score = float(score)
        self.ball_radius = int(40 + 50 * self.score)

        # ğŸ¨ å°†æ³¨æ„åŠ›åˆ†æ•°æ˜ å°„åˆ°çº¢â†’é»„â†’ç»¿çš„æ¸å˜
        # 0.0 â†’ çº¢ (255, 0, 0)
        # 0.5 â†’ é»„ (255, 255, 0)
        # 1.0 â†’ ç»¿ (0, 255, 0)
        if self.score <= 0.5:
            # çº¢ â†’ é»„ çº¿æ€§æ’å€¼
            r = 255
            g = int(255 * (self.score / 0.5))  # 0â†’255
            b = 0
        else:
            # é»„ â†’ ç»¿ çº¿æ€§æ’å€¼
            r = int(255 * (1 - (self.score - 0.5) / 0.5))  # 255â†’0
            g = 255
            b = 0

        self.color = QColor(r, g, b)
        self.update()

    def paintEvent(self, event):
        painter = QPainter(self)
        painter.setRenderHint(QPainter.Antialiasing)
        painter.setBrush(self.color)
        painter.setPen(Qt.NoPen)
        painter.drawEllipse(self.ball_pos, self.ball_radius, self.ball_radius)

        # âœï¸ æ˜¾ç¤ºæ³¨æ„åŠ›å¾—åˆ†ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
        painter.setPen(Qt.black)
        font = QFont("Arial", 14)
        font.setBold(True)
        painter.setFont(font)

        text = f"{self.score:.2f}"
        text_rect = QRect(self.ball_pos.x() - self.ball_radius,
                          self.ball_pos.y() - 10,
                          self.ball_radius * 2,
                          20)
        painter.drawText(text_rect, Qt.AlignCenter, text)




from PyQt5.QtWidgets import QDialog, QVBoxLayout, QPushButton, QCheckBox, QScrollArea, QWidget

# class ChannelSelectorDialog(QDialog):
#     def __init__(self, parent_gui, receiver):
#         super().__init__()
#         self.setWindowTitle("Select EEG Channels")
#         self.receiver = receiver
#         self.parent_gui = parent_gui
#         self.checkboxes = []
#
#         layout = QVBoxLayout()
#
#         scroll = QScrollArea()
#         scroll_widget = QWidget()
#         scroll_layout = QVBoxLayout(scroll_widget)
#
#         for i, label in enumerate(receiver.chan_labels):
#             cb = QCheckBox(label)
#             cb.setChecked(i in receiver.channel_range)
#             self.checkboxes.append(cb)
#             scroll_layout.addWidget(cb)
#
#         scroll.setWidget(scroll_widget)
#         scroll.setWidgetResizable(True)
#         layout.addWidget(scroll)
#
#         confirm_btn = QPushButton("Confirm Selection")
#         confirm_btn.clicked.connect(self.apply_selection)
#         layout.addWidget(confirm_btn)
#
#         self.setLayout(layout)
#         self.resize(300, 400)
#
#     def apply_selection(self):
#         selected_indices = [
#             i for i, cb in enumerate(self.checkboxes) if cb.isChecked()
#         ]
#         self.receiver.channel_range = selected_indices
#         print(f"âœ… Selected channel indices: {selected_indices}")
#         print(f"âœ… Selected channel labels: {[self.receiver.chan_labels[i] for i in selected_indices]}")
#         self.accept()



class ChannelSelectorDialog(QDialog):
    def __init__(self, parent_gui, receiver):
        super().__init__()
        self.setWindowTitle("Select EEG Channels")
        self.receiver = receiver
        self.parent_gui = parent_gui
        self.checkboxes = []

        layout = QVBoxLayout()

        scroll = QScrollArea()
        scroll_widget = QWidget()
        scroll_layout = QVBoxLayout(scroll_widget)

        # ä» ChannelManager è·å–å…¨éƒ¨é€šé“
        self.channel_info = self.receiver.channel_manager.channels

        # å½“å‰é€‰ä¸­çš„ index åˆ—è¡¨
        current_range = set(self.receiver.channel_range)

        for ch in self.channel_info:
            cb = QCheckBox(ch["label"])
            # å‹¾é€‰å½“å‰åœ¨ range ä¸­çš„é€šé“
            cb.setChecked(ch["index"] in current_range)
            self.checkboxes.append(cb)
            scroll_layout.addWidget(cb)

        scroll.setWidget(scroll_widget)
        scroll.setWidgetResizable(True)
        layout.addWidget(scroll)

        confirm_btn = QPushButton("Confirm Selection")
        confirm_btn.clicked.connect(self.apply_selection)
        layout.addWidget(confirm_btn)

        self.setLayout(layout)
        self.resize(300, 400)

    def apply_selection(self):
        selected_indices = []
        selected_labels = []

        for cb, ch in zip(self.checkboxes, self.channel_info):
            if cb.isChecked():
                selected_indices.append(ch["index"])
                selected_labels.append(ch["label"])

        # æ›´æ–° receiver çš„é€šé“èŒƒå›´å’Œæ ‡ç­¾
        self.receiver.channel_range = selected_indices
        self.receiver.chan_labels = selected_labels

        print(f"âœ… Selected channel indices: {selected_indices}")
        print(f"âœ… Selected channel labels: {selected_labels}")
        self.accept()



class ChannelManager:
    def __init__(self, lsl_info):
        """
        ä» pylsl.StreamInfo æå–å¹¶ä¿å­˜æ‰€æœ‰æœ‰æ„ä¹‰çš„ä¿¡æ¯
        åŒ…æ‹¬å…¨å±€å±æ€§å’Œé€šé“ç»“æ„
        """
        # === å…¨å±€æµä¿¡æ¯ ===
        self.name = lsl_info.name()
        self.type = lsl_info.type()
        self.channel_count = lsl_info.channel_count()
        self.srate = int(lsl_info.nominal_srate())
        self.uid = lsl_info.uid()
        self.hostname = lsl_info.hostname()
        self.source_id = lsl_info.source_id()
        self.version = lsl_info.version()
        self.created_at = lsl_info.created_at()

        # === æ‰€æœ‰é€šé“ä¿¡æ¯ ===
        #è¿™ä¸ªç±»çš„å®ä¾‹ä¸­æœ‰ç€æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸€äº›éEEGï¼Œä½†æ˜¯å®ƒæœ‰æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼Œåç»­è¿˜èƒ½ä½¿ç”¨ã€‚
        self.channels = []  # æ¯ä¸ªå…ƒç´ æ˜¯ dictï¼šlabel, index, type, unit

        ch = lsl_info.desc().child('channels').child('channel')
        index = 0
        while ch.name() == "channel":
            label = ch.child_value("label")
            ch_type = ch.child_value("type")
            unit = ch.child_value("unit")

            self.channels.append({
                "label": label,
                "index": index,
                "type": ch_type,
                "unit": unit
            })

            ch = ch.next_sibling()
            index += 1

    # === é€šé“ç­›é€‰æ–¹æ³• ===
    def get_all_labels(self):
        return [ch["label"] for ch in self.channels]

    def get_all_indices(self):
        return [ch["index"] for ch in self.channels]

    def get_labels_by_type(self, desired_type="EEG"):
        return [ch["label"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_type(self, desired_type="EEG"):
        return [ch["index"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_labels(self, labels):
        label_set = set(labels)
        return [ch["index"] for ch in self.channels if ch["label"] in label_set]

    def get_labels_excluding_keywords(self, keywords):
        return [ch["label"] for ch in self.channels
                if not any(kw in ch["label"] for kw in keywords)]

    def get_indices_excluding_keywords(self, keywords):
        return [ch["index"] for ch in self.channels
                if not any(kw in ch["label"] for kw in keywords)]

    def get_labels_by_indices(self, indices):
        """
        æ ¹æ®ç´¢å¼•åˆ—è¡¨è·å–å¯¹åº”çš„é€šé“ååˆ—è¡¨
        """
        index_set = set(indices)
        return [ch["label"] for ch in self.channels if ch["index"] in index_set]

    # === ä¿¡æ¯æ‰“å°æ–¹æ³• ===
    def print_summary(self):
        print("=== Stream Info ===")
        print(f"Name      : {self.name}")
        print(f"Type      : {self.type}")
        print(f"Channels  : {self.channel_count}")
        print(f"Sampling  : {self.srate} Hz")
        print(f"UID       : {self.uid}")
        print(f"Hostname  : {self.hostname}")
        print(f"Source ID : {self.source_id}")
        print(f"Version   : {self.version}")
        print(f"Created   : {self.created_at}")
        print("\n=== Channel List ===")
        for ch in self.channels:
            print(f"[{ch['index']:02}] {ch['label']} | Type: {ch['type']} | Unit: {ch['unit']}")

#åœ¨LSLStreamReceiver.find_and_open_stream()ä¸­
# info = self.inlet.info()
# self.channel_manager = ChannelManager(info)
#
# # åªè·å– EEG ç±»å‹
# self.chan_labels = self.channel_manager.get_labels_by_type("EEG")
# self.channel_range = self.channel_manager.get_indices_by_type("EEG")
#
# # æˆ–è€…è‡ªå®šä¹‰æ’é™¤æŸäº›å…³é”®è¯
# exclude = ['TRIGGER', 'ACC', 'Packet', 'ExG']
# self.chan_labels = self.channel_manager.get_labels_excluding_keywords(exclude)
# self.channel_range = self.channel_manager.get_indices_excluding_keywords(exclude)
#
# # æ‰“å°æ¦‚å†µ
# self.channel_manager.print_summary()
#
# # è·å–å…¨å±€å‚æ•°ï¼ˆå¯é€‰ï¼‰
# print("é‡‡æ ·ç‡ä¸ºï¼š", self.channel_manager.srate)


from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from PyQt5.QtWidgets import QWidget, QVBoxLayout
import numpy as np

class BandpowerStreamVisualizer(QWidget):
    def __init__(self, bands=('delta', 'theta', 'alpha', 'beta', 'gamma'), history_length=300):
        super().__init__()
        self.bands = bands
        self.history_length = history_length
        self.history = {band: [0] * history_length for band in self.bands}
        self.timestamps = list(range(-history_length + 1, 1))

        self.fig, self.ax = plt.subplots(figsize=(6, 4))
        self.canvas = FigureCanvas(self.fig)
        layout = QVBoxLayout()
        layout.addWidget(self.canvas)
        self.setLayout(layout)

        # åˆå§‹åŒ– line å’Œ legend label
        self.offsets = np.arange(len(self.bands)) * 30
        self.lines = {}
        self.text_labels = {}

        for i, band in enumerate(self.bands):
            line, = self.ax.plot([], [], label=f"{band}: 0.00", linewidth=1.5)
            self.lines[band] = line

        # è®¾ç½®å›¾åƒåŸºæœ¬ä¿¡æ¯
        self.ax.set_xlim(-self.history_length + 1, 0)
        self.ax.set_xlabel("Time (chunks)")
        self.ax.set_title("Real-time Bandpower Waveform")

        # å¤–éƒ¨å›¾ä¾‹
        self.ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5))

        self.fig.tight_layout()

    def update_bandpower(self, band_values):
        for band in self.bands:
            if band in band_values:
                self.history[band].append(band_values[band])
                if len(self.history[band]) > self.history_length:
                    self.history[band].pop(0)

        self.ax.clear()

        # 1. è®¡ç®—ä¸­ä½æ•° + é«˜ç™¾åˆ†ä½ï¼ˆæŠ—å¼‚å¸¸ï¼‰
        all_vals = np.concatenate([np.array(self.history[band]) for band in self.bands])
        sorted_vals = np.sort(all_vals)
        low_percentile = int(0.05 * len(sorted_vals))
        high_percentile = int(0.95 * len(sorted_vals))
        safe_vals = sorted_vals[low_percentile:high_percentile]
        safe_max = np.max(safe_vals) if len(safe_vals) > 0 else 1.0

        # 2. æ·»åŠ åç§»
        safe_max += 40

        # 3. é™åˆ¶æœ€å¤§é«˜åº¦ï¼ˆé˜²ç‚¸ï¼‰
        safe_max = min(safe_max, 200)

        # âœ… ç»˜åˆ¶æ¯ä¸ªé¢‘æ®µæ›²çº¿å¹¶æ ‡æ³¨å½“å‰å€¼
        for i, band in enumerate(self.bands):
            data = np.array(self.history[band])

            recent_window = data[-100:] if len(data) >= 100 else data
            band_min = np.min(recent_window)
            band_max = np.max(recent_window)
            range_ = band_max - band_min
            if range_ < 1e-3:
                range_ = 1.0
            norm_data = (data - band_min) / range_

            scaled_data = norm_data * 20 + self.offsets[i]

            self.ax.plot(self.timestamps[-len(data):], scaled_data,
                         label=f"{band}: {data[-1]:.2f}", linewidth=1.5)

        # 4. è®¾ç½® Y è½´ç­‰å±æ€§
        self.ax.set_ylim(-10, safe_max)
        self.ax.set_yticks(self.offsets)
        self.ax.set_yticklabels(self.bands)
        self.ax.set_xlabel("Time (chunks)")
        self.ax.set_title("Real-time Bandpower Waveform")

        # âœ… å›¾ä¾‹æ”¾å³ä¾§ï¼Œå¹¶é¿å…è­¦å‘Š
        handles, labels = self.ax.get_legend_handles_labels()
        if labels:
            self.ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5))

        self.fig.tight_layout()
        self.canvas.draw()


# GUIç•Œé¢åµŒå…¥Matplotlibç»˜å›¾
from PyQt5.QtWidgets import QTabWidget, QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, QLineEdit, QCheckBox, QGroupBox

class EEGGUI(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Real-time EEG Viewer")
        self.setGeometry(100, 100, 1000, 700)

        self.receiver = LSLStreamReceiver()
        self.viewer = LSLStreamVisualizer(self.receiver)
        self.regressor = RealTimeRegressor(gui=self)

        # ========== åˆ›å»º Tab ç•Œé¢ ==========
        self.tabs = QTabWidget()
        self.tab_main = QWidget()
        self.tab_bandpower = QWidget()
        self.tabs.addTab(self.tab_main, "EEG Viewer")
        self.tabs.addTab(self.tab_bandpower, "Bandpower Plot")

        # ========== ä¸»ç•Œé¢ Tab ==========
        main_layout = QVBoxLayout()
        self.canvas = FigureCanvas(self.viewer.fig)
        main_layout.addWidget(self.canvas)

        self.cutoff_input1 = QLineEdit("0.5")
        self.cutoff_input2 = QLineEdit("45")
        cutoff_layout = QHBoxLayout()
        cutoff_layout.addWidget(QLabel("Lower Cutoff:"))
        cutoff_layout.addWidget(self.cutoff_input1)
        cutoff_layout.addWidget(QLabel("Upper Cutoff:"))
        cutoff_layout.addWidget(self.cutoff_input2)
        main_layout.addLayout(cutoff_layout)

        self.start_btn = QPushButton("Start Stream")
        self.start_btn.clicked.connect(self.start_stream)
        main_layout.addWidget(self.start_btn)

        self.update_btn = QPushButton("Update Filter")
        self.update_btn.clicked.connect(self.update_filter_params)
        main_layout.addWidget(self.update_btn)

        self.asr_checkbox = QCheckBox("Enable ASR (pyPREP)")
        main_layout.addWidget(self.asr_checkbox)

        # attention display
        self.att_label = QLabel("ğŸ¯ æ³¨æ„åŠ›æ°´å¹³")
        self.att_circle = QLabel()
        self.att_circle.setFixedSize(100, 100)
        self.att_circle.setStyleSheet("border-radius: 50px; background-color: green;")
        main_layout.addWidget(self.att_label)
        main_layout.addWidget(self.att_circle)

        self.attention_ball_window = AttentionBallWindow()
        self.attention_ball_window.show()

        self.channel_select_btn = QPushButton("Select Channels")
        self.channel_select_btn.clicked.connect(self.open_channel_selector)
        main_layout.addWidget(self.channel_select_btn)

        self.tab_main.setLayout(main_layout)

        # ========== Bandpower Tab ==========
        # æ–°å¢ bandpower å¯è§†åŒ–å™¨
        self.bandpower_plot = BandpowerStreamVisualizer()
        bp_layout = QVBoxLayout()
        bp_layout.addWidget(self.bandpower_plot)
        self.tab_bandpower.setLayout(bp_layout)
        self.tabs.addTab(self.tab_bandpower, "Bandpower Waveform")

        # ========== å¤–å±‚ Layout ==========
        outer_layout = QVBoxLayout()
        outer_layout.addWidget(self.tabs)
        self.setLayout(outer_layout)


    def start_stream(self):
        self.update_filter_params()
        self.viewer.start()
        self.canvas.draw()

        self.receiver.register_analysis_callback(analyze_bandpower)
        self.receiver.register_analysis_callback(heavy_analysis)
        #self.receiver.register_analysis_callback(self.regressor.callback)

        self.attention_estimator = RealTimeAttentionEstimator(gui=self,receiver=self.receiver)
        self.receiver.register_analysis_callback(self.attention_estimator.callback)


        self.receiver.register_analysis_callback(lambda **kwargs: analyze_bandpower(gui=self, **kwargs))

    def update_filter_params(self):
        try:
            # è·å–è¾“å…¥çš„ä¸Šä¸‹æˆªæ­¢é¢‘ç‡
            val1 = float(self.cutoff_input1.text())
            val2 = float(self.cutoff_input2.text())

            # è®¾ç½®åˆ° receiver ä¸­
            self.receiver.cutoff = (val1, val2)
            print(f"âœ… å·²æ›´æ–°æ»¤æ³¢å‚æ•°: cutoff = {self.receiver.cutoff}")

        except ValueError:
            print("âŒ Cutoff å€¼æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ (0.5, 45)")

        # è®¾ç½®æ˜¯å¦å¯ç”¨ ASRï¼ˆä»å¤é€‰æ¡†è¯»å–ï¼‰
        if hasattr(self, 'asr_checkbox'):
            self.receiver.use_asr = self.asr_checkbox.isChecked()
            print(f"{'âœ… å¯ç”¨' if self.receiver.use_asr else 'âŒ å…³é—­'} ASR å¤„ç†")

    def update_prediction_display(self, pred):
        self.pred_label.setText(f"ğŸ¯ é¢„æµ‹æƒ…ç»ªå¼ºåº¦: {pred:.3f}")

    def update_model_from_gui(self):
        text = self.feedback_input.text()
        try:
            y = float(text)
            if 0 <= y <= 1:
                self.regressor.update_with_feedback(y)  # âœ… GUI ä¸å†å¤„ç† scaler æˆ–æ¨¡å‹
            else:
                print("âš ï¸ è¾“å…¥åº”åœ¨ [0, 1] ä¹‹é—´")
        except Exception as e:
            print("âŒ éæ³•è¾“å…¥", e)

        print(text)

    def enable_initial_rating_ui(self, enable=True):
        self.init_label.setVisible(enable)
        self.init_input.setVisible(enable)
        self.init_button.setVisible(enable)

    def submit_initial_rating(self):
        text = self.init_input.text()
        try:
            y = float(text)
            if 0 <= y <= 1:
                self.regressor.init_model_with_label(y)
                print("âœ… åˆå§‹è¯„åˆ†å·²ç”¨äºæ¨¡å‹åˆå§‹åŒ–")
                self.enable_initial_rating_ui(False)
            else:
                print("âš ï¸ è¾“å…¥åº”åœ¨ [0, 1] ä¹‹é—´")
        except Exception as e:
            print("âŒ åˆå§‹è¯„åˆ†è¾“å…¥æ— æ•ˆ", e)

    def update_attention_circle(self, score):
        #size = int(30 + 70 * score)
        size = int(100*score)
        self.att_circle.setFixedSize(size, size)
        color = "green" if score > 0.6 else "orange" if score > 0.3 else "red"
        self.att_circle.setStyleSheet(f"border-radius: {size // 2}px; background-color: {color};")

        # ğŸ‘‡ åŒæ­¥æ›´æ–°åˆ°æ¼‚ç§»å°çƒçª—å£
        self.attention_ball_window.update_attention(score)

    def open_channel_selector(self):
        if self.receiver.chan_labels:
            dlg = ChannelSelectorDialog(self, self.receiver)
            dlg.exec_()
        else:
            print("âš ï¸ é€šé“æ ‡ç­¾å°šæœªåŠ è½½ï¼Œæ— æ³•é€‰æ‹©é€šé“")


if __name__ == '__main__':
    app = QApplication(sys.argv)
    gui = EEGGUI()
    gui.show()
    sys.exit(app.exec_())
