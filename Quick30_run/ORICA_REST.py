import numpy as np
from scipy.stats import kurtosis
from sklearn.feature_selection import mutual_info_regression
from ORICA_calibration import ORICACalibration

class ORICAZ:
    def __init__(self, n_components, learning_rate=0.001, ortho_every=10, 
                 use_rls_whitening=False, forgetting_factor=0.98, 
                 nonlinearity='gaussian', block_size_ica=8, block_size_white=8,
                 ff_profile='cooling', tau_const=np.inf, gamma=0.6, lambda_0=0.995,
                 num_subgaussian=0, eval_convergence=True, verbose=False):
        """
        ORICA with RLS whitening support - åŸºäºMATLAB orica.må®ç°
        
        Args:
            n_components: ç‹¬ç«‹æˆåˆ†æ•°é‡
            learning_rate: å­¦ä¹ ç‡
            ortho_every: æ¯éš”å¤šå°‘æ¬¡è¿­ä»£æ­£äº¤åŒ–
            use_rls_whitening: æ˜¯å¦ä½¿ç”¨RLSç™½åŒ–
            forgetting_factor: RLSé—å¿˜å› å­ (0 < Î» < 1)
            nonlinearity: éçº¿æ€§å‡½æ•°ç±»å‹ ('gaussian', 'tanh')
            block_size_ica: ICAå—å¤§å°
            block_size_white: ç™½åŒ–å—å¤§å°
            ff_profile: é—å¿˜å› å­ç­–ç•¥ ('cooling', 'constant', 'adaptive')
            tau_const: å±€éƒ¨å¹³ç¨³æ€§å‚æ•°
            gamma: å†·å´ç­–ç•¥å‚æ•°
            lambda_0: åˆå§‹é—å¿˜å› å­
            num_subgaussian: æ¬¡é«˜æ–¯æºæ•°é‡
            eval_convergence: æ˜¯å¦è¯„ä¼°æ”¶æ•›æ€§
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        self.n_components = n_components
        self.learning_rate = learning_rate
        self.W = np.eye(n_components)  # è§£æ··çŸ©é˜µ (icaweights)
        self.mean = None
        self.whitening_matrix = None  # icasphere
        self.whitened = False
        self.update_count = 0
        self.ortho_every = ortho_every
        
        # å—æ›´æ–°å‚æ•°
        self.block_size_ica = block_size_ica
        self.block_size_white = block_size_white
        
        # é—å¿˜å› å­å‚æ•°
        self.ff_profile = ff_profile
        self.tau_const = tau_const
        self.gamma = gamma
        self.lambda_0 = lambda_0
        self.lambda_const = 1 - np.exp(-1/tau_const) if tau_const != np.inf else 0.98
        
        # æ¬¡é«˜æ–¯æºå‚æ•°
        self.num_subgaussian = num_subgaussian
        self.kurtosis_sign = np.ones(n_components, dtype=bool)  # Trueä¸ºè¶…é«˜æ–¯
        if num_subgaussian > 0:
            self.kurtosis_sign[:num_subgaussian] = False
        
        # æ”¶æ•›æ€§è¯„ä¼°
        self.eval_convergence = eval_convergence
        self.leaky_avg_delta = 0.01
        self.leaky_avg_delta_var = 1e-3
        self.Rn = None
        self.non_stat_idx = None
        self.min_non_stat_idx = None
        
        # çŠ¶æ€å˜é‡
        self.lambda_k = np.zeros(block_size_ica)
        self.counter = 0
        
        # RLSç™½åŒ–å‚æ•°
        self.use_rls_whitening = use_rls_whitening
        self.forgetting_factor = forgetting_factor
        self.nonlinearity = nonlinearity
        
        # RLSç™½åŒ–ç›¸å…³å˜é‡
        if self.use_rls_whitening:
            self.C = None  # åæ–¹å·®çŸ©é˜µçš„é€†
            self.t = 0     # æ—¶é—´æ­¥è®¡æ•°å™¨
            
        self.verbose = verbose

    def _center(self, X):
        """å»å‡å€¼"""
        if self.mean is None:
            self.mean = np.mean(X, axis=0)
        return X - self.mean

    def _whiten(self, X):
        """ä¼ ç»Ÿæ‰¹é‡ç™½åŒ– - ä½¿ç”¨ç‰¹å¾å€¼åˆ†è§£"""
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if X.shape[0] < 2:
            print(f"âš ï¸ ç™½åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {X.shape[0]}ï¼Œè·³è¿‡ç™½åŒ–")
            return X
        
        try:
            cov = np.cov(X, rowvar=False)
            d, E = np.linalg.eigh(cov)
            D_inv = np.diag(1.0 / np.sqrt(d + 1e-2))  # é˜²æ­¢é™¤0
            self.whitening_matrix = E @ D_inv @ E.T
            return X @ self.whitening_matrix.T
        except Exception as e:
            print(f"âš ï¸ ç™½åŒ–å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹æ•°æ®")
            return X

    def _rls_whiten_initialize(self, X):
        """åˆå§‹åŒ–RLSç™½åŒ–"""
        # Xçš„å½¢çŠ¶æ˜¯ (samples, channels)ï¼Œéœ€è¦è½¬ç½®ä¸º (channels, samples)
        # if X.shape[0] < X.shape[1]:  # å¦‚æœç¬¬ä¸€ä¸ªç»´åº¦å°äºç¬¬äºŒä¸ªç»´åº¦ï¼Œè¯´æ˜æ˜¯ (samples, channels)
        #     n_channels = X.shape[1]
        # else:
        n_channels = X.shape[1]
        
        # åˆå§‹åŒ–åæ–¹å·®çŸ©é˜µçš„é€†ä¸ºå•ä½çŸ©é˜µ
        self.C = np.eye(n_channels)
        self.whitening_matrix = np.eye(n_channels)
        self.t = 0
        print(f"ğŸ”§ RLSç™½åŒ–åˆå§‹åŒ–: é€šé“æ•°={n_channels}, CçŸ©é˜µå½¢çŠ¶={self.C.shape}")

    def _rls_whiten_update(self, x_t):
        """
        RLSç™½åŒ–å•æ­¥æ›´æ–°
        
        Args:
            x_t: å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ® (n_channels, 1)
        """
        if self.C is None:
            raise ValueError("RLS whitening not initialized. Call initialize() first.")
        
        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        expected_channels = self.C.shape[0]
        actual_channels = x_t.shape[0]
        
        if expected_channels != actual_channels:
            print(f"âš ï¸ RLSç™½åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{expected_channels}é€šé“ï¼Œå®é™…{actual_channels}é€šé“")
            # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.C = np.eye(actual_channels)
            self.whitening_matrix = np.eye(actual_channels)
            self.t = 0
            print(f"âœ… é‡æ–°åˆå§‹åŒ–RLSç™½åŒ–ï¼Œæ–°ç»´åº¦: {actual_channels}")
        
        # RLSæ›´æ–°è§„åˆ™
        lambda_t = self.forgetting_factor
        self.t += 1
        
        # è®¡ç®—å¢ç›Šå‘é‡
        k = self.C @ x_t
        denominator = lambda_t + x_t.T @ k
        k = k / denominator
        
        # æ›´æ–°åæ–¹å·®çŸ©é˜µçš„é€†
        self.C = (self.C - k @ x_t.T @ self.C) / lambda_t
        
        # æ›´æ–°ç™½åŒ–çŸ©é˜µ
        # ç™½åŒ–çŸ©é˜µæ˜¯åæ–¹å·®çŸ©é˜µé€†çš„å¹³æ–¹æ ¹
        eigenvals, eigenvecs = np.linalg.eigh(self.C)
        eigenvals = np.maximum(eigenvals, 1e-6)  # é˜²æ­¢è´Ÿå€¼
        self.whitening_matrix = eigenvecs @ np.diag(np.sqrt(eigenvals)) @ eigenvecs.T
        
        # è¿”å›ç™½åŒ–åçš„æ•°æ®
        return self.whitening_matrix @ x_t

    def _g(self, y):
        """
        éçº¿æ€§å‡½æ•°
        
        Args:
            y: è¾“å…¥ä¿¡å·
            
        Returns:
            g_y: éçº¿æ€§å‡½æ•°å€¼
            g_prime: å¯¼æ•°
        """
        if self.nonlinearity == 'gaussian':
            # é«˜æ–¯éçº¿æ€§å‡½æ•°
            g_y = y * np.exp(-0.5 * y**2)
            g_prime = (1 - y**2) * np.exp(-0.5 * y**2)
        elif self.nonlinearity == 'tanh':
            # åŒæ›²æ­£åˆ‡éçº¿æ€§å‡½æ•°
            g_y = np.tanh(y)
            g_prime = 1 - np.tanh(y)**2
        else:
            raise ValueError(f"Unknown nonlinearity: {self.nonlinearity}")
        
        return g_y, g_prime

    def _gen_cooling_ff(self, t):
        """ç”Ÿæˆå†·å´é—å¿˜å› å­ - å¯¹åº”MATLABçš„genCoolingFF"""
        return self.lambda_0 / (t ** self.gamma)
    
    def _gen_adaptive_ff(self, data_range, ratio_of_norm_rn):
        """ç”Ÿæˆè‡ªé€‚åº”é—å¿˜å› å­ - å¯¹åº”MATLABçš„genAdaptiveFF"""
        # è‡ªé€‚åº”ç­–ç•¥å‚æ•°
        decay_rate_alpha = 0.02
        upper_bound_beta = 1e-3
        trans_band_width_gamma = 1
        trans_band_center = 5
        
        # æ£€æŸ¥lambda_kæ˜¯å¦ä¸ºç©º
        if len(self.lambda_k) == 0:
            print("âš ï¸ lambda_kä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return np.full(len(data_range), self.lambda_const)
        
        gain_for_errors = upper_bound_beta * 0.5 * (1 + np.tanh((ratio_of_norm_rn - trans_band_center) / trans_band_width_gamma))
        
        def f(n):
            return ((1 + gain_for_errors) ** n) * self.lambda_k[-1] - \
                   decay_rate_alpha * (((1 + gain_for_errors) ** (2*n-1)) - ((1 + gain_for_errors) ** (n-1))) / gain_for_errors * (self.lambda_k[-1] ** 2)
        
        return np.array([f(n) for n in range(1, len(data_range) + 1)])

    def initialize(self, X_init):
        """åˆå§‹åŒ–ORICA"""
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if X_init.shape[0] < 2:
            print(f"âš ï¸ åˆå§‹åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {X_init.shape[0]}ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return X_init
        
        # æ£€æŸ¥å¹¶è°ƒæ•´n_componentsä»¥åŒ¹é…æ•°æ®ç»´åº¦
        if X_init.shape[1] != self.n_components:  # X_initæ˜¯ (samples, channels) æ ¼å¼
            print(f"âš ï¸ åˆå§‹åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{X_init.shape[1]}é€šé“")
            self.n_components = X_init.shape[1]
            # é‡æ–°åˆ›å»ºWçŸ©é˜µä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.W = np.eye(self.n_components)
            print(f"âœ… è°ƒæ•´n_componentsä¸º{self.n_components}")
        
        try:
            # å»å‡å€¼
            X_init = self._center(X_init)
            
            # ç™½åŒ–
            if self.use_rls_whitening:
                # ä½¿ç”¨RLSç™½åŒ–åˆå§‹åŒ–
                self._rls_whiten_initialize(X_init)
                # å¯¹åˆå§‹æ•°æ®è¿›è¡Œæ‰¹é‡ç™½åŒ–
                X_init = self._whiten(X_init)
            else:
                # ä½¿ç”¨ä¼ ç»Ÿæ‰¹é‡ç™½åŒ–
                X_init = self._whiten(X_init)
            
            self.whitened = True
            print(f"âœ… ORICAåˆå§‹åŒ–å®Œæˆ: n_components={self.n_components}, æ•°æ®å½¢çŠ¶={X_init.shape}")
        except Exception as e:
            print(f"âš ï¸ ORICAåˆå§‹åŒ–å¤±è´¥: {e}")
            self.whitened = False
        
        return X_init

    def partial_fit(self, x_t):
        """
        å•ä¸ªæ ·æœ¬åœ¨çº¿æ›´æ–°
        
        Args:
            x_t: å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ® (n_channels,)
        """
        try:
            x_t = x_t.reshape(-1, 1)# ä» (25,) å˜ä¸º (25, 1)
            if not self.whitened:
                raise ValueError("Must call `initialize` with initial batch before `partial_fit`.")
            
            # æ£€æŸ¥è¾“å…¥ç»´åº¦æ˜¯å¦ä¸å½“å‰æ¨¡å‹åŒ¹é…
            if x_t.shape[0] != self.n_components:
                print(f"âš ï¸ partial_fitç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{x_t.shape[0]}é€šé“")
                # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
                self.n_components = x_t.shape[0]
                self.W = np.eye(self.n_components)
                # é‡æ–°åˆå§‹åŒ–ç™½åŒ–
                if self.use_rls_whitening:
                    self.C = np.eye(self.n_components)
                    self.whitening_matrix = np.eye(self.n_components)
                    self.t = 0
                else:
                    self.whitening_matrix = np.eye(self.n_components)
                print(f"âœ… é‡æ–°åˆå§‹åŒ–ORICAï¼Œæ–°ç»´åº¦: {self.n_components}")
            
            # å»å‡å€¼
            if self.mean is not None and self.mean.shape[0] == x_t.shape[0]:
                x_t = x_t - self.mean.reshape(-1, 1)
            else:
                # å¦‚æœmeanç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—
                print(f"âš ï¸ å‡å€¼ç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—")
                self.mean = np.zeros(x_t.shape[0])
            
            # ç™½åŒ–
            if self.use_rls_whitening:
                # RLSç™½åŒ–æ›´æ–°
                x_t_whitened = self._rls_whiten_update(x_t)
            else:
                # ä¼ ç»Ÿç™½åŒ–
                x_t_whitened = self.whitening_matrix @ x_t
            
            # ICAæ›´æ–°
            y_t = self.W @ x_t_whitened
            g_y, _ = self._g(y_t)
            
            # ORICAæ›´æ–°è§„åˆ™
            I = np.eye(self.n_components)
            delta_W = self.learning_rate * ((I - g_y @ y_t.T) @ self.W)
            self.W += delta_W

            # æ­£äº¤åŒ–
            self.update_count += 1
            if self.update_count % self.ortho_every == 0:
                U, _, Vt = np.linalg.svd(self.W)
                self.W = U @ Vt

            return y_t.ravel()
        except Exception as e:
            print(f"âš ï¸ partial_fitå¤±è´¥: {e}")
            return x_t.ravel() if hasattr(x_t, 'ravel') else x_t



    def fit_online_stream(self, data_stream, block_size=None):
        """
        åœ¨çº¿æµå¤„ç† - ä½¿ç”¨é€æ ·æœ¬æ›´æ–°è€Œéæ‰¹é‡å¤„ç†
        
        Args:
            data_stream: æ•°æ®æµ (samples, channels)
            block_size: å—å¤§å°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
        """
        try:
            if block_size is None:
                block_size = self.block_size_ica
            
        # æ£€æŸ¥æ•°æ®é•¿åº¦
            if data_stream.shape[0] < 1 or data_stream.shape[1] < 1:
                print(f"âš ï¸ æ•°æ®æµé•¿åº¦ä¸è¶³: {data_stream.shape}ï¼Œè¿”å›åŸå§‹æ•°æ®")
                return data_stream
            

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–
            if not self.whitened or self.whitening_matrix is None:
                print("âš ï¸ ORICAæœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–...")
                # ä½¿ç”¨å‰å‡ ä¸ªæ ·æœ¬è¿›è¡Œåˆå§‹åŒ–
                init_samples = min(block_size*2, data_stream.shape[0])
                if init_samples >= 2:
                    init_data = data_stream[:init_samples, :]
                    self.initialize(init_data)
                else:
                    print("âš ï¸ åˆå§‹åŒ–æ•°æ®ä¸è¶³ï¼Œè¿”å›åŸå§‹æ•°æ®")
                    return data_stream
            
            # ä½¿ç”¨é€æ ·æœ¬çš„æ–¹å¼å¤„ç†æ•°æ®æµï¼Œå°±åƒpartial_fitä¸€æ ·
            sources = []

            for i in range(data_stream.shape[0]):
                x_t = data_stream[i, :]  # è·å–å•ä¸ªæ ·æœ¬ (n_channels,)
                y_t = self.partial_fit(x_t)  # è¿›è¡Œåœ¨çº¿å­¦ä¹ å¹¶è¿”å›æºä¿¡å·
                sources.append(y_t)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è½¬ç½®ä»¥åŒ¹é…æœŸæœ›çš„è¾“å‡ºæ ¼å¼
            sources = np.array(sources)  # shape: (samples, components)
            # è½¬ç½®ä»¥åŒ¹é…partial_fitæ–¹å¼çš„è¾“å‡ºæ ¼å¼: (components, samples)
            sources = sources.T  # shape: (components, samples)
            return sources
                
        except Exception as e:
            print(f"âš ï¸ fit_online_streamå¤±è´¥: {e}")
            return data_stream




    def transform(self, X):
        """å˜æ¢æ•°æ®"""
        try:
            if not self.whitened:
                raise ValueError("Model must be initialized first with `initialize()`.")
            
            # æ£€æŸ¥æ•°æ®é•¿åº¦
            if X.shape[0] < 1:
                print(f"âš ï¸ å˜æ¢æ•°æ®é•¿åº¦ä¸è¶³: {X.shape[0]}")
                return X
            
            # æ£€æŸ¥ç»´åº¦åŒ¹é…
            if self.mean is not None and self.mean.shape[0] != X.shape[1]:
                print(f"âš ï¸ å‡å€¼ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{X.shape[1]}ï¼Œå®é™…{self.mean.shape[0]}")
                # é‡æ–°è®¡ç®—å‡å€¼
                self.mean = np.mean(X, axis=0)
            
            # å»å‡å€¼
            if self.mean is not None:
                X = X - self.mean
            
            # ç™½åŒ–
            if self.use_rls_whitening:
                # ä½¿ç”¨å½“å‰çš„ç™½åŒ–çŸ©é˜µ
                X_whitened = X @ self.whitening_matrix.T
            else:
                # ä¼ ç»Ÿç™½åŒ–
                X_whitened = X @ self.whitening_matrix.T
            
            # ICAå˜æ¢
            Y = (self.W @ X_whitened.T).T
            return Y
        except Exception as e:
            print(f"âš ï¸ transformå¤±è´¥: {e}")
            return X

    def inverse_transform(self, Y):
        """é€†å˜æ¢"""
        Xw = np.linalg.pinv(self.W) @ Y.T
        X = Xw.T @ np.linalg.pinv(self.whitening_matrix).T + self.mean
        return X

    def get_W(self):
        """è·å–è§£æ··çŸ©é˜µ"""
        return self.W

    def get_whitening_matrix(self):
        """è·å–ç™½åŒ–çŸ©é˜µ"""
        return self.whitening_matrix

    def evaluate_separation(self, Y):
        """è¯„ä¼°åˆ†ç¦»æ•ˆæœ - ä½¿ç”¨å³°åº¦"""
        k = kurtosis(Y, axis=0, fisher=False)
        return k

    def rank_components_by_kurtosis(self, Y):
        """æŒ‰å³°åº¦æ’åºæˆåˆ†"""
        k = self.evaluate_separation(Y)
        indices = np.argsort(-np.abs(k))
        return indices, k

    def calc_mutual_info_matrix(self, sources):
        """è®¡ç®—äº’ä¿¡æ¯çŸ©é˜µ"""
        n = sources.shape[0]
        MI = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if i != j:
                    MI[i, j] = mutual_info_regression(
                        sources[i, :].reshape(-1, 1), sources[j, :]
                    )[0]
        return MI

    def set_nonlinearity(self, nonlinearity):
        """è®¾ç½®éçº¿æ€§å‡½æ•°ç±»å‹"""
        if nonlinearity not in ['gaussian', 'tanh']:
            raise ValueError("nonlinearity must be 'gaussian' or 'tanh'")
        self.nonlinearity = nonlinearity

    def set_forgetting_factor(self, forgetting_factor):
        """è®¾ç½®RLSé—å¿˜å› å­"""
        if not (0 < forgetting_factor < 1):
            raise ValueError("forgetting_factor must be between 0 and 1")
        self.forgetting_factor = forgetting_factor

    def _dynamic_whitening(self, block_data):
        """åŠ¨æ€ç™½åŒ– - å¯¹åº”MATLABçš„dynamicWhitening"""
        n_pts = block_data.shape[1]
        
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if n_pts < 2:
            print(f"âš ï¸ ç™½åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {n_pts}ï¼Œè·³è¿‡ç™½åŒ–æ›´æ–°")
            return
        
        # å®šä¹‰è‡ªé€‚åº”é—å¿˜ç‡
        if self.ff_profile == 'cooling':
            lambda_vals = self._gen_cooling_ff(self.counter + np.arange(1, n_pts + 1))
            if lambda_vals[0] < self.lambda_const:
                lambda_vals = np.full(n_pts, self.lambda_const)
        elif self.ff_profile == 'constant':
            lambda_vals = np.full(n_pts, self.lambda_const)
        elif self.ff_profile == 'adaptive':
            lambda_vals = np.full(n_pts, self.lambda_k[-1] if len(self.lambda_k) > 0 else self.lambda_const)
        
        # ä½¿ç”¨åœ¨çº¿RLSç™½åŒ–å—æ›´æ–°è§„åˆ™æ›´æ–°çƒåŒ–çŸ©é˜µ
        v = self.whitening_matrix @ block_data  # é¢„ç™½åŒ–æ•°æ®
        lambda_avg = 1 - lambda_vals[n_pts // 2]  # ä¸­ä½æ•°lambda
        Q_white = lambda_avg / (1 - lambda_avg) + np.trace(v.T @ v) / n_pts
        self.whitening_matrix = (1 / lambda_avg) * (self.whitening_matrix - 
                                                   v @ v.T / n_pts / Q_white @ self.whitening_matrix)

    def _dynamic_orica(self, block_data):
        """åŠ¨æ€ORICA - å¯¹åº”MATLABçš„dynamicOrica"""
        n_chs, n_pts = block_data.shape
        
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if n_pts < 2:
            print(f"âš ï¸ ORICAæ•°æ®é•¿åº¦ä¸è¶³: {n_pts}ï¼Œè·³è¿‡ORICAæ›´æ–°")
            return
        
        f = np.zeros((n_chs, n_pts))
        
        # ä½¿ç”¨å…ˆå‰çš„æƒé‡çŸ©é˜µè®¡ç®—æºæ¿€æ´»
        y = self.W @ block_data
        
        # ä¸ºè¶…é«˜æ–¯å’Œæ¬¡é«˜æ–¯é€‰æ‹©éçº¿æ€§å‡½æ•°
        f[self.kurtosis_sign, :] = -2 * np.tanh(y[self.kurtosis_sign, :])  # è¶…é«˜æ–¯
        f[~self.kurtosis_sign, :] = 2 * np.tanh(y[~self.kurtosis_sign, :])  # æ¬¡é«˜æ–¯
        
        # è®¡ç®—éå¹³ç¨³æ€§æŒ‡æ•°å’ŒæºåŠ¨æ€æ–¹å·®
        if self.eval_convergence:
            model_fitness = np.eye(n_chs) + y @ f.T / n_pts
            variance = block_data * block_data
            if self.Rn is None:
                self.Rn = model_fitness
            else:
                self.Rn = (1 - self.leaky_avg_delta) * self.Rn + self.leaky_avg_delta * model_fitness
            self.non_stat_idx = np.linalg.norm(self.Rn, 'fro')
        
        # è®¡ç®—é—å¿˜ç‡
        data_range = np.arange(1, n_pts + 1)
        if self.ff_profile == 'cooling':
            self.lambda_k = self._gen_cooling_ff(self.counter + data_range)
            if len(self.lambda_k) > 0 and self.lambda_k[0] < self.lambda_const:
                self.lambda_k = np.full(n_pts, self.lambda_const)
            self.counter += n_pts
        elif self.ff_profile == 'constant':
            self.lambda_k = np.full(n_pts, self.lambda_const)
        elif self.ff_profile == 'adaptive':
            if self.min_non_stat_idx is None:
                self.min_non_stat_idx = self.non_stat_idx
            self.min_non_stat_idx = max(min(self.min_non_stat_idx, self.non_stat_idx), 1)
            ratio_of_norm_rn = self.non_stat_idx / self.min_non_stat_idx
            self.lambda_k = self._gen_adaptive_ff(data_range, ratio_of_norm_rn)
        
        # ä½¿ç”¨åœ¨çº¿é€’å½’ICAå—æ›´æ–°è§„åˆ™æ›´æ–°æƒé‡çŸ©é˜µ
        lambda_prod = np.prod(1.0 / (1.0 - self.lambda_k))
        Q = 1 + self.lambda_k * (np.sum(f * y, axis=0) - 1)
        self.W = lambda_prod * (self.W - y @ np.diag(self.lambda_k / Q) @ f.T @ self.W)
        
        # æ­£äº¤åŒ–æƒé‡çŸ©é˜µ
        eigenvals, eigenvecs = np.linalg.eigh(self.W @ self.W.T)
        self.W = eigenvecs @ np.diag(1/np.sqrt(eigenvals)) @ eigenvecs.T @ self.W

    def fit_block(self, data, num_passes=1):
        """
        å—æ›´æ–°æ‹Ÿåˆ - å¯¹åº”MATLAB orica.mçš„ä¸»è¦é€»è¾‘
        
        Args:
            data: è¾“å…¥æ•°æ® (channels, samples)
            num_passes: æ•°æ®éå†æ¬¡æ•°
        """
        n_chs, n_pts = data.shape
        
        if self.verbose:
            print(f"ä½¿ç”¨{'åœ¨çº¿' if self.use_rls_whitening else 'ç¦»çº¿'}ç™½åŒ–æ–¹æ³•")
            print(f"è¿è¡ŒORICAï¼Œé—å¿˜å› å­ç­–ç•¥: {self.ff_profile}")
        
        # åˆå§‹åŒ–ç™½åŒ–
        if not self.use_rls_whitening:
            if self.verbose:
                print("ä½¿ç”¨é¢„ç™½åŒ–æ–¹æ³•")
            # é¢„ç™½åŒ–
            cov_matrix = np.cov(data.T)
            self.whitening_matrix = 2.0 * np.linalg.inv(np.sqrtm(cov_matrix))
        
        # ç™½åŒ–æ•°æ®
        data = self.whitening_matrix @ data
        
        # å°†æ•°æ®åˆ†æˆå—è¿›è¡Œåœ¨çº¿å—æ›´æ–°
        min_block_size = min(self.block_size_ica, self.block_size_white)
        num_blocks = n_pts // min_block_size
        
        if self.verbose:
            import time
            start_time = time.time()
        
        for it in range(num_passes):
            for bi in range(num_blocks):
                # è®¡ç®—æ•°æ®èŒƒå›´
                start_idx = bi * n_pts // num_blocks
                end_idx = min(n_pts, (bi + 1) * n_pts // num_blocks)
                data_range = slice(start_idx, end_idx)
                block_data = data[:, data_range]
                
                # åœ¨çº¿ç™½åŒ–
                if self.use_rls_whitening:
                    self._dynamic_whitening(block_data)
                    block_data = self.whitening_matrix @ block_data
                
                # åŠ¨æ€ORICA
                self._dynamic_orica(block_data)
                
                if self.verbose and bi % (num_blocks // 10) == 0:
                    progress = (it * num_blocks + bi) / (num_passes * num_blocks) * 100
                    print(f" è¿›åº¦: {progress:.0f}%")
        
        if self.verbose:
            elapsed_time = time.time() - start_time
            print(f"å®Œæˆã€‚è€—æ—¶: {elapsed_time:.2f} ç§’")
        
        return self.W, self.whitening_matrix
