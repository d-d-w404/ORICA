import threading
import time
import numpy as np
from scipy.signal import welch
from pylsl import StreamInlet, resolve_byprop
import numpy as np
from filter_utils import EEGSignalProcessor

from filter_utils_fir import example_usage
from pylsl import resolve_streams
from orica_processor import ORICAProcessor
from asrpy import ASR
import mne
from scipy.signal import medfilt
from meegkit import asr
import scipy.io


from mne.filter import filter_data
from FirFilter import rest_fir_filter
#this class to some extent is like a container which includs all of the paraments(orica, icalabel)
class LSLStreamReceiver:
    def __init__(self, stream_type='EEG', time_range=5, stream_name='mybrain'):
        # inoput LSL stream info
        self.stream_type = stream_type
        self.stream_name = stream_name
        self.inlet = None
        self.srate = None
        self.nbchan = None
        self.chan_labels = []
        self.chan_range = []
        self.channel_manager=None

        # buffer 
        self.time_range = time_range #control the buffer size by sec
        self.raw_buffer = None  
        self.buffer = None
        self.pair_buffer = None

        # chunk (currently I use chunk for vis, because it's more small than buffer, making the vis smooth)
        # chunk size is not a fixed value
        self.last_unclean_chunk = None  # this chunk currently only used for vis(before orica)
        self.last_processed_chunk = None  #this chunk currently only used for vis(after orica)
        self.chunk_pairs = []  # conbining two chunk above

        #IIR
        self.cutoff = (1, 50)

        # ASR
        self.use_asr = False
        self.asr_filter = None
        # values for online asr calibration
        self.asr_calibration_data = None 
        self.asr_calibration_size = 0

        #ORICA
        self.orica = None
        self.latest_sources = None

        #ICLabel
        self.latest_ic_probs = None
        self.latest_ic_labels = None
        self.latest_eog_indices = None
        
        # ç®€å•çš„10ç§’æ•°æ®æ”¶é›†
        self.calibration_data = None
        self.calibration_size = 0
        self.calibration_duration = 10  # 10ç§’
        self.calibration_collected = False
        


        #å½“æˆ‘åœ¨åˆ‡æ¢é€šé“çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè®©icçš„ä¸ªæ•°å‘ç”Ÿæ”¹å˜ï¼Œä½†æ˜¯æ­¤æ—¶bufferè¿˜åœ¨è¿è¡Œï¼Œä¼šå¯¼è‡´å¡æ­»ï¼Œ
        #æ‰€ä»¥æˆ‘éœ€è¦æŠŠé€šé“åˆ‡æ¢è¿‡ç¨‹é”ä½
        self.lock = threading.Lock()
        
        # âœ… æ–°å¢ï¼šæ•°æ®æ›´æ–°çº¿ç¨‹æ§åˆ¶
        self.data_update_thread = None
        self.is_running = False
        self.update_interval = 0.1  # 100msæ›´æ–°é—´éš”




    def find_and_open_stream(self):
        # ========================1) check all available streams===============================
        streams = resolve_streams()
        print("Current available LSL streams:")
        for i, stream in enumerate(streams):
            print(
                f"[{i}] Name: {stream.name()}, Type: {stream.type()}, Channels: {stream.channel_count()}, ID: {stream.source_id()}")
        print(f"Searching for LSL stream with type = '{self.stream_type}'...")

        # ========================2) select the stream by type or name===============================
        '''
        # useing the stream_type to filter the stream, 
        # but sometimes there are serveral streams with the same type, 
        # so we need to use the stream_name to filter the stream

        '''
        #streams = resolve_byprop('type', self.stream_type, timeout=5)
        # using the stream_name to filter the stream
        streams = resolve_byprop('name', self.stream_name, timeout=60)

        if not streams:
            raise RuntimeError(f"No LSL stream with type '{self.stream_type}' and name '{self.stream_name}' found.")


        # ========================3)generate basic info of the stream===============================
        self.inlet = StreamInlet(streams[0])
        info = self.inlet.info()
        self.channel_manager = ChannelManager(info)
        self.srate = int(info.nominal_srate())
        self.nbchan = info.channel_count()

        # remove some of the useless or broken channels
        #exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','ACC','Oz','PO8',"F7","T8",'FC5','F8']#,'F7','F8'
        exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','ACC']#,'F7','F8'
        self.chan_labels = self.channel_manager.get_labels_excluding_keywords(exclude)
        self.chan_range = self.channel_manager.get_indices_excluding_keywords(exclude)
        self.nbchan = len(self.chan_range)

        # 4) buffer for visualization
        self.buffer = np.zeros((info.channel_count(), self.srate * self.time_range))
        self.raw_buffer = np.zeros((info.channel_count(), self.srate * self.time_range))

        #buffer for asr calibration
        #self.asr_calibration_data = np.zeros((info.channel_count(), self.srate * 40))
        self.asr_calibration_data = np.zeros((len(self.chan_range), self.srate * 40))
        
        # åˆå§‹åŒ–10ç§’æ ¡å‡†æ•°æ®ç¼“å†²åŒº
        self.calibration_data = np.zeros((len(self.chan_range), self.srate * self.calibration_duration))

        print(f"Stream opened: {info.channel_count()} channels at {self.srate} Hz")
        print(f"Using {self.nbchan} EEG channels: {self.chan_labels}")

        # ========================5) init ORICA===============================
        self.reinitialize_orica()


    #input chunk, return modeify chunk and sources , artifact index
    def process_orica(self, chunk):
        """
        use the orica_processor.py to modify the chunk data
        """
        cleaned_chunk = chunk.copy()
        if self.orica is not None:
            if self.orica.update_buffer(chunk[self.chan_range, :]):
                sources, eog_indices, ic_probs, ic_labels= self.orica.fit(self.orica.data_buffer, self.chan_range, self.chan_labels, self.srate)
                if sources is not None:
                    cleaned = self.orica.transform(chunk[self.chan_range, :])
                    cleaned_chunk[self.chan_range, :] = cleaned  
                    self.latest_ic_probs = ic_probs
                    self.latest_ic_labels = ic_labels       
                    
        return cleaned_chunk, sources, eog_indices

    def pull_and_update_buffer(self):
        # ========================1) pull data from the stream===============================
        # this samples_random mean the number of samples is random, which depends on the system situation(no control)
        # this timestamps are the time of every random samples
        samples_random, timestamps = self.inlet.pull_chunk(timeout=0.0)
        #samples, timestamps = self.inlet.pull_chunk(max_samples=100, timeout=0.0)#

        # check if there is data
        if not timestamps:
            return
            
        # convert samples_random to the correct format (channels, samples)
        samples_random = np.array(samples_random).T
        samples=samples_random


        # ========================2) process the data===============================
        '''
        timestampes sometime is (0,), which means there is no data, the if will not execute.
        timestampes sometime is (samples_size,0), which means there is data, the if will execute.
        '''
        if timestamps:
            chunk = np.array(samples)  # shape: (channels, samples)samples size is not a fixed value

            raw_chunk = chunk.copy()
            raw_chunk = raw_chunk[self.chan_range, :]

            # # ç®€å•çš„10ç§’æ•°æ®æ”¶é›†
            # if not self.calibration_collected:
            #     self._collect_10s_data(raw_chunk)
            #     return  # æ”¶é›†æœŸé—´è·³è¿‡åç»­å¤„ç†

            # Step 1: Apply Common Average Reference (CAR)
            #chunk = self.apply_car_rereference(chunk)
            
            # Step 2: use the professional FIR filter from MNE
            chunk = self.apply_mne_iir_filter(chunk)
   


            #step 2: ASR with offline calibration
            #asr calibration
            if self.asr_filter is None:
                self.initialize_asr_from_mat()
            # asr usage
            if self.asr_filter is not None:
                chunk = self.asr_filter.transform(chunk)




                

            # Step 3: ORICA artifact removal
            # update chunk for visualization before ORICA
            self.last_unclean_chunk = chunk.copy()

            # update buffer before ORICA
            if self.raw_buffer is not None:
                self.raw_buffer = np.roll(self.raw_buffer, -chunk.shape[1], axis=1)
                self.raw_buffer[:, -chunk.shape[1]:] = self.last_unclean_chunk


            # ORICA processing
            chunk, ica_sources, eog_indices = self.process_orica(chunk)
            if ica_sources is not None:
                self.latest_sources = ica_sources
            if eog_indices is not None:
                self.latest_eog_indices = eog_indices

            #ASR with online calibration
            if not self.use_asr:
                # å¦‚æœæ­£åœ¨è¿›è¡Œåœ¨çº¿æ ¡å‡†ï¼Œæ”¶é›†æ•°æ®
                if self.asr_calibration_size < self.srate * 40:
                    print("collecting asr data")
                    if self.asr_calibration_data is not None:
                        self.asr_calibration_data = np.roll(self.asr_calibration_data, -raw_chunk.shape[1], axis=1)
                        self.asr_calibration_data[:, -raw_chunk.shape[1]:] = raw_chunk
                        self.asr_calibration_size += raw_chunk.shape[1]
                # å¦‚æœASRå·²æ ¡å‡†ä¸”å¯ç”¨ï¼Œåˆ™ä½¿ç”¨ASRå¤„ç†
                elif self.asr_calibration_size >= self.srate * 40:
                    print("init asr")
                    self.initialize_asr_online(self.asr_calibration_data)
                    self.use_asr = True
            elif self.use_asr:
                print("using asr")
                chunk[self.chan_range, :] = self.asr_filter.transform(chunk[self.chan_range, :])


            # update chunk for visualization after ORICA
            self.last_processed_chunk = chunk.copy()
            
            
            # update buffer after ORICA
            num_new = chunk.shape[1]
            self.buffer = np.roll(self.buffer, -num_new, axis=1)
            self.buffer[:, -num_new:] = chunk


            #Step 4: update chunk pairs for visualization
            # this step is used for keeping the vis looks synced
            # becasue the ORICA takes some time which would cause the data before and after ORICA looks not synced
            timestamp = time.time()
            self.chunk_pairs.append((timestamp, self.last_unclean_chunk, self.last_processed_chunk))
            if len(self.chunk_pairs) > 1:
                self.chunk_pairs.pop(0)
            self.pair_buffer = (self.raw_buffer, self.buffer)



    


    #Selected channel indices: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]
    #Selected channel labels: ['AF7', 'Fpz', 'F7', 'Fz', 'T7', 'FC6', 'F4', 'C4', 'Oz', 'CP6', 'Cz', 'PO8', 'CP5', 'O2', 'O1', 'P3', 'P4', 'P7', 'P8', 'Pz', 'PO7', 'T8', 'C3', 'Fp2', 'F3', 'F8', 'FC5', 'AF8']
    #ä¸Šé¢å°±æ˜¯channel_rangeå’Œchannel_labelsçš„æ ¼å¼ï¼Œè¦è°ƒç”¨å‡½æ•°å°±ä¼ å…¥è¿™æ ·çš„list
    #channel_selector.py use this function to update the channel range and labels
    def set_channel_range_and_labels(self, new_range, new_labels):
        with self.lock:
            self.chan_range = new_range
            self.chan_labels = new_labels
            self.nbchan = len(new_range)
            self.reinitialize_orica()
            print(f"channel range and labels updated: {self.chan_labels}")


    def reinitialize_orica(self):
        self.orica = ORICAProcessor(
            n_components=len(self.chan_range),
            srate=self.srate
        )
        print("ğŸ” ORICA processor re-initialized with new channel range.")
    
    def apply_car_rereference(self, data):
        """
        åº”ç”¨å¹³å‡å‚è€ƒ (Common Average Reference)
        
        Args:
            data: EEGæ•°æ® (channels, samples)
        
        Returns:
            é‡å‚è€ƒåçš„æ•°æ® (channels, samples) - é€šé“æ•°ä¸å˜
        """
        try:
            # è®¡ç®—æ‰€æœ‰é€šé“çš„å¹³å‡å€¼ä½œä¸ºå‚è€ƒ
            ref_signal = np.mean(data, axis=0, keepdims=True)
            # æ¯ä¸ªé€šé“å‡å»å‚è€ƒä¿¡å·
            reref_data = data - ref_signal
            print(f"âœ… CARé‡å‚è€ƒå®Œæˆ: {data.shape[0]} é€šé“")
            return reref_data
            
        except Exception as e:
            print(f"âŒ CARé‡å‚è€ƒå¤±è´¥: {e}")
            print("âš ï¸ è¿”å›åŸå§‹æ•°æ®")
            return data

    def apply_mne_iir_filter(self, data):
        try:     
            filtered_data = filter_data(
                data=data,
                sfreq=self.srate,
                l_freq=self.cutoff[0],      # low frequency cutoff
                h_freq=self.cutoff[1],      # high frequency cutoff
                method='iir',               # apply IIR filter
                iir_params={'order': 4, 'ftype': 'butter'},  # 4th order Butterworth
                verbose=False
            )
            print(f"âœ… MNE IIR filter finished: {self.cutoff[0]}-{self.cutoff[1]} Hz")
            return filtered_data
        except Exception as e:
            print(f"âŒ MNE IIR filter failed: {e}")
            print("âš ï¸ revert to original data")
            return data


    def _collect_10s_data(self, raw_chunk):
        """
        æ”¶é›†10ç§’æ•°æ®
        
        Args:
            raw_chunk: åŸå§‹æ•°æ®å— (channels, samples)
        """
        chunk_size = raw_chunk.shape[1]
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç©ºé—´å­˜å‚¨æ›´å¤šæ•°æ®
        if self.calibration_size + chunk_size <= self.calibration_data.shape[1]:
            # å°†æ–°æ•°æ®æ·»åŠ åˆ°æ ¡å‡†ç¼“å†²åŒº
            self.calibration_data[:, self.calibration_size:self.calibration_size + chunk_size] = raw_chunk
            self.calibration_size += chunk_size
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = self.calibration_size / (self.srate * self.calibration_duration)
            print(f"ğŸ“Š æ”¶é›†è¿›åº¦: {progress:.1%} ({self.calibration_size / self.srate:.1f}/{self.calibration_duration}ç§’)")
            
            # æ£€æŸ¥æ˜¯å¦æ”¶é›†å®Œæˆ
            if self.calibration_size >= self.srate * self.calibration_duration:
                print("âœ… 10ç§’æ•°æ®æ”¶é›†å®Œæˆï¼")
                self.calibration_collected = True
        else:
            print("âš ï¸ æ ¡å‡†æ•°æ®ç¼“å†²åŒºå·²æ»¡")

    def initialize_asr_from_mat(self, mat_file_path=r"D:\work\Python_Project\ORICA\temp_txt\cleaned_data_quick30.mat"):
        """
        ä» MATLAB æ–‡ä»¶åŠ è½½æ ¡å‡†æ•°æ®å¹¶åˆå§‹åŒ– ASRï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        
        Args:
            mat_file_path: æ ¡å‡†æ•°æ®çš„ .mat æ–‡ä»¶è·¯å¾„
        """
        if self.asr_filter is not None:
            print("â© ASR å·²æ ¡å‡†ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return self.asr_filter
        
        try:


            
            # åŠ è½½ MATLAB æ–‡ä»¶
            mat_data = scipy.io.loadmat(mat_file_path)
            
            # æå–æ ¡å‡†æ•°æ®ï¼ˆEEGLAB æ ¼å¼ï¼‰
            calibration_data = None
            if 'cleaned_data' in mat_data:
                eeg_struct = mat_data['cleaned_data'][0, 0]
                if 'data' in eeg_struct.dtype.names:
                    calibration_data = eeg_struct['data']
            elif 'data' in mat_data:
                calibration_data = mat_data['data']
            
            if calibration_data is None:
                print(f"âŒ æ— æ³•æå–æ ¡å‡†æ•°æ®ï¼Œå¯ç”¨å­—æ®µ: {mat_data.keys()}")
                return None
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ•°ç»„
            calibration_data = np.asarray(calibration_data, dtype=np.float64)
            print(f"âœ… æ ¡å‡†æ•°æ®åŠ è½½æˆåŠŸ - åŸå§‹å½¢çŠ¶: {calibration_data.shape}")
            
            # åªé€‰æ‹©å½“å‰ä½¿ç”¨çš„é€šé“
            if calibration_data.shape[0] != len(self.chan_range):
                print(f"âš ï¸ é€šé“æ•°ä¸åŒ¹é…ï¼šæ ¡å‡† {calibration_data.shape[0]} é€šé“ï¼Œåœ¨çº¿ {len(self.chan_range)} é€šé“")
                calibration_data = calibration_data[self.chan_range, :]
                print(f"âœ… å·²è°ƒæ•´æ ¡å‡†æ•°æ®å½¢çŠ¶: {calibration_data.shape}")
            
            # åˆå§‹åŒ–å¹¶æ‹Ÿåˆ ASR
            self.asr_filter = asr.ASR(
                sfreq=self.srate,
                cutoff=5,
            )
            self.asr_filter.fit(calibration_data)
            print(f"âœ… ASR å·²æ ¡å‡†å®Œæˆï¼Œé€šé“æ•°: {calibration_data.shape[0]}")
            
            return self.asr_filter
            
        except Exception as e:
            print(f"âŒ ASR åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def initialize_asr_online(self,calibration_data_raw):
        """
        ä» MATLAB æ–‡ä»¶åŠ è½½æ ¡å‡†æ•°æ®å¹¶åˆå§‹åŒ– ASRï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        
        Args:
            mat_file_path: æ ¡å‡†æ•°æ®çš„ .mat æ–‡ä»¶è·¯å¾„
        """
        if self.asr_filter is not None:
            print("â© ASR å·²æ ¡å‡†ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return self.asr_filter
        
        try:


            
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ•°ç»„
            print("will get in")
            calibration_data = np.asarray(calibration_data_raw, dtype=np.float64)
            print(f"âœ… æ ¡å‡†æ•°æ®åŠ è½½æˆåŠŸ - åŸå§‹å½¢çŠ¶: {calibration_data.shape}")
            
            # åªé€‰æ‹©å½“å‰ä½¿ç”¨çš„é€šé“
            if calibration_data.shape[0] != len(self.chan_range):
                print(f"âš ï¸ é€šé“æ•°ä¸åŒ¹é…ï¼šæ ¡å‡† {calibration_data.shape[0]} é€šé“ï¼Œåœ¨çº¿ {len(self.chan_range)} é€šé“")
                calibration_data = calibration_data[self.chan_range, :]
                print(f"âœ… å·²è°ƒæ•´æ ¡å‡†æ•°æ®å½¢çŠ¶: {calibration_data.shape}")
            
            # åˆå§‹åŒ–å¹¶æ‹Ÿåˆ ASR
            self.asr_filter = asr.ASR(
                sfreq=self.srate,
                cutoff=5,
            )
            self.asr_filter.fit(calibration_data)
            print(f"âœ… ASR å·²æ ¡å‡†å®Œæˆï¼Œé€šé“æ•°: {calibration_data.shape[0]}")
            
            return self.asr_filter
            
        except Exception as e:
            print(f"âŒ ASR åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


    def start(self):
        """å¯åŠ¨æ•°æ®æµå’Œæ•°æ®æ›´æ–°çº¿ç¨‹"""
        if hasattr(self, 'is_running') and self.is_running:
            print("âš ï¸ æ•°æ®æµå·²åœ¨è¿è¡Œ")
            return
        self.find_and_open_stream()
        self.is_running = True
        self.data_update_thread = threading.Thread(target=self._data_update_loop, daemon=True)
        self.data_update_thread.start()
        print("âœ… æ•°æ®æµå’Œæ•°æ®æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢æ•°æ®æ›´æ–°çº¿ç¨‹"""
        self.is_running = False
        if hasattr(self, 'data_update_thread') and self.data_update_thread and self.data_update_thread.is_alive():
            self.data_update_thread.join(timeout=1.0)
        print("ğŸ›‘ æ•°æ®æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def _data_update_loop(self):
        """æ•°æ®æ›´æ–°å¾ªç¯ - åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ"""
        while self.is_running:
            try:
                self.pull_and_update_buffer()
                time.sleep(self.update_interval)
            except Exception as e:
                print(f"âŒ æ•°æ®æ›´æ–°é”™è¯¯: {e}")
                time.sleep(0.1)  # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…

    # âœ… æ–°å¢ï¼šæ•°æ®æ¥å£æ–¹æ³•
    def get_raw_data(self):
        """è·å–æœ€æ–°çš„åŸå§‹æ•°æ®ï¼ˆä»…å¸¦é€šæ»¤æ³¢ï¼‰"""
        return self.last_unclean_chunk.copy() if self.last_unclean_chunk is not None else None
    
    def get_processed_data(self):
        """è·å–æœ€æ–°çš„å¤„ç†åæ•°æ®ï¼ˆORICA + ASRï¼‰"""
        return self.last_processed_chunk.copy() if self.last_processed_chunk is not None else None

    def get_pair_data(self):
        return self.pair_buffer[0][self.chan_range, :], self.pair_buffer[1][self.chan_range, :] if self.pair_buffer is not None else None

    def get_pair_data_old(self, data_type='processed'):
        if data_type == 'raw':
            return self.chunk_pairs.copy()[0][1][self.chan_range, :] if self.chunk_pairs is not None else None
        else:
            return self.chunk_pairs.copy()[0][2][self.chan_range, :] if self.chunk_pairs is not None else None
        #return self.chunk_pairs.copy() if self.chunk_pairs is not None else None
    
    def get_buffer_data(self, data_type='processed'):
        """
        this function is used for the visualization
        Args:
            data_type: 'raw' or 'processed'
        """
        if data_type == 'raw':
            return self.raw_buffer[self.chan_range, :] if self.raw_buffer is not None else None
        else:
            return self.buffer[self.chan_range, :] if self.buffer is not None else None
    
    
    def get_ica_sources(self):
        """è·å–æœ€æ–°çš„ICAæºä¿¡å·"""
        return self.latest_sources.copy() if self.latest_sources is not None else None
    
    def get_eog_indices(self):
        """è·å–EOGä¼ªå½±æˆåˆ†ç´¢å¼•"""
        return self.latest_eog_indices.copy() if self.latest_eog_indices is not None else None
    
    def get_channel_info(self):
        """è·å–é€šé“ä¿¡æ¯"""
        return {
            'labels': self.chan_labels.copy() if self.chan_labels else [],
            'indices': self.chan_range.copy() if self.chan_range else [],
            'count': len(self.chan_range) if self.chan_range else 0,
            'sampling_rate': self.srate
        }
    
    def is_data_available(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•°æ®"""
        return (self.last_unclean_chunk is not None and 
                self.last_processed_chunk is not None and 
                self.buffer is not None)
    
    def get_calibration_data(self):
        """è·å–æ”¶é›†åˆ°çš„10ç§’æ ¡å‡†æ•°æ®"""
        if self.calibration_collected:
            return self.calibration_data[:, :self.calibration_size].copy()
        return None
    
    def is_calibration_completed(self):
        """æ£€æŸ¥10ç§’æ•°æ®æ”¶é›†æ˜¯å¦å®Œæˆ"""
        return self.calibration_collected
    
    def process_calibration_data(self):
        """
        å¯¹æ”¶é›†åˆ°çš„10ç§’æ•°æ®ä¾æ¬¡æ‰§è¡ŒIIRã€CARã€ASRã€ORICAå¤„ç†
        è¿”å›æ¯ä¸€æ­¥å¤„ç†åçš„æ•°æ®å’Œæœ€ç»ˆçš„icaweightã€icasphere
        """
        if not self.calibration_collected:
            print("âŒ æ ¡å‡†æ•°æ®æ”¶é›†æœªå®Œæˆï¼Œæ— æ³•å¤„ç†")
            return None
        
        try:
            print("ğŸ”„ å¼€å§‹å¤„ç†10ç§’æ ¡å‡†æ•°æ®...")
            
            # è·å–æ”¶é›†åˆ°çš„åŸå§‹æ•°æ®
            raw_data = self.calibration_data[:, :self.calibration_size]
            print(f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: {raw_data.shape}")
            
            # Step 1: CAR (Common Average Reference)
            print("ğŸ”„ æ‰§è¡ŒCARé‡å‚è€ƒ...")
            car_data = self.apply_car_rereference(raw_data)
            print(f"âœ… CARå®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {car_data.shape}")
            
            # Step 2: IIRæ»¤æ³¢
            print("ğŸ”„ æ‰§è¡ŒIIRæ»¤æ³¢...")
            iir_data = self.apply_mne_iir_filter(car_data)
            print(f"âœ… IIRæ»¤æ³¢å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {iir_data.shape}")
            
            # Step 3: ASRå¤„ç†
            print("ğŸ”„ æ‰§è¡ŒASRå¤„ç†...")
            asr_data = self._apply_asr_to_calibration_data(iir_data)
            print(f"âœ… ASRå¤„ç†å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {asr_data.shape}")
            
            # Step 4: ORICAå¤„ç†
            print("ğŸ”„ æ‰§è¡ŒORICAå¤„ç†...")
            orica_results = self._apply_orica_to_calibration_data(asr_data)
            
            if orica_results is not None:
                ica_weight, ica_sphere, sources, eog_indices = orica_results
                print(f"âœ… ORICAå¤„ç†å®Œæˆ")
                print(f"ğŸ“Š ICA Weightå½¢çŠ¶: {ica_weight.shape}")
                print(f"ğŸ“Š ICA Sphereå½¢çŠ¶: {ica_sphere.shape}")
                print(f"ğŸ“Š æºä¿¡å·å½¢çŠ¶: {sources.shape}")
                print(f"ğŸ“Š è¯†åˆ«åˆ° {len(eog_indices) if eog_indices else 0} ä¸ªä¼ªå½±æˆåˆ†")
                
                # è¿”å›æ‰€æœ‰å¤„ç†ç»“æœ
                return {
                    'raw_data': raw_data,
                    'car_data': car_data,
                    'iir_data': iir_data,
                    'asr_data': asr_data,
                    'ica_weight': ica_weight,
                    'ica_sphere': ica_sphere,
                    'sources': sources,
                    'eog_indices': eog_indices
                }
            else:
                print("âŒ ORICAå¤„ç†å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ æ ¡å‡†æ•°æ®å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _apply_asr_to_calibration_data(self, iir_data):
        """
        å¯¹IIRæ»¤æ³¢åçš„æ•°æ®åº”ç”¨ASRå¤„ç†
        
        Args:
            iir_data: IIRæ»¤æ³¢åçš„æ•°æ® (channels, samples)
        
        Returns:
            asr_data: ASRå¤„ç†åçš„æ•°æ® (channels, samples)
        """
        try:
            # åˆ›å»ºASRæ»¤æ³¢å™¨
            asr_filter = asr.ASR(
                sfreq=self.srate,
                cutoff=5,
            )
            
            # ä½¿ç”¨IIRæ•°æ®æ‹ŸåˆASR
            asr_filter.fit(iir_data)
            
            # åº”ç”¨ASRå¤„ç†
            asr_data = asr_filter.transform(iir_data)
            
            return asr_data
            
        except Exception as e:
            print(f"âŒ ASRå¤„ç†å¤±è´¥: {e}")
            return iir_data  # å¦‚æœASRå¤±è´¥ï¼Œè¿”å›åŸå§‹IIRæ•°æ®
    
    def _apply_orica_to_calibration_data(self, asr_data):
        """
        å¯¹ASRå¤„ç†åçš„æ•°æ®åº”ç”¨ORICAå¤„ç†
        
        Args:
            asr_data: ASRå¤„ç†åçš„æ•°æ® (channels, samples)
        
        Returns:
            tuple: (ica_weight, ica_sphere, sources, eog_indices) æˆ– None
        """
        try:
            # åˆ›å»ºä¸´æ—¶ORICAå¤„ç†å™¨
            temp_orica = ORICAProcessor(
                n_components=len(self.chan_range),
                srate=self.srate
            )
            
            # æ‰§è¡ŒORICAæ‹Ÿåˆ
            sources, eog_indices, ic_probs, ic_labels = temp_orica.fit(
                asr_data, self.chan_range, self.chan_labels, self.srate
            )
            
            if sources is not None and temp_orica.ica is not None:
                # è·å–ICA weightå’Œsphereå‚æ•°
                ica_weight = temp_orica.ica.get_W()
                ica_sphere = temp_orica.ica.get_sphere()
                
                return ica_weight, ica_sphere, sources, eog_indices
            else:
                print("âš ï¸ ORICAæœªäº§ç”Ÿæœ‰æ•ˆç»“æœ")
                return None
                
        except Exception as e:
            print(f"âŒ ORICAå¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    

    def print_latest_channel_values(self):
        if self.buffer is None:
            print("âš ï¸ Buffer å°šæœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰“å°é€šé“å€¼")
            return



class ChannelManager:
    def __init__(self, lsl_info):
        """
        ä» pylsl.StreamInfo æå–å¹¶ä¿å­˜æ‰€æœ‰æœ‰æ„ä¹‰çš„ä¿¡æ¯
        åŒ…æ‹¬å…¨å±€å±æ€§å’Œé€šé“ç»“æ„
        """
        # === å…¨å±€æµä¿¡æ¯ ===
        self.name = lsl_info.name()
        self.type = lsl_info.type()
        self.channel_count = lsl_info.channel_count()
        self.srate = int(lsl_info.nominal_srate())
        self.uid = lsl_info.uid()
        self.hostname = lsl_info.hostname()
        self.source_id = lsl_info.source_id()
        self.version = lsl_info.version()
        self.created_at = lsl_info.created_at()

        # === æ‰€æœ‰é€šé“ä¿¡æ¯ ===
        #è¿™ä¸ªç±»çš„å®ä¾‹ä¸­æœ‰ç€æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸€äº›éEEGï¼Œä½†æ˜¯å®ƒæœ‰æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼Œåç»­è¿˜èƒ½ä½¿ç”¨ã€‚
        self.channels = []  # æ¯ä¸ªå…ƒç´ æ˜¯ dictï¼šlabel, index, type, unit

        ch = lsl_info.desc().child('channels').child('channel')
        index = 0
        while ch.name() == "channel":
            label = ch.child_value("label")
            ch_type = ch.child_value("type")
            unit = ch.child_value("unit")

            self.channels.append({
                "label": label,
                "index": index,
                "type": ch_type,
                "unit": unit
            })
            print(self.channels)

            ch = ch.next_sibling()
            index += 1

    # === é€šé“ç­›é€‰æ–¹æ³• ===
    def get_all_labels(self):
        return [ch["label"] for ch in self.channels]

    def get_all_indices(self):
        return [ch["index"] for ch in self.channels]

    def get_labels_by_type(self, desired_type="EEG"):
        return [ch["label"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_type(self, desired_type="EEG"):
        return [ch["index"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_labels(self, labels):
        label_set = set(labels)
        return [ch["index"] for ch in self.channels if ch["label"] in label_set]

    def get_labels_excluding_keywords(self, keywords):
        return [ch["label"] for ch in self.channels
                if not any(kw in ch["label"] for kw in keywords)]

    def get_indices_excluding_keywords(self, keywords):
        return [ch["index"] for ch in self.channels
                if not any(kw in ch["label"] for kw in keywords)]

    def get_labels_by_indices(self, indices):
        """
        æ ¹æ®ç´¢å¼•åˆ—è¡¨è·å–å¯¹åº”çš„é€šé“ååˆ—è¡¨
        """
        index_set = set(indices)
        return [ch["label"] for ch in self.channels if ch["index"] in index_set]

    # === ä¿¡æ¯æ‰“å°æ–¹æ³• ===
    def print_summary(self):
        print("=== Stream Info ===")
        print(f"Name      : {self.name}")
        print(f"Type      : {self.type}")
        print(f"Channels  : {self.channel_count}")
        print(f"Sampling  : {self.srate} Hz")
        print(f"UID       : {self.uid}")
        print(f"Hostname  : {self.hostname}")
        print(f"Source ID : {self.source_id}")
        print(f"Version   : {self.version}")
        print(f"Created   : {self.created_at}")
        print("\n=== Channel List ===")
        for ch in self.channels:
            print(f"[{ch['index']:02}] {ch['label']} | Type: {ch['type']} | Unit: {ch['unit']}")