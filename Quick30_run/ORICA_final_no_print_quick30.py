import numpy as np
from scipy.stats import kurtosis
from sklearn.feature_selection import mutual_info_regression
from scipy.linalg import sqrtm
import scipy

# ç¦ç”¨æ‰€æœ‰printè¾“å‡º
def _noop_print(*args, **kwargs):
    pass

print = _noop_print

class ORICA_final_new:
    def __init__(self, n_components, learning_rate=0.001, ortho_every=10, 
                 use_rls_whitening=False, forgetting_factor=0.98, 
                 nonlinearity='gaussian', block_size_ica=1, block_size_white=8,
                 ff_profile='cooling', tau_const=3, gamma=0.6, lambda_0=0.995,
                 num_subgaussian=0, eval_convergence=True, verbose=False, srate=500,
                 time_perm=False):
        """
        ORICA with RLS whitening support - åŸºäºMATLAB orica.må®ç°
        
        Args:
            n_components: ç‹¬ç«‹æˆåˆ†æ•°é‡
            learning_rate: å­¦ä¹ ç‡
            ortho_every: æ¯éš”å¤šå°‘æ¬¡è¿­ä»£æ­£äº¤åŒ–
            use_rls_whitening: æ˜¯å¦ä½¿ç”¨RLSç™½åŒ–
            forgetting_factor: RLSé—å¿˜å› å­ (0 < Î» < 1)
            nonlinearity: éçº¿æ€§å‡½æ•°ç±»å‹ ('gaussian', 'tanh')
            block_size_ica: ICAå—å¤§å°
            block_size_white: ç™½åŒ–å—å¤§å°
            ff_profile: é—å¿˜å› å­ç­–ç•¥ ('cooling', 'constant', 'adaptive')
            tau_const: å±€éƒ¨å¹³ç¨³æ€§å‚æ•°
            gamma: å†·å´ç­–ç•¥å‚æ•°
            lambda_0: åˆå§‹é—å¿˜å› å­
            num_subgaussian: æ¬¡é«˜æ–¯æºæ•°é‡
            eval_convergence: æ˜¯å¦è¯„ä¼°æ”¶æ•›æ€§
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            time_perm: æ˜¯å¦å¯¹æ•°æ®è¿›è¡Œæ—¶é—´æ‰“ä¹±ï¼ˆå‡å°‘æ—¶é—´ç›¸å…³æ€§ï¼‰
        """
        self.n_components = n_components
        self.learning_rate = learning_rate
        self.W = np.eye(n_components)  # è§£æ··çŸ©é˜µ (icaweights)
        self.mean = None
        self.whitening_matrix = None  # icasphere
        self.whitened = False
        self.update_count = 0
        self.ortho_every = ortho_every
        
        # å—æ›´æ–°å‚æ•°
        self.block_size_ica = block_size_ica
        self.block_size_white = block_size_white
        
        # æ—¶é—´æ‰“ä¹±å‚æ•°
        self.time_perm = time_perm
        
        # é—å¿˜å› å­å‚æ•°
        self.ff_profile = ff_profile
        self.srate = srate
        self.tau_const = tau_const
        self.gamma = gamma
        self.lambda_0 = lambda_0
        self.lambda_const = 1 - np.exp(-1/(self.tau_const*self.srate)) if tau_const != np.inf else 0.98
        
        print("srate",self.srate)
        print("tau_const",self.tau_const)
        print("lambda_const",self.lambda_const)
        
        # æ¬¡é«˜æ–¯æºå‚æ•°
        self.num_subgaussian = num_subgaussian
        self.kurtosis_sign = np.ones(n_components, dtype=bool)  # Trueä¸ºè¶…é«˜æ–¯
        if num_subgaussian > 0:
            self.kurtosis_sign[:num_subgaussian] = False
        
        # æ”¶æ•›æ€§è¯„ä¼°
        self.eval_convergence = eval_convergence
        self.leaky_avg_delta = 0.01
        self.leaky_avg_delta_var = 1e-3
        self.Rn = None
        self.non_stat_idx = None
        self.min_non_stat_idx = None
        
        # çŠ¶æ€å˜é‡
        self.lambda_k = np.zeros(block_size_ica)
        self.counter = 7681
        
        # RLSç™½åŒ–å‚æ•°
        self.use_rls_whitening = use_rls_whitening
        self.forgetting_factor = forgetting_factor
        self.nonlinearity = nonlinearity
        
        # RLSç™½åŒ–ç›¸å…³å˜é‡
        if self.use_rls_whitening:
            self.C = None  # åæ–¹å·®çŸ©é˜µçš„é€†
            self.t = 0     # æ—¶é—´æ­¥è®¡æ•°å™¨
            
        self.verbose = verbose

        self.record=None



    def initialize(self, X_init):
        """åˆå§‹åŒ–ORICA"""
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if X_init.shape[0] < 2:
            print(f"âš ï¸ åˆå§‹åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {X_init.shape[0]}ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return X_init
        
        # æ£€æŸ¥å¹¶è°ƒæ•´n_componentsä»¥åŒ¹é…æ•°æ®ç»´åº¦
        if X_init.shape[1] != self.n_components:  # X_initæ˜¯ (samples, channels) æ ¼å¼
            print(f"âš ï¸ åˆå§‹åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{X_init.shape[1]}é€šé“")
            self.n_components = X_init.shape[1]
            # é‡æ–°åˆ›å»ºWçŸ©é˜µä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.W = np.eye(self.n_components)
            print(f"âœ… è°ƒæ•´n_componentsä¸º{self.n_components}")
        
        print("initialize")
        # #data = scipy.io.loadmat(r"D:\work\Python_Project\ORICA\temp_txt\cleaned_data_20251001_163725.mat")
        # data = scipy.io.loadmat(r"D:\work\Python_Project\ORICA\temp_txt\cleaned_data_20251008_030649.mat")
        
        # cleaned_data = data['cleaned_data']
        # # è·å–æ‰€æœ‰å­—æ®µå
        # field_names = cleaned_data.dtype.names
        # print(f"å­—æ®µå: {field_names}")

        # # å°è¯•è®¿é—®icaweightså’Œicasphere
        # try:
        #     icaweights = cleaned_data[0, 0]['icaweights']
        #     print(f"\nicaweights ç±»å‹: {type(icaweights)}")
        #     print(f"icaweights å½¢çŠ¶: {icaweights.shape}")
        #     print(f"icaweights å†…å®¹: {icaweights[0:3,0:3]}")
        #     self.W = icaweights
            
        #     icasphere = cleaned_data[0, 0]['icasphere']
        #     print(f"\nicasphere ç±»å‹: {type(icasphere)}")
        #     print(f"icasphere å½¢çŠ¶: {icasphere.shape}")
        #     print(f"icasphere å†…å®¹: {icasphere[0:3,0:3]}")
        #     self.whitening_matrix = icasphere
            
        # except Exception as e:
        #     print(f"è®¿é—®å­—æ®µæ—¶å‡ºé”™: {e}")

        # # self.W = data["icaweights"]
        # # self.whitening_matrix = data["icasphere"]
        # # print(data)
        # # print("self.W",self.W)
        # # print("self.whitening_matrix",self.whitening_matrix.shape)
        print("initialize done")
        self.whitening_matrix = np.eye(self.n_components)
        # try:
        #     # å»å‡å€¼
        #     #X_init = self._center(X_init)
        #     #ä¼¼ä¹np.covè‡ªå¸¦ä¸­å¿ƒåŒ–
            
        #     # ç™½åŒ–
        #     if self.use_rls_whitening:
        #         # ä½¿ç”¨RLSç™½åŒ–åˆå§‹åŒ–
        #         self._rls_whiten_initialize(X_init)
        #         # å¯¹åˆå§‹æ•°æ®è¿›è¡Œæ‰¹é‡ç™½åŒ–
        #         X_init = self._whiten(X_init)
        #     else:
        #         # ä½¿ç”¨ä¼ ç»Ÿæ‰¹é‡ç™½åŒ–
        #         X_init = self._whiten(X_init)
            
        #     self.whitened = True
        #     print(f"âœ… ORICAåˆå§‹åŒ–å®Œæˆ: n_components={self.n_components}, æ•°æ®å½¢çŠ¶={X_init.shape}")
        # except Exception as e:
        #     print(f"âš ï¸ ORICAåˆå§‹åŒ–å¤±è´¥: {e}")
        #     self.whitened = False
        
        return X_init




    def dynamic_whitening(self,blockdata, data_range, state, lambda_const,gamma,lambda_0):
        """
        RLSåœ¨çº¿ç™½åŒ–ç®—æ³• - ä¸MATLABæºç å®Œå…¨ä¸€è‡´
        
        å‚æ•°:
        blockdata: å½“å‰æ•°æ®å— [nChs Ã— nPts]
        data_range: æ•°æ®èŒƒå›´ç´¢å¼•
        state: çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«icasphereç­‰
        adaptive_ff: è‡ªé€‚åº”é—å¿˜å› å­å‚æ•°
        lambda_const: é—å¿˜å› å­ä¸‹é™å¸¸æ•°
        
        è¿”å›:
        state: æ›´æ–°åçš„çŠ¶æ€
        """
        print(f"ç™½åŒ–çŸ©é˜µbefore: {state['icasphere'][0:3,0:3]}")
        nPts = blockdata.shape[1]

        



        # è®¡ç®—é—å¿˜å› å­ - å®Œå…¨æŒ‰ç…§MATLABçš„é€»è¾‘
        # MATLAB: lambda = genCoolingFF(state.counter+dataRange, adaptiveFF.gamma, adaptiveFF.lambda_0);

        print("oricain201")
        print("state['counter']",state['counter'])
        print("data_range",data_range)
        print("gamma",gamma)
        print("lambda_0",lambda_0)
        lambda_values = self.gen_cooling_ff(state['counter'] + data_range, gamma, lambda_0)

        #lambda_const=1 - np.exp(-1 / np.inf)
        #lambda_const = 1 - np.exp(-1/3)  # çº¦0.000667ï¼Œä¸æ˜¯0

        # MATLAB: if lambda(1) < adaptiveFF.lambda_const
        #         lambda = repmat(adaptiveFF.lambda_const,1,nPts);

                
        #if lambda_values[0] < self.lambda_const:
        if True:#å› ä¸ºquick30ä½¿ç”¨äº†const
            print("w"*100)
            print("lambda_k[0] < lambda_const orica",lambda_values[0],lambda_const)
            lambda_values = np.full(len(data_range), self.lambda_const)
        
        print("lambda_values2",lambda_values)

        print("blockdata_size",blockdata.shape)
        print("blockdata",blockdata[0:3,0:3])



            

        # save_txt("23.txt",lambda_values.reshape(1, -1))
        # æ³¨æ„ï¼šLambdaä¸‹é™æ£€æŸ¥åº”è¯¥åœ¨dynamic_whiteningå‡½æ•°å†…éƒ¨è¿›è¡Œï¼Œä¸MATLABä¸€è‡´
        # è¿™é‡Œåªä¼ é€’åŸå§‹lambdaå€¼
        adaptive_ff = {'lambda': lambda_values}


        #save_txt("201.txt",blockdata)

        # 1. ä½¿ç”¨å½“å‰ç™½åŒ–çŸ©é˜µé¢„å¤„ç†æ•°æ®

        print("oricain21")
        print("state['icasphere']_shape",state['icasphere'].shape)
        print("state['icasphere']",state['icasphere'][0:3,0:3])
        print("blockdata_shape",blockdata.shape)
        print("blockdata",blockdata[0:3,0:3])

        v = state['icasphere'] @ blockdata  # é¢„ç™½åŒ–æ•°æ®
        v = self.snap_to_kbits(v, k=38)

        
        print("v_shape",v.shape)
        print("v",v[0:3,0:3])


        #print("blockdata",blockdata)
        np.set_printoptions(precision=16, suppress=False, linewidth=200)


        # save_txt("21.txt",v)

        
        
        # 2. è®¡ç®—é—å¿˜å› å­ - ä¿®å¤ï¼šä½¿ç”¨ä¸­é—´å€¼ï¼Œä¸MATLABå®Œå…¨ä¸€è‡´
        # MATLAB: lambda_avg = 1 - lambda(ceil(end/2));
        #lambda_avg = 1 - adaptive_ff['lambda'][len(adaptive_ff['lambda'])//2]
        print("lambda_values_before",lambda_values)
        lambda_avg = 1 - lambda_values[int(np.ceil(len(lambda_values) / 2)) - 1]
        print("lambda_avg",lambda_avg)
        print("lambda_values",lambda_values)

        # save_txt("28.txt",lambda_avg)
        

        # 3. RLSæ›´æ–°è§„åˆ™
        #QWhite = lambda_avg/(1-lambda_avg) + np.trace(v.T @ v) / nPts
        # æ–¹å¼ 1ï¼šæ˜¾å¼å…±è½­è½¬ç½®
        #QWhite = lambda_avg/(1 - lambda_avg) + (np.trace(v.conj().T @ v).real) / nPts
        # æ–¹å¼ 2ï¼šç”¨ vdotï¼ˆå¯¹ç¬¬ä¸€ä¸ªå‚æ•°åšå…±è½­ï¼Œå†åšå†…ç§¯ï¼›ç­‰ä»·äº Frobenius èŒƒæ•°å¹³æ–¹ï¼‰
        #QWhite = lambda_avg/(1 - lambda_avg) + (np.vdot(v, v).real) / nPts
        # æ–¹å¼ 3ï¼šç›´æ¥ç”¨ Frobenius èŒƒæ•°
        QWhite = lambda_avg/(1 - lambda_avg) + (np.linalg.norm(v, 'fro')**2) / len(data_range)




        QWhite = self.snap_to_kbits(QWhite, k=38)


        print("Qwhite_shape",QWhite.shape)
        print("Qwhite",QWhite)

        # save_txt("22.txt",QWhite)

        # 4. é€’å½’æ›´æ–°ç™½åŒ–çŸ©é˜µ - ä¸MATLABå®Œå…¨ä¸€è‡´

        #è¿™é‡Œå‡ºäº†é—®é¢˜ã€‚ã€‚



        
        # MATLAB: state.icasphere = 1/lambda_avg * (state.icasphere - v * v' / nPts / QWhite * state.icasphere);
        update_term = (v @ v.T) / nPts / QWhite @ state['icasphere']


        
        state['icasphere'] = (1/lambda_avg) * (state['icasphere'] - update_term)

        print(f"ç™½åŒ–çŸ©é˜µ: {state['icasphere'][0:3,0:3]}")








        

        
        return state

    def gen_cooling_ff(self,t, gamma, lambda_0):
        """
        ç”Ÿæˆå†·å´é—å¿˜å› å­ - ä¸MATLABæºç å®Œå…¨ä¸€è‡´
        MATLAB: lambda = lambda_0 ./ (t .^ gamma)
        
        å‚æ•°:
        t: æ—¶é—´ç‚¹æˆ–æ•°ç»„
        gamma: è¡°å‡ç‡
        lambda_0: åˆå§‹é—å¿˜å› å­
        
        è¿”å›:
        lambda: é—å¿˜å› å­å€¼æˆ–æ•°ç»„
        """
        # ç¡®ä¿tä¸ä¸º0ï¼Œé¿å…é™¤é›¶é”™è¯¯
        # save_txt("24.txt",t.reshape(1, -1))
        # save_txt("25.txt",gamma)
        # save_txt("26.txt",lambda_0)
        t_safe = np.maximum(t, 1e-10)
        #lambda_values = lambda_0 / (t ** gamma)
        print("oricain20101")
        print("t",t)
        print("gamma",gamma)
        print("lambda_0",lambda_0)
        lambda_values = lambda_0 / np.power(t, gamma)
        print("lambda_values",lambda_values)


        # ç”¨æ³•
        #lambda_ = lambda_0 / np.power(t, gamma)
        lambda_values = self.snap_to_kbits(lambda_values, k=50)
        print("lambda_values2",lambda_values)


        # save_txt("27.txt",lambda_values.reshape(1, -1))
        return lambda_values

    def snap_to_kbits(self,x, k=50):  # k < 52
        # k=10
        # x = np.asarray(x, dtype=np.float64)
        # m, e = np.frexp(x)                     # x = m * 2**eï¼Œmâˆˆ[-1, -0.5)âˆª[0.5, 1)
        # m = np.round(m * (1 << k)) / float(1 << k)  # åªä¿ç•™ k ä½å°¾æ•°ï¼ˆçº¯2çš„å¹‚ï¼ŒäºŒè¿›åˆ¶ç²¾ç¡®ï¼‰
        # return np.ldexp(m, e)
        return x

    def dynamic_orica_cooling(self,blockdata, data_range, state=None, gamma=0.5, lambda_0=1.0):
        """
        æç®€ ORICAï¼ˆcooling ç‰ˆï¼Œlambda_const=0ï¼‰
        blockdata: np.ndarray, shape=(n_chs, n_pts)

        state: dictï¼Œå¯ä¸ºç©ºï¼›ç¼ºçœæ—¶è‡ªåŠ¨åˆå§‹åŒ–ï¼š
        - icaweights: è§£æ··çŸ©é˜µ (n_chs, n_chs)
        - kurtsign  : True=super-gaussian, False=sub-gaussianï¼ˆé»˜è®¤å…¨ Trueï¼‰
        - counter   : å·²å¤„ç†æ ·æœ¬è®¡æ•°
        - lambda_k  : ä¸Šæ¬¡ Î»ï¼ˆä»…è®°å½•ï¼‰

        è¿”å›ï¼šæ›´æ–°åçš„ state
        """
        X = np.asarray(blockdata, dtype=np.float64)
        n_chs, n_pts = X.shape

        # --- åˆå§‹åŒ– stateï¼ˆè‹¥æœªç»™ï¼‰ ---
        if state is None:
            state = {}
        if "icaweights" not in state:
            state["icaweights"] = np.eye(n_chs, dtype=np.float32)
        if "kurtsign" not in state:
            state["kurtsign"] = np.ones(n_chs, dtype=bool)  # å…¨éƒ¨æŒ‰è¶…é«˜æ–¯å¤„ç†
        if "counter" not in state:
            state["counter"] = 0
        if "lambda_k" not in state:
            state["lambda_k"] = np.array([0.0], dtype=np.float32)

        W = state["icaweights"]

        # (1) æºæ¿€æ´»
        Y = W @ X  # (n_chs, n_pts)
        # save_txt("5.txt",Y)
        #print("blockdata",blockdata)
        # print("Y.shape",Y.shape)
        # print("Y",Y[0:3,:])

        # (2) éçº¿æ€§ï¼ˆextended-Infomax çš„ç¬¦å·ï¼‰
        F = np.empty_like(Y)
        idx_sg  = state["kurtsign"]           # super-gaussian
        idx_sub = ~state["kurtsign"]          # sub-gaussian
        # F[idx_sg, :]  = -2.0 * np.tanh(Y[idx_sg, :])
        # F[idx_sub, :] =  2.0 * np.tanh(Y[idx_sub, :])
        # åœ¨dynamic_orica_coolingä¸­ä¿®å¤
        F[idx_sg, :] = -2.0 * np.tanh(Y[idx_sg, :])           # è¶…é«˜æ–¯ï¼šæ­£ç¡®
        F[idx_sub, :] = np.tanh(Y[idx_sub, :]) - Y[idx_sub, :]  # æ¬¡é«˜æ–¯ï¼šä¿®å¤

        # print("F",F.shape)
        # print("F",F)
        # print("Y",Y.shape)
        # print("Y",Y)
        # print("Y @ F.T",(Y @ F.T) / nPts)
        # print("nChs,n_pts",nChs,n_pts)


        evalConvergence = {}
        evalConvergence["profile"] = True
        evalConvergence["leakyAvgDelta"] = 0.01
        evalConvergence["leakyAvgDeltaVar"] = 1e-3


        if evalConvergence["profile"]:
            # modelFitness = I + (y @ f.T) / nPts
            modelFitness = np.eye(n_chs) + (Y @ F.T) / n_pts
            
            # variance = blockdata .* blockdata
            variance = blockdata * blockdata   # element-wise square
            
            state['Rn']=self.Rn
            if state.get("Rn") is None:
                state["Rn"] = modelFitness
                #print("state['Rn']",state["Rn"])
            else:
                delta = evalConvergence["leakyAvgDelta"]
                state["Rn"] = (1 - delta) * state["Rn"] + delta * modelFitness
                #print("state2['Rn']",state["Rn"])
            
            # Frobenius norm
            state["nonStatIdx"] = np.linalg.norm(state["Rn"], 'fro')

            #print("state['nonStatIdx']",state["nonStatIdx"])

        




        # (3) cooling é—å¿˜å› å­ï¼ˆlambda_const=0ï¼Œä¸è®¾ä¸‹é™ï¼‰

        lambda_k = self.gen_cooling_ff(state['counter'] + data_range, gamma, lambda_0)
        # print("state['counter']",state['counter'])
        # print("data_range",data_range)
        state['counter'] += n_pts
        #lambda_const=1 - np.exp(-1 / np.inf)
        #lambda_const = 1 - np.exp(-1/3)  # çº¦0.000667ï¼Œä¸æ˜¯0

        # MATLAB: if lambda(1) < adaptiveFF.lambda_const
        #         lambda = repmat(adaptiveFF.lambda_const,1,nPts);
                
        #if lambda_k[0] < self.lambda_const:
        if True:#å› ä¸ºquick30ä½¿ç”¨äº†const
            print("è¿›å…¥oricaäº†")
            print("lambda_k[0] < lambda_const orica",lambda_k[0],self.lambda_const)
            lambda_k = np.full(len(data_range), self.lambda_const)


        
        #print("lambda_k",lambda_k)



        # update weight matrix using online recursive ICA block update rule
        lambda_prod = np.prod(1.0 / (1 - lambda_k))
        Q = 1.0 + lambda_k * (np.sum(F * Y, axis=0) - 1.0)
        F=self.snap_to_kbits(F, k=44)



        # save_txt("31.txt",Y)
        # save_txt("32.txt",np.diag(lambda_k / Q))
        # save_txt("33.txt",F.T)
        # save_txt("34.txt",state['icaweights'])
        # save_txt("35.txt",lambda_prod)
        

        state['icaweights'] = lambda_prod * (state['icaweights'] - Y @ np.diag(lambda_k / Q) @ F.T @ state['icaweights'])


        # save_txt("36.txt",state['icaweights'])
        #print("state['icaweights']",state['icaweights'])



        # orthogonalize weight matrix 
        # V, D = np.linalg.eig(state['icaweights'] @ state['icaweights'].T)
        # D_sqrt_inv = np.diag(1.0 / np.sqrt(np.diag(D)))
        #state['icaweights'] = V @ D_sqrt_inv @ V.T @ state['icaweights']



        # save_txt("391.txt",state["icaweights"].T)
        # save_txt("392.txt",state["icaweights"] @ state["icaweights"].T)
        #D, V = np.linalg.eigh(state["icaweights"] @ state["icaweights"].T)
        #D, V = np.linalg.eigh(state["icaweights"] @ state["icaweights"].T)
        D, V = scipy.linalg.eigh(state["icaweights"] @ state["icaweights"].T)



        D = np.diag(D)

        D=self.snap_to_kbits(D, k=32)
        V=self.snap_to_kbits(V, k=32)




        # save_txt("38.txt",D)

        # save_txt("39.txt",np.abs(V))

        # print("V",V)
        # print("D",D)
        # print("np.diag(1.0/np.sqrt(D))",V @ np.diag(1.0/np.sqrt(D)))
        # print("state['icaweights']",state["icaweights"])



        # state["icaweights"] = V @ np.diag(1.0/np.sqrt(D)) @ V.T @ state["icaweights"]
        # state["icaweights"] = snap_to_kbits(state["icaweights"], k=40)

        # save_txt("37.txt",state["icaweights"])






        def inv_sqrt_from_D(D):
            """D å¯ä»¥æ˜¯ (n,) çš„ç‰¹å¾å€¼å‘é‡ æˆ– (n,n) çš„å¯¹è§’çŸ©é˜µã€‚è¿”å› inv(sqrt(D)) çš„å¯¹è§’çŸ©é˜µ (n,n)ã€‚"""
            D = np.asarray(D)
            if D.ndim == 1:              # w: ç‰¹å¾å€¼å‘é‡
                d = D
            elif D.ndim == 2:            # å¯¹è§’çŸ©é˜µ
                d = np.diag(D)
            else:
                raise ValueError("D å¿…é¡»æ˜¯ä¸€ç»´(ç‰¹å¾å€¼å‘é‡)æˆ–äºŒç»´(å¯¹è§’çŸ©é˜µ)")
            inv_sqrt = 1.0 / np.sqrt(d)  # æ³¨æ„ 0 ä¼šå˜æˆ infï¼Œå»ºè®®åŠ ä¸€ä¸ªæå°é˜ˆå€¼é˜²é›¶
            return np.diag(inv_sqrt)

        # === ä»£å…¥ä½ çš„å¼å­ ===
        W = state["icaweights"]
        # å¦‚æœ V,D æ¥è‡ª np.linalg.eigh(W @ W.conj().T):
        #   w, V = np.linalg.eigh(W @ W.conj().T)     # w: (n,), V: (n,n)
        #   D = w  # æ­¤æ—¶ D å°±ç”¨å‘é‡ï¼Œæ›´æ–¹ä¾¿
        # å¦åˆ™å¦‚æœä½ å·²ç»æœ‰å¯¹è§’çŸ©é˜µ D = np.diag(w)ï¼Œä¹Ÿæ²¡é—®é¢˜ã€‚

        M = V @ inv_sqrt_from_D(D) @ V.conj().T      # ç­‰ä»·äº MATLAB çš„ V / sqrt(D) * V'
        state["icaweights"] = M @ W                  # å†ä¸åŸ W ç›¸ä¹˜

        # snap & ä¿å­˜ï¼ˆæ³¨æ„ state["icaweights"] å¿…é¡»æ˜¯ 2Dï¼‰
        state["icaweights"] = self.snap_to_kbits(state["icaweights"], k=40)
        assert state["icaweights"].ndim == 2 and state["icaweights"].shape == (V.shape[0], V.shape[0])
        # save_txt("37.txt", state["icaweights"])



        



        
        

        
        


        
        #     t = counter + (1..n_pts)
        # t = state["counter"] + np.arange(1, n_pts + 1, dtype=float)
        # lam = lambda_0 / (t ** gamma)                   # shape (n_pts,)
        # state["lambda_k"] = lam
        # state["counter"] += n_pts

        # # (4) é€’å½’å—æ›´æ–°
        # # s_j = sum_i F_ij * Y_ij
        # s = np.sum(F * Y, axis=0)                      # (n_pts,)
        # Q = 1.0 + lam * (s - 1.0)                      # (n_pts,)
        # col_scale = (lam / Q)[None, :]                 # (1, n_pts)
        # M = (Y * col_scale) @ F.T                      # (n_chs, n_chs)
        # lambda_prod = float(np.prod(1.0 / (1.0 - lam)))  # æ ‡é‡
        # W = lambda_prod * (W - M @ W)

        # # (5) å¯¹ç§°å»ç›¸å…³ï¼ˆorthogonalizeï¼‰
        # WWt = W @ W.T
        # d, E = np.linalg.eigh(WWt)                     # WWt = E diag(d) E^T
        # eps = 1e-12
        # Dm12 = E @ np.diag(1.0 / np.sqrt(d + eps)) @ E.T
        # W = Dm12 @ W

        # # å†™å›
        # state["icaweights"] = W


        print("oricain4")
        print("state['icaweights'].shape",state["icaweights"].shape)
        print("state['icaweights']",state["icaweights"][0:3,0:3])
        return state


    def gen_adaptive_ff(self,data_range,
                        lambda_vec,
                        decayRateAlpha,
                        upperBoundBeta,
                        transBandWidthGamma,
                        transBandCenter,
                        ratioOfNormRn):
        """
        å¤ç° MATLAB: genAdaptiveFF
        å‚æ•°
        ----
        data_range : 1D array-like
            æœ¬ block çš„æ ·æœ¬ç´¢å¼•ï¼ˆåªéœ€é•¿åº¦ï¼‰
        lambda_vec : 1D array-like
            å†å² Î» åºåˆ—ï¼›åªä½¿ç”¨æœ€åä¸€ä¸ªå…ƒç´  lambda_vec[-1]
        decayRateAlpha : float
        upperBoundBeta : float
        transBandWidthGamma : float
        transBandCenter : float
        ratioOfNormRn : float
            éå¹³ç¨³æ€§æŒ‡æ ‡ç›¸å¯¹æœ€å°å€¼çš„æ¯”å€¼

        è¿”å›
        ----
        lambdas : np.ndarray, shape = (len(data_range),)
            æœ¬ block å†…é€æ ·æœ¬çš„ Î» åºåˆ—
        """
        n_pts = len(data_range)
        lam0 = float(np.asarray(lambda_vec)[-1])  # lambda(end)
        # gainForErrors = upperBoundBeta * 0.5 * (1 + tanh((ratio - center)/bandwidth))
        gain = upperBoundBeta * 0.5 * (1.0 + np.tanh((ratioOfNormRn - transBandCenter) / transBandWidthGamma))

        n = np.arange(1, n_pts + 1, dtype=np.float32)     # n = 1..N
        one_plus_g = 1.0 + gain

        # term1 = (1+g)^n * lam0
        term1 = (one_plus_g ** n) * lam0

        # term2 = decayRateAlpha * ((1+g)^(2n-1) - (1+g)^(n-1)) / g * lam0^2
        # éœ€è¦å¤„ç† g -> 0 çš„æé™ï¼šå½“ gâ‰ˆ0 æ—¶ï¼Œåˆ†å­ ~ n*gï¼Œå› æ­¤æ•´ä½“æé™ä¸º n
        eps = 1e-12
        if abs(gain) < eps:
            frac = n  # æé™ï¼š((1+g)^(2n-1) - (1+g)^(n-1)) / g  ->  n
        else:
            frac = ((one_plus_g ** (2.0 * n - 1.0)) - (one_plus_g ** (n - 1.0))) / gain

        term2 = decayRateAlpha * frac * (lam0 ** 2)

        lambdas = term1 - term2
        return np.asarray(lambdas, dtype=np.float32)


    def mmul_strict(self,A, B):
        A = np.asarray(A, dtype=np.float64, order='F')  # åˆ—ä¸»åºè§†å›¾
        B = np.asarray(B, dtype=np.float64, order='F')
        m, k = A.shape
        k2, n = B.shape
        assert k == k2
        C = np.empty((m, n), dtype=np.float64, order='F')
        for j in range(n):            # å…ˆåˆ—åè¡Œï¼ˆåŒ¹é… MATLAB çº¿æ€§ç´¢å¼•ï¼‰
            for i in range(m):
                s = 0.0
                for p in range(k):
                    s += A[i, p] * B[p, j]
                C[i, j] = s
        return C


    def orica_rls_whitening(self,data, block_size_white=8, num_pass=1, 
                            lambda_0=0.995, gamma=0.6, lambda_const=0.95, verbose=True):
        """
        ORICA RLSåœ¨çº¿ç™½åŒ–ä¸»å‡½æ•° - ä¸MATLABæºç å®Œå…¨ä¸€è‡´
        
        å‚æ•°:
        data: è¾“å…¥æ•°æ® [nChs Ã— nPts]
        block_size_white: ç™½åŒ–å—å¤§å°
        num_pass: æ•°æ®éå†æ¬¡æ•°
        lambda_0: åˆå§‹é—å¿˜å› å­
        gamma: è¡°å‡ç‡
        lambda_const: é—å¿˜å› å­ä¸‹é™å¸¸æ•°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        
        è¿”å›:
        weights: ICAæƒé‡çŸ©é˜µ
        sphere: æœ€ç»ˆç™½åŒ–çŸ©é˜µ
        """
        nChs, nPts = data.shape
        print("oricain1")
        print("data.shape",data.shape)
        print("data",data[0:3,0:3])

        #original_data = data.copy()
        #è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œcenterä»…ä»…ç”¨äºonline whiteningï¼Œç®—mixturesè¿˜æ˜¯ç”¨original_data

        data_center = data.copy()
        data_center -= data.mean(axis=1, keepdims=True)

        print("data_center",data_center[0:3,0:3])

        print("oricain1")
        print("data_center.shape",data_center.shape)
        print("data_center",data_center[0:3,0:3])
        print("self.whitening_matrix_shape",self.whitening_matrix.shape)
        print("self.whitening_matrix",self.whitening_matrix[0:3,0:3])
        print("self.W_shape",self.W.shape)
        print("self.W",self.W[0:3,0:3])

        
        # # # åˆå§‹åŒ–çŠ¶æ€
        # state = {
        #     'icasphere': np.eye(nChs),  # åˆå§‹ç™½åŒ–çŸ©é˜µä¸ºå•ä½çŸ©é˜µ
        #     'icaweights': np.eye(nChs),  # åˆå§‹ICAæƒé‡çŸ©é˜µ
        #     'counter': 0
        # }

        #ä½¿ç”¨å½“å‰æƒé‡åˆå§‹åŒ–çŠ¶æ€ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å•ä½çŸ©é˜µ
        if self.whitening_matrix is not None and self.W is not None:
            state = {
                'icasphere': self.whitening_matrix,  # ä½¿ç”¨å½“å‰ç™½åŒ–çŸ©é˜µ
                'icaweights': self.W,  # ä½¿ç”¨å½“å‰è§£æ··çŸ©é˜µ
                'counter': self.counter
            }
            print("ğŸ”„ ä½¿ç”¨å½“å‰æƒé‡çŸ©é˜µåˆå§‹åŒ–çŠ¶æ€")
        else:
            # ä½¿ç”¨éšæœºæ­£äº¤çŸ©é˜µåˆå§‹åŒ–ï¼ˆç±»ä¼¼ MATLAB: [U,~,~] = svd(rand(nChs)); state.icasphere = Uï¼‰
            # è¿™é‡Œé‡‡ç”¨ QR åˆ†è§£è·å–æ­£äº¤çŸ©é˜µ Qï¼Œç­‰ä»·å¯è¡Œä¸”æ›´é«˜æ•ˆ
            rand_mat = np.random.randn(nChs, nChs)
            Q, R = np.linalg.qr(rand_mat)
            # å¯é€‰ï¼šå°† R çš„ç¬¦å·å½’å…¥ Qï¼Œä¿è¯å¯¹è§’çº¿ä¸ºæ­£ï¼Œä»è€Œä½¿ Q çš„åˆ†å¸ƒæ›´å‡åŒ€
            signs = np.sign(np.diag(R))
            signs[signs == 0] = 1.0
            Q = Q * signs

            state = {
                'icasphere': Q,                 # âœ… ä¿®å¤ï¼šä½¿ç”¨éšæœºæ­£äº¤çŸ©é˜µ Qï¼ˆä¹‹å‰é”™è¯¯åœ°ç”¨äº† np.eyeï¼‰
                'icaweights': np.eye(nChs),     # åˆå§‹ICAæƒé‡çŸ©é˜µä»ç”¨å•ä½é˜µ
                'counter': 0
            }
            print("ğŸ”„ ä½¿ç”¨éšæœºæ­£äº¤çŸ©é˜µåˆå§‹åŒ–ç™½åŒ–çŸ©é˜µ")

        # print("xxxxxxxx")
        # print(np.array_equal(self.record, state['icaweights']))
        # print("xxxxxxxx")
        # save_txt("13.txt", data)
        # é¢„ç™½åŒ–æ•´ä¸ªæ•°æ®é›†
        #data = state['icasphere'] @ data  # å¯¹åº”MATLAB: data = state.icasphere * data;
        # save_txt("14.txt", data)  # ä¿å­˜é¢„ç™½åŒ–åçš„æ•°æ®
        
        # æ•°æ®åˆ†å— - ç¡®ä¿æ¯ä¸ªå—éƒ½æ˜¯å›ºå®šçš„block_size_whiteå¤§å°
        num_block = int(np.floor(nPts / block_size_white))
        print("num_block",num_block)

        numsplits = nPts // block_size_white  # ç­‰åŒäº MATLAB çš„ floor(nPts/blockSize)
        print("numsplits",numsplits)

        
        if verbose:

            import time
            start_time = time.time()
        
        for it in range(num_pass):
            print("cat")
            # print(data[:3])
            #range(1)å°±åªæœ‰ä¸€ä¸ªæ•°
            #for bi in range(11):
            for bi in range(num_block):
                # # è®¡ç®—å½“å‰æ•°æ®å—èŒƒå›´ - ç¡®ä¿æ¯ä¸ªå—éƒ½æ˜¯å›ºå®šçš„block_size_whiteå¤§å°
                # start_idx = bi * block_size_white
                # end_idx = min(nPts, (bi + 1) * block_size_white)
                # data_range = np.arange(start_idx, end_idx)
                # print("data_range",data_range)
                
                # # å¦‚æœå‰©ä½™æ•°æ®ä¸è¶³ä¸€ä¸ªå®Œæ•´å—ï¼Œè·³è¿‡
                # if end_idx - start_idx < block_size_white:
                #     break

                # # save_txt("11.txt",data)
                # # æå–å½“å‰æ•°æ®å—
                # blockdata = data[:, data_range]
                # ====== MATLAB-style block split (avg partition with floor) ======
                # å‡è®¾ï¼šnPts = data.shape[1], numsplits = nPts // block_size_white
                # start_idx = int(np.floor(bi * nPts / numsplits))                 # å«
                # end_idx   = min(nPts, int(np.floor((bi + 1) * nPts / numsplits)))  # ä¸å«
                # data_range = np.arange(start_idx, end_idx)                       # å¯èƒ½æ˜¯ 8 æˆ– 9 é•¿åº¦
                # # æå–å½“å‰æ•°æ®å—


                
                start = int(bi * nPts / numsplits)        # ä» 0 å¼€å§‹
                end = min(nPts, int((bi + 1) * nPts / numsplits))
                data_range = np.arange(start, end)      # å³å¼€åŒºé—´ï¼Œä¸éœ€è¦ +1


                print("fish")
                print("bi",bi)
                print("nPts",nPts)
                print("numsplits",numsplits)
                print("data_range",data_range)
                blockdata = data_center[:, data_range]







                #print("blockdataxxxxxxxxxxx",blockdata)
                
                # # è®¡ç®—é—å¿˜å› å­ - å®Œå…¨æŒ‰ç…§MATLABçš„é€»è¾‘
                # # MATLAB: lambda = genCoolingFF(state.counter+dataRange, adaptiveFF.gamma, adaptiveFF.lambda_0);
                # lambda_values = gen_cooling_ff(state['counter'] + data_range, gamma, lambda_0)
                # lambda_const=1 - np.exp(-1 / np.inf)

                # # MATLAB: if lambda(1) < adaptiveFF.lambda_const
                # #         lambda = repmat(adaptiveFF.lambda_const,1,nPts);
                
                # if lambda_values[0] < lambda_const:
                #     lambda_values = np.full(nPts_block, lambda_const)
                #     print(f"åŠ¨æ€ç™½åŒ– - åº”ç”¨ä¸‹é™: {lambda_const}")

                # print("shit")
                # print(state['counter'])
                # print(data_range)
                # print(lambda_values)
                # print(lambda_const)
                # print()
                
                # # æ³¨æ„ï¼šLambdaä¸‹é™æ£€æŸ¥åº”è¯¥åœ¨dynamic_whiteningå‡½æ•°å†…éƒ¨è¿›è¡Œï¼Œä¸MATLABä¸€è‡´
                # # è¿™é‡Œåªä¼ é€’åŸå§‹lambdaå€¼
                #adaptive_ff = {'lambda': lambda_values}
                
                # æ‰§è¡ŒRLSç™½åŒ–æ›´æ–°
                state = self.dynamic_whitening(blockdata, data_range+1, state,  lambda_const, gamma,lambda_0)
                
                # save_txt("2.txt",state['icasphere'])

        print("state['icasphere']_out.shape",state['icasphere'].shape)
        print("state['icasphere']_out",state['icasphere'][0:3,0:3])
        print("data.shape",data.shape)
        print("data",data[0:3,0:3])

        mixtures = state['icasphere'] @ data
        print("oricain2")
        print("mixtures.shape",mixtures.shape)
        print("mixtures",mixtures[0:3,0:3])
        print("icasphere_shape",state['icasphere'].shape)
        print("icasphere",state['icasphere'][0:3,0:3])
        print("icaweights_shape",state['icaweights'].shape)
        print("icaweights",state['icaweights'][0:3,0:3])
        print("data.shape",data.shape)
        print("data",data[0:3,0:3])
        
        # ===== æ—¶é—´æ‰“ä¹±ï¼ˆTime Permutationï¼‰- å¯¹åº” MATLAB çš„ options.timeperm =====
        # ç›®çš„ï¼šéšæœºæ‰“ä¹±æ•°æ®æ—¶é—´é¡ºåºï¼Œå‡å°‘æ—¶é—´ç›¸å…³æ€§ï¼Œå¸®åŠ© ICA æ›´å¥½åœ°æ”¶æ•›
        if self.time_perm:
            # ç”Ÿæˆéšæœºæ’åˆ—ç´¢å¼•ï¼ˆå¯¹åº” MATLAB: permIdx = randperm(nPts)ï¼‰
            perm_idx = np.random.permutation(nPts)
            print("ğŸ”€ å¯ç”¨æ—¶é—´æ‰“ä¹±ï¼ˆTime Permutationï¼‰")
        else:
            # ä¸æ‰“ä¹±ï¼Œä½¿ç”¨é¡ºåºç´¢å¼•ï¼ˆå¯¹åº” MATLAB: permIdx = 1:nPtsï¼‰
            perm_idx = np.arange(nPts)
            print("â¡ï¸ ä¸ä½¿ç”¨æ—¶é—´æ‰“ä¹±ï¼Œä¿æŒåŸå§‹æ—¶é—´é¡ºåº")




        #data[:, data_range] = state['icasphere'] @ data[:, data_range]
        #data = state['icasphere'] @ data
        #data[:, data_range] = mmul_strict(state['icasphere'], data[:, data_range])
        #data[:, data_range] = self.snap_to_kbits(data[:, data_range], k=44)
        #print("data",data.shape)

        block_size_orica = 16
        num_block_orica = int(np.floor(nPts / block_size_orica))
        print("num_block_orica",num_block_orica)


        print("=====================beforeorica============================")
        for it in range(num_pass):
            print("dog")
            # print(data[:3])
            #range(1)å°±åªæœ‰ä¸€ä¸ªæ•°
            #for bi in range(11):
            print("times")
            print("num_block_orica",num_block_orica)
            for bi in range(num_block_orica):
                #è®¡ç®—å½“å‰æ•°æ®å—èŒƒå›´ - ç¡®ä¿æ¯ä¸ªå—éƒ½æ˜¯å›ºå®šçš„block_size_whiteå¤§å°
                # start_idx = bi * block_size_orica
                # end_idx = min(nPts, (bi + 1) * block_size_orica)
                # data_range = np.arange(start_idx, end_idx)
                
                # # å¦‚æœå‰©ä½™æ•°æ®ä¸è¶³ä¸€ä¸ªå®Œæ•´å—ï¼Œè·³è¿‡
                # if end_idx - start_idx < block_size_orica:
                #     break

                # # save_txt("11.txt",data)
                # # æå–å½“å‰æ•°æ®å—
                # blockdata = data[:, data_range]
                # # save_txt("12.txt",blockdata)
                # nPts_block = blockdata.shape[1]


                # start = 1 + int(bi * nPts / numsplits)
                # end = min(nPts, int((bi + 1) * nPts / numsplits))
                # data_range = list(range(start, end + 1))

                start = int(bi * nPts / numsplits)        # ä» 0 å¼€å§‹
                end = min(nPts, int((bi + 1) * nPts / numsplits))
                data_range = np.arange(start, end)      # å³å¼€åŒºé—´ï¼Œä¸éœ€è¦ +1




                # print("blockdata.shape",blockdata.shape)
                # print("data_range",data_range)
                



                # æ›´æ–°è®¡æ•°å™¨
                #state['counter'] += len(data_range)
                
                # if verbose and bi % 10 == 0:
                #     pass
                print("oricain40")
                
                # âœ… åº”ç”¨æ—¶é—´æ‰“ä¹±ç´¢å¼•ï¼ˆå¯¹åº” MATLAB: Mixtures(:, permIdx(dataRange))ï¼‰
                perm_data_range = perm_idx[data_range]  # è·å–æ‰“ä¹±åçš„ç´¢å¼•
                
                print("mixtures[:, perm_data_range].shape",mixtures[:, perm_data_range].shape)
                print("mixtures[:, perm_data_range]",mixtures[:, perm_data_range][0:3,0:3])
                print("data_range",data_range)
                print("perm_data_range",perm_data_range[:10] if len(perm_data_range) > 10 else perm_data_range)

                print("state['icasphere'].shape",state['icasphere'].shape)
                print("state['icasphere']",state['icasphere'][0:3,0:3])

                print("state['icaweights'].shape",state['icaweights'].shape)
                print("state['icaweights']",state['icaweights'][0:3,0:3])
                print("gamma",gamma)
                print("lambda_0",lambda_0)

                # save_txt("3.txt",data[:, data_range])
                # âœ… ä½¿ç”¨æ‰“ä¹±åçš„æ•°æ®ç´¢å¼•
                state=self.dynamic_orica_cooling(mixtures[:, perm_data_range], data_range+1, state, gamma, lambda_0)
                
                # countxxx=0
                # #print("data[:, data_range].shape",data[:, data_range].shape)
                # # ORICAæŒ‰1ä¸ªæ ·æœ¬ä¸ºå•ä½å¤„ç†ï¼ˆç¡®ä¿block_size_ica=1ï¼‰
                # for sample_idx in range(data[:, data_range].shape[1]):
                #     countxxx+=1
                #     #print("coyuntersssxx",countxxx)
                #     single_sample = data[:, data_range][:, sample_idx:sample_idx+1]  # å–å•ä¸ªæ ·æœ¬
                #     single_range = np.array([data_range[sample_idx]])  # å¯¹åº”çš„ç´¢å¼•
                #     state = self.dynamic_orica_cooling(single_sample, single_range+1, state, gamma, lambda_0)
                



                # Xx = np.asarray(data[:, data_range], dtype=np.float64)
                # n_chsxxx, n_ptsxxx = Xx.shape
                # state['counter'] += n_ptsxxx

                
        
                # save_txt("4.txt",state['icaweights'])
                # print("finalweights",state['icaweights'])
                # print("finalsphere",state['icasphere'])





        if verbose:
            elapsed_time = time.time() - start_time


        print("=====================after orica============================")




        #mixtures = state['icasphere'] @ data
        print("mixtures.shape",mixtures.shape)
        print("mixtures",mixtures[0:3,0:3])

        icaact=state['icaweights'] @ mixtures
        print("icaact.shape",icaact.shape)
        print("icaact",icaact[0:3,0:3])


        
        print("state['icasphere']_out.shape",state['icasphere'].shape)
        print("state['icasphere']_out",state['icasphere'][0:3,0:3])
        print("state['icaweights']_out.shape",state['icaweights'].shape)
        print("state['icaweights']_out",state['icaweights'][0:3,0:3])


        print("bigbigbig")

        print("oricain3")
        print("mixtures.shape",mixtures.shape)
        print("mixtures",mixtures[0:3,0:3])
        print("icasphere_shape",state['icasphere'].shape)
        print("icasphere",state['icasphere'][0:3,0:3])
        print("icaweights_shape",state['icaweights'].shape)
        print("icaweights",state['icaweights'][0:3,0:3])
        print("data.shape",data.shape)
        print("data",data[0:3,0:3])
        print("icaact_shape",icaact.shape)
        print("icaact",icaact[0:3,0:3])
        


        self.record=state['icaweights']
        self.counter=state['counter']
        # print('self.counter',self.counter)
        # print('state[counter]',state['counter'])

        self.Rn=state['Rn']
        #print('self.Rn',self.Rn)

        self.lambda_k=state['lambda_k']


        return state['icaweights'], state['icasphere']





    def fit(self,data,
            block_size_white=16,
            num_pass=1,
            lambda_0=0.5,
            gamma=0.6,
            lambda_const=0.95,
            verbose=False):
        """
        ç”¨ ORICA_final.py ä¸­çš„ orica_rls_whitening è¿›è¡Œç™½åŒ–+ORICAï¼Œå¹¶è¿”å›æºä¿¡å·ï¼ˆsourcesï¼‰ã€‚
        - è¾“å…¥:
        data: np.ndarray, shape = (samples, channels)
        - è¿”å›:
        sources: np.ndarray, shape = (samples, components)  # ä¸è¾“å…¥ samples å¯¹é½
        weights: np.ndarray, shape = (components, components)  # icaweights
        sphere:  np.ndarray, shape = (components, components)  # icasphere
        """
        assert isinstance(data, np.ndarray) and data.ndim == 2, "dataå¿…é¡»æ˜¯(samples, channels)çš„äºŒç»´ndarray"

        # ç»Ÿä¸€åˆ° (channels, samples)
        X = data.T.astype(np.float64, copy=False)

        # è°ƒç”¨ä½ æ–‡ä»¶å†…çš„ç™½åŒ–+ORICAä¸»æµç¨‹ï¼Œå¾—åˆ°æƒé‡å’Œç™½åŒ–çŸ©é˜µ




        weights, sphere = self.orica_rls_whitening(
            X,
            block_size_white=block_size_white,
            num_pass=num_pass,
            lambda_0=lambda_0,
            gamma=gamma,
            lambda_const=lambda_const,
            verbose=verbose
        )


        # y_orica = weights @ sphere @ X
        X_whitened = sphere @ X
        sources = weights @ X_whitened

        self.whitening_matrix = sphere
        
        self.W = weights





        # è¿”å›ä¸º (samples, components)
        return sources, weights, sphere


    def transform(self, X):
        """å˜æ¢æ•°æ®"""
        X_whitened = X @ self.whitening_matrix.T
        Y = (self.W @ X_whitened.T).T
        return Y

    
    def inverse_transform(self, Y):
        """é€†å˜æ¢"""
        Xw = np.linalg.pinv(self.W) @ Y.T
        X = Xw.T @ np.linalg.pinv(self.whitening_matrix).T 
        return X


    def get_W(self):
        """è·å–è§£æ··çŸ©é˜µ"""
        return self.W

    def get_whitening_matrix(self):
        """è·å–ç™½åŒ–çŸ©é˜µ"""
        return self.whitening_matrix

    def get_icawinv(self):
        """è·å–ICAé€†çŸ©é˜µ"""
        return self.W @ self.whitening_matrix

    def get_sources(self):
        """è·å–æºä¿¡å·"""
        return self.sources

    def evaluate_separation(self, Y):
        """è¯„ä¼°åˆ†ç¦»æ•ˆæœ - ä½¿ç”¨å³°åº¦"""
        k = kurtosis(Y, axis=0, fisher=False)
        return k

    def rank_components_by_kurtosis(self, Y):
        """æŒ‰å³°åº¦æ’åºæˆåˆ†"""
        k = self.evaluate_separation(Y)
        indices = np.argsort(-np.abs(k))
        return indices, k

    def calc_mutual_info_matrix(self, sources):
        """è®¡ç®—äº’ä¿¡æ¯çŸ©é˜µ"""
        n = sources.shape[0]
        MI = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if i != j:
                    MI[i, j] = mutual_info_regression(
                        sources[i, :].reshape(-1, 1), sources[j, :]
                    )[0]
        return MI

    def set_nonlinearity(self, nonlinearity):
        """è®¾ç½®éçº¿æ€§å‡½æ•°ç±»å‹"""
        if nonlinearity not in ['gaussian', 'tanh']:
            raise ValueError("nonlinearity must be 'gaussian' or 'tanh'")
        self.nonlinearity = nonlinearity

    def set_forgetting_factor(self, forgetting_factor):
        """è®¾ç½®RLSé—å¿˜å› å­"""
        if not (0 < forgetting_factor < 1):
            raise ValueError("forgetting_factor must be between 0 and 1")
        self.forgetting_factor = forgetting_factor


if __name__ == "__main__":
    print("single chunk test")




    import os
    import numpy as np
    from scipy.io import loadmat

    set_path = r"D:\work\Python_Project\ORICA\temp_txt\Demo_EmotivEPOC_EyeOpen.set"

    S = loadmat(set_path, squeeze_me=True, struct_as_record=False)
    EEG = S["EEG"]
    print("EEG",EEG)




    def _get(obj, name):
        # å…¼å®¹ scipy åŠ è½½æˆå¯¹è±¡æˆ–å­—å…¸çš„ä¸¤ç§æƒ…å†µ
        return getattr(obj, name) if hasattr(obj, name) else obj[name]

    nbchan = int(_get(EEG, 'nbchan'))
    pnts   = int(_get(EEG, 'pnts'))
    data_f = _get(EEG, 'data')  # å¤–éƒ¨ .fdt æ–‡ä»¶åæˆ–ç›´æ¥å†…åµŒçŸ©é˜µ\

    icapshere_f = _get(EEG, 'icasphere')
    icaweights_f = _get(EEG, 'icaweights')




    if isinstance(data_f, (str, bytes, np.str_)):
        fdt_path = data_f if os.path.isabs(data_f) else os.path.join(os.path.dirname(set_path), data_f)
        # ç›´æ¥è¯»å– .fdt çš„åŸå§‹ float32ï¼ˆEEGLAB æŒ‰åˆ—å†™å…¥ï¼‰â†’ é‡å¡‘ä¸º (channels, time)
        X = np.fromfile(fdt_path, dtype='<f4', count=nbchan * pnts).reshape((nbchan, pnts), order='F')
    else:
        # å°‘è§ï¼šæ•°æ®å†…åµŒåœ¨ .set
        X = np.asarray(data_f, dtype=np.float32, order='F')

    X = X.astype(np.float64, copy=False)   # float32â†’float64 æ˜¯ç²¾ç¡®æ˜ å°„
    print("X",X.shape)
    print(X[0:3,0:3])


    """
    æˆªå–æ•°æ® 60s
    """
    # é‡‡æ ·ç‡ä¸æ—¶é—´è½´èµ·ç‚¹ï¼ˆç§’ï¼‰
    srate = float(EEG.srate)
    xmin  = float(getattr(EEG, "xmin", 0.0))  # EEGLAB é€šå¸¸æ˜¯ 0ï¼›è‹¥ä¸æ˜¯ 0 éœ€è€ƒè™‘åç§»

    # è¯»å– dataï¼šå¯èƒ½æ˜¯å†…å­˜çŸ©é˜µï¼Œä¹Ÿå¯èƒ½æ˜¯æŒ‡å‘ .fdt çš„æ–‡ä»¶å
    if isinstance(EEG.data, np.ndarray):
        data = EEG.data.astype(np.float32, copy=False)
    else:
        # data æ˜¯ .fdt æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹ .setï¼‰
        fdt_rel = str(EEG.data)
        fdt_path = os.path.join(os.path.dirname(set_path), fdt_rel)
        nbchan = int(EEG.nbchan)
        pnts   = int(EEG.pnts)
        flat = np.fromfile(fdt_path, dtype="<f4", count=nbchan * pnts)  # float32, little-endian
        # EEGLAB çº¿æ€§å­˜å‚¨ä¸ºåˆ—ä¸»åºï¼ˆæ ·æœ¬ä¸ºåˆ—ï¼‰ï¼Œç”¨ order='F' å¤åŸä¸º (channels, samples)
        data = flat.reshape((nbchan, pnts), order="F")

        icasphere_ff = EEG.icasphere
        icaweights_ff = EEG.icaweights

    print("data shape:", data.shape, "srate:", srate, "xmin:", xmin)

    # å®šä¹‰æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ï¼šç­‰ä»·äº pop_select(...,'time',[0, 60])
    window = (0.0, 60.0)  # (t0, t1)

    # è‹¥ç»™å®šæ ‡é‡ Tï¼ŒæŒ‰ [0, T]
    if np.isscalar(window):
        t0, t1 = 0.0, float(window)
    else:
        t0, t1 = map(float, window)

    # å°†æ—¶é—´è½¬ä¸ºé‡‡æ ·ä¸‹æ ‡ï¼ˆè€ƒè™‘ xmin åç§»ï¼‰ï¼Œå«èµ·å§‹ã€å«ç»“æŸï¼ˆå°½é‡å¯¹é½ EEGLAB è¡Œä¸ºï¼‰
    start = max(0, int(np.floor((t0 - xmin) * srate)))
    end   = int(np.floor((t1 - xmin) * srate))  # å³å¼€æˆ–å³é—­å‡å¯ï¼›è¿™é‡Œå…ˆå³å¼€
    end   = min(end, data.shape[1])

    win_data = data[:, start:end]

    print("data",data.shape)
    print("data",data[0:3,0:3])
    print("icapshere_ff",icasphere_ff.shape)
    print("icapshere_ff",icasphere_ff[0:3,0:3])
    print("icaweights_ff",icaweights_ff.shape)
    print("icaweights_ff",icaweights_ff[0:3,0:3])

    print("windowed data:", win_data.shape)
    print("windowed data",win_data[0:3,0:3])





    X = win_data
    # ç¡®ä¿æ•°æ®æ˜¯ (samples, channels) æ ¼å¼
    if X.shape[0] < X.shape[1]:
        X = X.T
    print(f"è°ƒæ•´åçš„æ•°æ®å½¢çŠ¶: {X.shape}")

        # åˆ›å»º ORICA å®ä¾‹
    #n_components = min(X.shape[1], 14)  # ä½¿ç”¨é€šé“æ•°æˆ–14ï¼Œå–è¾ƒå°å€¼
    n_components = X.shape[1]
    orica = ORICA_final_new(
        n_components=n_components,
        learning_rate=0.001,
        use_rls_whitening=True,
        block_size_white=8,
        block_size_ica=1,
        gamma=0.6,
        lambda_0=0.995,
        verbose=True
    )
    
    print("å¼€å§‹ ORICA å¤„ç†...")
    # ä½¿ç”¨ ORICA å¤„ç†æ•°æ®
    sources, weights, sphere = orica.fit(
        X,
        block_size_white=8,
        num_pass=1,
        lambda_0=0.995,
        gamma=0.6,
        lambda_const=0.95,
        verbose=True
    )
    
    print(f"å¤„ç†å®Œæˆ!")
    print(f"æºä¿¡å·å½¢çŠ¶: {sources.shape}")
    print(f"æºä¿¡å·: {sources[0:3,0:3]}")
    print(f"ç™½åŒ–çŸ©é˜µå½¢çŠ¶: {sphere.shape}")
    print(f"ç™½åŒ–çŸ©é˜µ: {sphere[0:3,0:3]}")
    print(f"æƒé‡çŸ©é˜µå½¢çŠ¶: {weights.shape}")
    print(f"æƒé‡çŸ©é˜µ: {weights[0:3,0:3]}")












    # åŠ è½½æ•°æ®
    data_dict = scipy.io.loadmat(r'D:\work\matlab_project\REST\X.mat')
    X = data_dict['X']  # å‡è®¾æ•°æ®å­˜å‚¨åœ¨ 'X' é”®ä¸­
    print(f"åŠ è½½çš„æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"åŠ è½½çš„æ•°æ®: {X[0:3,0:3]}")
    
    # ç¡®ä¿æ•°æ®æ˜¯ (samples, channels) æ ¼å¼
    if X.shape[0] < X.shape[1]:
        X = X.T
    print(f"è°ƒæ•´åçš„æ•°æ®å½¢çŠ¶: {X.shape}")
    
    # åˆ›å»º ORICA å®ä¾‹
    #n_components = min(X.shape[1], 14)  # ä½¿ç”¨é€šé“æ•°æˆ–14ï¼Œå–è¾ƒå°å€¼
    n_components = X.shape[1]
    orica = ORICA_final_new(
        n_components=n_components,
        learning_rate=0.001,
        use_rls_whitening=True,
        block_size_white=8,
        block_size_ica=1,
        gamma=0.6,
        lambda_0=0.995,
        verbose=True
    )
    
    print("å¼€å§‹ ORICA å¤„ç†...")
    # ä½¿ç”¨ ORICA å¤„ç†æ•°æ®
    sources, weights, sphere = orica.fit(
        X,
        block_size_white=8,
        num_pass=1,
        lambda_0=0.995,
        gamma=0.6,
        lambda_const=0.95,
        verbose=True
    )
    
    print(f"å¤„ç†å®Œæˆ!")
    print(f"æºä¿¡å·å½¢çŠ¶: {sources.shape}")
    print(f"æºä¿¡å·: {sources[0:3,0:3]}")
    print(f"ç™½åŒ–çŸ©é˜µå½¢çŠ¶: {sphere.shape}")
    print(f"ç™½åŒ–çŸ©é˜µ: {sphere[0:3,0:3]}")
    print(f"æƒé‡çŸ©é˜µå½¢çŠ¶: {weights.shape}")
    print(f"æƒé‡çŸ©é˜µ: {weights[0:3,0:3]}")

    # ä¿å­˜ç»“æœ
    output_file = r'D:\work\Python_Project\ORICA\temp_txt\orica_results_X.mat'
    scipy.io.savemat(output_file, {
        'sources': sources,
        'weights': weights,
        'sphere': sphere,
        'X_original': X
    })
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # è¯„ä¼°åˆ†ç¦»æ•ˆæœ
    print("\n=== åˆ†ç¦»æ•ˆæœè¯„ä¼° ===")
    kurtosis_values = orica.evaluate_separation(sources.T)
    print(f"å³°åº¦å€¼: {kurtosis_values}")
    print(f"å¹³å‡å³°åº¦: {np.mean(np.abs(kurtosis_values)):.4f}")
    
    # è®¡ç®—äº’ä¿¡æ¯
    if sources.shape[1] <= 10:  # åªå¯¹å°‘é‡æˆåˆ†è®¡ç®—äº’ä¿¡æ¯
        mi_matrix = orica.calc_mutual_info_matrix(sources.T)
        print(f"äº’ä¿¡æ¯çŸ©é˜µå¯¹è§’çº¿å¤–å‡å€¼: {np.mean(mi_matrix[np.triu_indices_from(mi_matrix, k=1)]):.4f}")
    
    print("ORICA å¤„ç†å®Œæˆ!")






'''
1.å…³äºä½¿ç”¨dynamic_whiteningä¹‹å‰åšçš„ç™½åŒ–çš„é—®é¢˜
åœ¨orica.mä¸­æœ‰ä¸€è¡Œæ˜¯åšäº†è¿™ä¸ªç™½åŒ–è¿‡ç¨‹ï¼Œé‚£ä¹ˆç”¨äºç™½åŒ–çš„icasphereå¿…ç„¶æ˜¯ä¸Šä¸€ä¸ªchunkçš„ç™½åŒ–çŸ©é˜µæˆ–è€…æ˜¯åˆå§‹çŸ©é˜µã€‚ï¼ˆåœ¨offlineä¸­æ˜¯ä½†ä¸ºé˜µï¼‰
ä½†æ˜¯æˆ‘å†flt_orica.mä¸­æ²¡æœ‰æ‰¾åˆ°è¿™ä¸ªç™½åŒ–è¿‡ç¨‹ã€‚

2.å…³äº



'''