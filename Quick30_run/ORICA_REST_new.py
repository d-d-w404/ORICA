import numpy as np
from scipy.stats import kurtosis
from sklearn.feature_selection import mutual_info_regression
from ORICA_calibration import ORICACalibration
from scipy.linalg import sqrtm

class ORICAZ:
    def __init__(self, n_components, learning_rate=0.001, ortho_every=10, 
                 use_rls_whitening=False, forgetting_factor=0.98, 
                 nonlinearity='gaussian', block_size_ica=8, block_size_white=8,
                 ff_profile='cooling', tau_const=np.inf, gamma=0.6, lambda_0=0.995,
                 num_subgaussian=0, eval_convergence=True, verbose=False):
        """
        ORICA with RLS whitening support - åŸºäºMATLAB orica.må®ç°
        
        Args:
            n_components: ç‹¬ç«‹æˆåˆ†æ•°é‡
            learning_rate: å­¦ä¹ ç‡
            ortho_every: æ¯éš”å¤šå°‘æ¬¡è¿­ä»£æ­£äº¤åŒ–
            use_rls_whitening: æ˜¯å¦ä½¿ç”¨RLSç™½åŒ–
            forgetting_factor: RLSé—å¿˜å› å­ (0 < Î» < 1)
            nonlinearity: éçº¿æ€§å‡½æ•°ç±»å‹ ('gaussian', 'tanh')
            block_size_ica: ICAå—å¤§å°
            block_size_white: ç™½åŒ–å—å¤§å°
            ff_profile: é—å¿˜å› å­ç­–ç•¥ ('cooling', 'constant', 'adaptive')
            tau_const: å±€éƒ¨å¹³ç¨³æ€§å‚æ•°
            gamma: å†·å´ç­–ç•¥å‚æ•°
            lambda_0: åˆå§‹é—å¿˜å› å­
            num_subgaussian: æ¬¡é«˜æ–¯æºæ•°é‡
            eval_convergence: æ˜¯å¦è¯„ä¼°æ”¶æ•›æ€§
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        self.n_components = n_components
        self.learning_rate = learning_rate
        self.W = np.eye(n_components)  # è§£æ··çŸ©é˜µ (icaweights)
        self.mean = None
        self.whitening_matrix = None  # icasphere
        self.whitened = False
        self.update_count = 0
        self.ortho_every = ortho_every
        
        # å—æ›´æ–°å‚æ•°
        self.block_size_ica = block_size_ica
        self.block_size_white = block_size_white
        
        # é—å¿˜å› å­å‚æ•°
        self.ff_profile = ff_profile
        self.tau_const = tau_const
        self.gamma = gamma
        self.lambda_0 = lambda_0
        self.lambda_const = 1 - np.exp(-1/tau_const) if tau_const != np.inf else 0.98
        
        # æ¬¡é«˜æ–¯æºå‚æ•°
        self.num_subgaussian = num_subgaussian
        self.kurtosis_sign = np.ones(n_components, dtype=bool)  # Trueä¸ºè¶…é«˜æ–¯
        if num_subgaussian > 0:
            self.kurtosis_sign[:num_subgaussian] = False
        
        # æ”¶æ•›æ€§è¯„ä¼°
        self.eval_convergence = eval_convergence
        self.leaky_avg_delta = 0.01
        self.leaky_avg_delta_var = 1e-3
        self.Rn = None
        self.non_stat_idx = None
        self.min_non_stat_idx = None
        
        # çŠ¶æ€å˜é‡
        self.lambda_k = np.zeros(block_size_ica)
        self.counter = 0
        
        # RLSç™½åŒ–å‚æ•°
        self.use_rls_whitening = use_rls_whitening
        self.forgetting_factor = forgetting_factor
        self.nonlinearity = nonlinearity
        
        # RLSç™½åŒ–ç›¸å…³å˜é‡
        if self.use_rls_whitening:
            self.C = None  # åæ–¹å·®çŸ©é˜µçš„é€†
            self.t = 0     # æ—¶é—´æ­¥è®¡æ•°å™¨
            
        self.verbose = verbose

    def _center(self, X):
        """å»å‡å€¼"""
        if self.mean is None:
            self.mean = np.mean(X, axis=0)
        return X - self.mean

    def _whiten(self, X):
        """ä¼ ç»Ÿæ‰¹é‡ç™½åŒ– - ä½¿ç”¨ç‰¹å¾å€¼åˆ†è§£"""
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if X.shape[0] < 2:
            print(f"âš ï¸ ç™½åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {X.shape[0]}ï¼Œè·³è¿‡ç™½åŒ–")
            return X
        
        try:
            # cov = np.cov(X, rowvar=False)
            # d, E = np.linalg.eigh(cov)
            # D_inv = np.diag(1.0 / np.sqrt(d + 1e-2))  # é˜²æ­¢é™¤0
            # self.whitening_matrix = E @ D_inv @ E.T

            cov = np.cov(X, rowvar=False)
            self.whitening_matrix=2.0 *np.linalg.inv(sqrtm(cov))


            return X @ self.whitening_matrix.T
        except Exception as e:
            print(f"âš ï¸ ç™½åŒ–å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹æ•°æ®")
            return X

    def _rls_whiten_initialize(self, X):
        """åˆå§‹åŒ–RLSç™½åŒ–"""
        # Xçš„å½¢çŠ¶æ˜¯ (samples, channels)ï¼Œéœ€è¦è½¬ç½®ä¸º (channels, samples)
        # if X.shape[0] < X.shape[1]:  # å¦‚æœç¬¬ä¸€ä¸ªç»´åº¦å°äºç¬¬äºŒä¸ªç»´åº¦ï¼Œè¯´æ˜æ˜¯ (samples, channels)
        #     n_channels = X.shape[1]
        # else:
        n_channels = X.shape[1]
        
        # åˆå§‹åŒ–åæ–¹å·®çŸ©é˜µçš„é€†ä¸ºå•ä½çŸ©é˜µ
        self.C = np.eye(n_channels)
        self.whitening_matrix = np.eye(n_channels)
        self.t = 0
        print(f"ğŸ”§ RLSç™½åŒ–åˆå§‹åŒ–: é€šé“æ•°={n_channels}, CçŸ©é˜µå½¢çŠ¶={self.C.shape}")

    def _rls_whiten_update(self, x_t):
        """
        RLSç™½åŒ–å•æ­¥æ›´æ–°
        
        Args:
            x_t: å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ® (n_channels, 1)
        """
        if self.C is None:
            raise ValueError("RLS whitening not initialized. Call initialize() first.")
        
        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        expected_channels = self.C.shape[0]
        actual_channels = x_t.shape[0]
        
        if expected_channels != actual_channels:
            print(f"âš ï¸ RLSç™½åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{expected_channels}é€šé“ï¼Œå®é™…{actual_channels}é€šé“")
            # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.C = np.eye(actual_channels)
            self.whitening_matrix = np.eye(actual_channels)
            self.t = 0
            print(f"âœ… é‡æ–°åˆå§‹åŒ–RLSç™½åŒ–ï¼Œæ–°ç»´åº¦: {actual_channels}")
        
        # RLSæ›´æ–°è§„åˆ™
        lambda_t = self.forgetting_factor
        self.t += 1
        
        # è®¡ç®—å¢ç›Šå‘é‡
        k = self.C @ x_t
        denominator = lambda_t + x_t.T @ k
        k = k / denominator
        
        # æ›´æ–°åæ–¹å·®çŸ©é˜µçš„é€†
        self.C = (self.C - k @ x_t.T @ self.C) / lambda_t
        
        # æ›´æ–°ç™½åŒ–çŸ©é˜µ
        # ç™½åŒ–çŸ©é˜µæ˜¯åæ–¹å·®çŸ©é˜µé€†çš„å¹³æ–¹æ ¹
        eigenvals, eigenvecs = np.linalg.eigh(self.C)
        eigenvals = np.maximum(eigenvals, 1e-6)  # é˜²æ­¢è´Ÿå€¼
        self.whitening_matrix = eigenvecs @ np.diag(np.sqrt(eigenvals)) @ eigenvecs.T
        
        # è¿”å›ç™½åŒ–åçš„æ•°æ®
        return self.whitening_matrix @ x_t

    def _g(self, y):
        """
        éçº¿æ€§å‡½æ•°
        
        Args:
            y: è¾“å…¥ä¿¡å·
            
        Returns:
            g_y: éçº¿æ€§å‡½æ•°å€¼
            g_prime: å¯¼æ•°
        """
        if self.nonlinearity == 'gaussian':
            # é«˜æ–¯éçº¿æ€§å‡½æ•°
            g_y = y * np.exp(-0.5 * y**2)
            g_prime = (1 - y**2) * np.exp(-0.5 * y**2)
        elif self.nonlinearity == 'tanh':
            # åŒæ›²æ­£åˆ‡éçº¿æ€§å‡½æ•°
            g_y = np.tanh(y)
            g_prime = 1 - np.tanh(y)**2
        else:
            raise ValueError(f"Unknown nonlinearity: {self.nonlinearity}")
        
        return g_y, g_prime

    def _gen_cooling_ff(self, t):
        """ç”Ÿæˆå†·å´é—å¿˜å› å­ - å¯¹åº”MATLABçš„genCoolingFF"""
        return self.lambda_0 / (t ** self.gamma)
    
    def _gen_adaptive_ff(self, data_range, ratio_of_norm_rn):
        """ç”Ÿæˆè‡ªé€‚åº”é—å¿˜å› å­ - å¯¹åº”MATLABçš„genAdaptiveFF"""
        # è‡ªé€‚åº”ç­–ç•¥å‚æ•°
        decay_rate_alpha = 0.02
        upper_bound_beta = 1e-3
        trans_band_width_gamma = 1
        trans_band_center = 5
        
        # æ£€æŸ¥lambda_kæ˜¯å¦ä¸ºç©º
        if len(self.lambda_k) == 0:
            print("âš ï¸ lambda_kä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return np.full(len(data_range), self.lambda_const)
        
        gain_for_errors = upper_bound_beta * 0.5 * (1 + np.tanh((ratio_of_norm_rn - trans_band_center) / trans_band_width_gamma))
        
        def f(n):
            return ((1 + gain_for_errors) ** n) * self.lambda_k[-1] - \
                   decay_rate_alpha * (((1 + gain_for_errors) ** (2*n-1)) - ((1 + gain_for_errors) ** (n-1))) / gain_for_errors * (self.lambda_k[-1] ** 2)
        
        return np.array([f(n) for n in range(1, len(data_range) + 1)])

    def initialize(self, X_init):
        """åˆå§‹åŒ–ORICA"""
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if X_init.shape[0] < 2:
            print(f"âš ï¸ åˆå§‹åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {X_init.shape[0]}ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return X_init
        
        # æ£€æŸ¥å¹¶è°ƒæ•´n_componentsä»¥åŒ¹é…æ•°æ®ç»´åº¦
        if X_init.shape[1] != self.n_components:  # X_initæ˜¯ (samples, channels) æ ¼å¼
            print(f"âš ï¸ åˆå§‹åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{X_init.shape[1]}é€šé“")
            self.n_components = X_init.shape[1]
            # é‡æ–°åˆ›å»ºWçŸ©é˜µä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.W = np.eye(self.n_components)
            print(f"âœ… è°ƒæ•´n_componentsä¸º{self.n_components}")
        
        try:
            # å»å‡å€¼
            #X_init = self._center(X_init)
            #ä¼¼ä¹np.covè‡ªå¸¦ä¸­å¿ƒåŒ–
            
            # ç™½åŒ–
            if self.use_rls_whitening:
                # ä½¿ç”¨RLSç™½åŒ–åˆå§‹åŒ–
                self._rls_whiten_initialize(X_init)
                # å¯¹åˆå§‹æ•°æ®è¿›è¡Œæ‰¹é‡ç™½åŒ–
                X_init = self._whiten(X_init)
            else:
                # ä½¿ç”¨ä¼ ç»Ÿæ‰¹é‡ç™½åŒ–
                X_init = self._whiten(X_init)
            
            self.whitened = True
            print(f"âœ… ORICAåˆå§‹åŒ–å®Œæˆ: n_components={self.n_components}, æ•°æ®å½¢çŠ¶={X_init.shape}")
        except Exception as e:
            print(f"âš ï¸ ORICAåˆå§‹åŒ–å¤±è´¥: {e}")
            self.whitened = False
        
        return X_init

    def partial_fit(self, x_t):
        """
        å•ä¸ªæ ·æœ¬åœ¨çº¿æ›´æ–°
        
        Args:
            x_t: å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ® (n_channels,)
        """
        try:
            x_t = x_t.reshape(-1, 1)# ä» (25,) å˜ä¸º (25, 1)
            if not self.whitened:
                raise ValueError("Must call `initialize` with initial batch before `partial_fit`.")
            
            # æ£€æŸ¥è¾“å…¥ç»´åº¦æ˜¯å¦ä¸å½“å‰æ¨¡å‹åŒ¹é…
            if x_t.shape[0] != self.n_components:
                print(f"âš ï¸ partial_fitç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{x_t.shape[0]}é€šé“")
                # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
                self.n_components = x_t.shape[0]
                self.W = np.eye(self.n_components)
                # é‡æ–°åˆå§‹åŒ–ç™½åŒ–
                if self.use_rls_whitening:
                    self.C = np.eye(self.n_components)
                    self.whitening_matrix = np.eye(self.n_components)
                    self.t = 0
                else:
                    self.whitening_matrix = np.eye(self.n_components)
                print(f"âœ… é‡æ–°åˆå§‹åŒ–ORICAï¼Œæ–°ç»´åº¦: {self.n_components}")
            
            # å»å‡å€¼
            if self.mean is not None and self.mean.shape[0] == x_t.shape[0]:
                x_t = x_t - self.mean.reshape(-1, 1)
            else:
                # å¦‚æœmeanç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—
                print(f"âš ï¸ å‡å€¼ç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—")
                self.mean = np.zeros(x_t.shape[0])
            
            # ç™½åŒ–
            if self.use_rls_whitening:
                # RLSç™½åŒ–æ›´æ–°
                x_t_whitened = self._rls_whiten_update(x_t)
            else:
                # ä¼ ç»Ÿç™½åŒ–
                x_t_whitened = self.whitening_matrix @ x_t
            
            # ICAæ›´æ–°
            y_t = self.W @ x_t_whitened
            g_y, _ = self._g(y_t)
            
            # ORICAæ›´æ–°è§„åˆ™
            I = np.eye(self.n_components)
            delta_W = self.learning_rate * ((I - g_y @ y_t.T) @ self.W)
            self.W += delta_W

            # æ­£äº¤åŒ–
            self.update_count += 1
            if self.update_count % self.ortho_every == 0:
                U, _, Vt = np.linalg.svd(self.W)
                self.W = U @ Vt

            return y_t.ravel()
        except Exception as e:
            print(f"âš ï¸ partial_fitå¤±è´¥: {e}")
            return x_t.ravel() if hasattr(x_t, 'ravel') else x_t

    def partial_fit_new(self, x_t):
        """
        å—æ ·æœ¬åœ¨çº¿æ›´æ–° - èƒ½å¤Ÿå¤„ç†æŒ‡å®šé•¿åº¦çš„å—æ•°æ®
        
        Args:
            x_t: å—æ•°æ® (n_channels, block_size) æˆ– (n_channels,)
        """
        try:
            # æ£€æŸ¥è¾“å…¥å½¢çŠ¶
            if x_t.ndim == 1:
                # å¦‚æœæ˜¯å•ä¸ªæ ·æœ¬ï¼Œè½¬æ¢ä¸º (n_channels, 1)
                x_t = x_t.reshape(-1, 1)
                block_size = 1
            elif x_t.ndim == 2:
                # å¦‚æœæ˜¯å—æ•°æ® (n_channels, block_size)
                if x_t.shape[0] != x_t.shape[1]:  # ç¡®ä¿æ˜¯ (n_channels, block_size) æ ¼å¼
                    if x_t.shape[1] < x_t.shape[0]:  # å¦‚æœç¬¬äºŒä¸ªç»´åº¦æ›´å°ï¼Œè½¬ç½®
                        x_t = x_t.T
                block_size = x_t.shape[1]
            else:
                raise ValueError(f"è¾“å…¥æ•°æ®ç»´åº¦é”™è¯¯: {x_t.shape}ï¼ŒæœŸæœ› (n_channels,) æˆ– (n_channels, block_size)")
            
            if not self.whitened:
                raise ValueError("Must call `initialize` with initial batch before `partial_fit_new`.")
            
            # æ£€æŸ¥è¾“å…¥ç»´åº¦æ˜¯å¦ä¸å½“å‰æ¨¡å‹åŒ¹é…
            if x_t.shape[0] != self.n_components:
                print(f"âš ï¸ partial_fit_newç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{x_t.shape[0]}é€šé“")
                # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
                self.n_components = x_t.shape[0]
                self.W = np.eye(self.n_components)
                # é‡æ–°åˆå§‹åŒ–ç™½åŒ–
                if self.use_rls_whitening:
                    self.C = np.eye(self.n_components)
                    self.whitening_matrix = np.eye(self.n_components)
                    self.t = 0
                else:
                    self.whitening_matrix = np.eye(self.n_components)
                # é‡æ–°è®¡ç®—å‡å€¼
                self.mean = np.zeros(self.n_components)
                print(f"âœ… é‡æ–°åˆå§‹åŒ–ORICAï¼Œæ–°ç»´åº¦: {self.n_components}")
            
            # å»å‡å€¼ - å¯¹å—æ•°æ®åŒæ—¶å¤„ç†
            if self.mean is not None and self.mean.shape[0] == x_t.shape[0]:
                x_t = x_t - self.mean.reshape(-1, 1)
            else:
                # å¦‚æœmeanç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—
                print(f"âš ï¸ å‡å€¼ç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—")
                self.mean = np.zeros(x_t.shape[0])
                # ç¡®ä¿n_componentsä¹ŸåŒ¹é…
                if self.n_components != x_t.shape[0]:
                    self.n_components = x_t.shape[0]
                    self.W = np.eye(self.n_components)
                    if self.use_rls_whitening:
                        self.C = np.eye(self.n_components)
                        self.whitening_matrix = np.eye(self.n_components)
                        self.t = 0
                    else:
                        self.whitening_matrix = np.eye(self.n_components)
            
            # ç™½åŒ– - å¯¹å—æ•°æ®åŒæ—¶å¤„ç†
            if self.use_rls_whitening:
                # RLSç™½åŒ–æ›´æ–° - å¯¹æ¯ä¸ªæ ·æœ¬åˆ†åˆ«æ›´æ–°
                x_t_whitened = np.zeros_like(x_t)
                for i in range(block_size):
                    x_t_whitened[:, i:i+1] = self._rls_whiten_update(x_t[:, i:i+1])
            else:
                # ä¼ ç»Ÿç™½åŒ– - å¯¹å—æ•°æ®åŒæ—¶å¤„ç†
                x_t_whitened = self.whitening_matrix @ x_t
            
            # ICAæ›´æ–° - å¯¹å—æ•°æ®åŒæ—¶å¤„ç†
            y_t = self.W @ x_t_whitened  # shape: (n_components, block_size)
            
            # è®¡ç®—éçº¿æ€§å‡½æ•° - å¯¹å—æ•°æ®åŒæ—¶å¤„ç†
            g_y = np.zeros_like(y_t)
            g_prime = np.zeros_like(y_t)
            
            for i in range(block_size):
                g_y[:, i:i+1], g_prime[:, i:i+1] = self._g(y_t[:, i:i+1])
            
            # ORICAæ›´æ–°è§„åˆ™ - ä½¿ç”¨å—æ•°æ®çš„ç´¯ç§¯æ›´æ–°
            I = np.eye(self.n_components)
            
            # è®¡ç®—å—æ•°æ®çš„ç´¯ç§¯æ›´æ–°
            delta_W_total = np.zeros_like(self.W)
            for i in range(block_size):
                y_i = y_t[:, i:i+1]
                g_y_i = g_y[:, i:i+1]
                delta_W = self.learning_rate * ((I - g_y_i @ y_i.T) @ self.W)
                delta_W_total += delta_W
            
            # åº”ç”¨ç´¯ç§¯æ›´æ–°
            self.W += delta_W_total / block_size  # å¹³å‡æ›´æ–°
            
            # æ­£äº¤åŒ–
            self.update_count += block_size  # æ›´æ–°è®¡æ•°å¢åŠ block_size
            if self.update_count % self.ortho_every == 0:
                U, _, Vt = np.linalg.svd(self.W)
                self.W = U @ Vt

            return y_t  # è¿”å›æ•´ä¸ªå—çš„ç»“æœ (n_components, block_size)
            
        except Exception as e:
            print(f"âš ï¸ partial_fit_newå¤±è´¥: {e}")
            return x_t

    def fit_online_stream(self, data_stream, block_size=None):
        """
        åœ¨çº¿æµå¤„ç† - ä½¿ç”¨é€æ ·æœ¬æ›´æ–°è€Œéæ‰¹é‡å¤„ç†
        
        Args:
            data_stream: æ•°æ®æµ (samples, channels)
            block_size: å—å¤§å°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
        """
        try:
            if block_size is None:
                block_size = self.block_size_ica
            
        # æ£€æŸ¥æ•°æ®é•¿åº¦
            if data_stream.shape[0] < 1 or data_stream.shape[1] < 1:
                print(f"âš ï¸ æ•°æ®æµé•¿åº¦ä¸è¶³: {data_stream.shape}ï¼Œè¿”å›åŸå§‹æ•°æ®")
                return data_stream
            

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–
            if not self.whitened or self.whitening_matrix is None:
                print("âš ï¸ ORICAæœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–...")
                # ä½¿ç”¨å‰å‡ ä¸ªæ ·æœ¬è¿›è¡Œåˆå§‹åŒ–
                init_samples = min(block_size*2, data_stream.shape[0])
                if init_samples >= 2:
                    init_data = data_stream[:init_samples, :]
                    self.initialize(init_data)
                else:
                    print("âš ï¸ åˆå§‹åŒ–æ•°æ®ä¸è¶³ï¼Œè¿”å›åŸå§‹æ•°æ®")
                    return data_stream
            
            # ä½¿ç”¨å—å¤„ç†çš„æ–¹å¼å¤„ç†æ•°æ®æµ
            sources = []

            # for i in range(data_stream.shape[0]):
            #     x_t = data_stream[i, :]  # è·å–å•ä¸ªæ ·æœ¬ (n_channels,)
            #     y_t = self.partial_fit(x_t)  # è¿›è¡Œåœ¨çº¿å­¦ä¹ å¹¶è¿”å›æºä¿¡å·
            #     sources.append(y_t)

            # # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è½¬ç½®ä»¥åŒ¹é…æœŸæœ›çš„è¾“å‡ºæ ¼å¼
            # sources = np.array(sources)  # shape: (samples, components)
            # # è½¬ç½®ä»¥åŒ¹é…partial_fitæ–¹å¼çš„è¾“å‡ºæ ¼å¼: (components, samples)
            # sources = sources.T  # shape: (components, samples)
            # return sources

            # æŒ‰å—å¤§å°å¤„ç†æ•°æ®
            n_samples = data_stream.shape[0]
            for i in range(0, n_samples, block_size):
                # è·å–å½“å‰å—çš„æ•°æ®
                end_idx = min(i + block_size, n_samples)
                current_block = data_stream[i:end_idx, :]  # (current_block_size, channels)
                
                # è½¬ç½®ä¸º (channels, current_block_size) æ ¼å¼
                current_block_transposed = current_block.T
                
                # ä½¿ç”¨ partial_fit_new è¿›è¡Œå—å¤„ç†
                y_t = self.partial_fit_new(current_block_transposed)
                
                # å°†ç»“æœæ·»åŠ åˆ°sourcesä¸­
                if y_t.ndim == 2:
                    # å¦‚æœè¿”å›çš„æ˜¯å—ç»“æœ (channels, current_block_size)
                    sources.append(y_t.T)  # è½¬ç½®ä¸º (current_block_size, channels)
                else:
                    # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªç»“æœï¼Œè½¬æ¢ä¸º (1, channels)
                    sources.append(y_t.reshape(1, -1))
            
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            if sources:
                sources = np.vstack(sources)  # shape: (total_samples, components)
                # è½¬ç½®ä»¥åŒ¹é…æœŸæœ›çš„è¾“å‡ºæ ¼å¼: (components, total_samples)
                sources = sources.T
                return sources
            else:
                return data_stream

            
            

                
        except Exception as e:
            print(f"âš ï¸ fit_online_streamå¤±è´¥: {e}")
            return data_stream




    def transform(self, X):
        """å˜æ¢æ•°æ®"""
        try:
            if not self.whitened:
                raise ValueError("Model must be initialized first with `initialize()`.")
            
            # æ£€æŸ¥æ•°æ®é•¿åº¦
            if X.shape[0] < 1:
                print(f"âš ï¸ å˜æ¢æ•°æ®é•¿åº¦ä¸è¶³: {X.shape[0]}")
                return X
            
            # æ£€æŸ¥ç»´åº¦åŒ¹é…
            if self.mean is not None and self.mean.shape[0] != X.shape[1]:
                print(f"âš ï¸ å‡å€¼ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{X.shape[1]}ï¼Œå®é™…{self.mean.shape[0]}")
                # é‡æ–°è®¡ç®—å‡å€¼
                self.mean = np.mean(X, axis=0)
            
            # å»å‡å€¼
            if self.mean is not None:
                X = X - self.mean
            
            # ç™½åŒ–
            if self.use_rls_whitening:
                # ä½¿ç”¨å½“å‰çš„ç™½åŒ–çŸ©é˜µ
                X_whitened = X @ self.whitening_matrix.T
            else:
                # ä¼ ç»Ÿç™½åŒ–
                X_whitened = X @ self.whitening_matrix.T
            
            # ICAå˜æ¢
            Y = (self.W @ X_whitened.T).T
            return Y
        except Exception as e:
            print(f"âš ï¸ transformå¤±è´¥: {e}")
            return X

    def inverse_transform(self, Y):
        """é€†å˜æ¢"""
        Xw = np.linalg.pinv(self.W) @ Y.T
        X = Xw.T @ np.linalg.pinv(self.whitening_matrix).T + self.mean
        return X

    def get_W(self):
        """è·å–è§£æ··çŸ©é˜µ"""
        return self.W

    def get_whitening_matrix(self):
        """è·å–ç™½åŒ–çŸ©é˜µ"""
        return self.whitening_matrix

    def evaluate_separation(self, Y):
        """è¯„ä¼°åˆ†ç¦»æ•ˆæœ - ä½¿ç”¨å³°åº¦"""
        k = kurtosis(Y, axis=0, fisher=False)
        return k

    def rank_components_by_kurtosis(self, Y):
        """æŒ‰å³°åº¦æ’åºæˆåˆ†"""
        k = self.evaluate_separation(Y)
        indices = np.argsort(-np.abs(k))
        return indices, k

    def calc_mutual_info_matrix(self, sources):
        """è®¡ç®—äº’ä¿¡æ¯çŸ©é˜µ"""
        n = sources.shape[0]
        MI = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if i != j:
                    MI[i, j] = mutual_info_regression(
                        sources[i, :].reshape(-1, 1), sources[j, :]
                    )[0]
        return MI

    def set_nonlinearity(self, nonlinearity):
        """è®¾ç½®éçº¿æ€§å‡½æ•°ç±»å‹"""
        if nonlinearity not in ['gaussian', 'tanh']:
            raise ValueError("nonlinearity must be 'gaussian' or 'tanh'")
        self.nonlinearity = nonlinearity

    def set_forgetting_factor(self, forgetting_factor):
        """è®¾ç½®RLSé—å¿˜å› å­"""
        if not (0 < forgetting_factor < 1):
            raise ValueError("forgetting_factor must be between 0 and 1")
        self.forgetting_factor = forgetting_factor

    def _dynamic_whitening(self, block_data):
        """åŠ¨æ€ç™½åŒ– - å¯¹åº”MATLABçš„dynamicWhitening"""
        n_pts = block_data.shape[1]
        
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if n_pts < 2:
            print(f"âš ï¸ ç™½åŒ–æ•°æ®é•¿åº¦ä¸è¶³: {n_pts}ï¼Œè·³è¿‡ç™½åŒ–æ›´æ–°")
            return
        
        # å®šä¹‰è‡ªé€‚åº”é—å¿˜ç‡
        if self.ff_profile == 'cooling':
            lambda_vals = self._gen_cooling_ff(self.counter + np.arange(1, n_pts + 1))
            if lambda_vals[0] < self.lambda_const:
                lambda_vals = np.full(n_pts, self.lambda_const)
        elif self.ff_profile == 'constant':
            lambda_vals = np.full(n_pts, self.lambda_const)
        elif self.ff_profile == 'adaptive':
            lambda_vals = np.full(n_pts, self.lambda_k[-1] if len(self.lambda_k) > 0 else self.lambda_const)
        
        # ä½¿ç”¨åœ¨çº¿RLSç™½åŒ–å—æ›´æ–°è§„åˆ™æ›´æ–°çƒåŒ–çŸ©é˜µ
        v = self.whitening_matrix @ block_data  # é¢„ç™½åŒ–æ•°æ®
        lambda_avg = 1 - lambda_vals[n_pts // 2]  # ä¸­ä½æ•°lambda
        Q_white = lambda_avg / (1 - lambda_avg) + np.trace(v.T @ v) / n_pts
        self.whitening_matrix = (1 / lambda_avg) * (self.whitening_matrix - 
                                                   v @ v.T / n_pts / Q_white @ self.whitening_matrix)

    def _dynamic_orica(self, block_data):
        """åŠ¨æ€ORICA - å¯¹åº”MATLABçš„dynamicOrica"""
        n_chs, n_pts = block_data.shape
        
        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if n_pts < 2:
            print(f"âš ï¸ ORICAæ•°æ®é•¿åº¦ä¸è¶³: {n_pts}ï¼Œè·³è¿‡ORICAæ›´æ–°")
            return
        
        f = np.zeros((n_chs, n_pts))
        
        # ä½¿ç”¨å…ˆå‰çš„æƒé‡çŸ©é˜µè®¡ç®—æºæ¿€æ´»
        y = self.W @ block_data
        
        # ä¸ºè¶…é«˜æ–¯å’Œæ¬¡é«˜æ–¯é€‰æ‹©éçº¿æ€§å‡½æ•°
        f[self.kurtosis_sign, :] = -2 * np.tanh(y[self.kurtosis_sign, :])  # è¶…é«˜æ–¯
        f[~self.kurtosis_sign, :] = 2 * np.tanh(y[~self.kurtosis_sign, :])  # æ¬¡é«˜æ–¯
        
        # è®¡ç®—éå¹³ç¨³æ€§æŒ‡æ•°å’ŒæºåŠ¨æ€æ–¹å·®
        if self.eval_convergence:
            model_fitness = np.eye(n_chs) + y @ f.T / n_pts
            variance = block_data * block_data
            if self.Rn is None:
                self.Rn = model_fitness
            else:
                self.Rn = (1 - self.leaky_avg_delta) * self.Rn + self.leaky_avg_delta * model_fitness
            self.non_stat_idx = np.linalg.norm(self.Rn, 'fro')
        
        # è®¡ç®—é—å¿˜ç‡
        data_range = np.arange(1, n_pts + 1)
        if self.ff_profile == 'cooling':
            self.lambda_k = self._gen_cooling_ff(self.counter + data_range)
            if len(self.lambda_k) > 0 and self.lambda_k[0] < self.lambda_const:
                self.lambda_k = np.full(n_pts, self.lambda_const)
            self.counter += n_pts
        elif self.ff_profile == 'constant':
            self.lambda_k = np.full(n_pts, self.lambda_const)
        elif self.ff_profile == 'adaptive':
            if self.min_non_stat_idx is None:
                self.min_non_stat_idx = self.non_stat_idx
            self.min_non_stat_idx = max(min(self.min_non_stat_idx, self.non_stat_idx), 1)
            ratio_of_norm_rn = self.non_stat_idx / self.min_non_stat_idx
            self.lambda_k = self._gen_adaptive_ff(data_range, ratio_of_norm_rn)
        
        # ä½¿ç”¨åœ¨çº¿é€’å½’ICAå—æ›´æ–°è§„åˆ™æ›´æ–°æƒé‡çŸ©é˜µ
        lambda_prod = np.prod(1.0 / (1.0 - self.lambda_k))
        Q = 1 + self.lambda_k * (np.sum(f * y, axis=0) - 1)
        self.W = lambda_prod * (self.W - y @ np.diag(self.lambda_k / Q) @ f.T @ self.W)
        
        # æ­£äº¤åŒ–æƒé‡çŸ©é˜µ
        eigenvals, eigenvecs = np.linalg.eigh(self.W @ self.W.T)
        self.W = eigenvecs @ np.diag(1/np.sqrt(eigenvals)) @ eigenvecs.T @ self.W

    def fit_block(self, data, num_passes=1):
        """
        å—æ›´æ–°æ‹Ÿåˆ - å¯¹åº”MATLAB orica.mçš„ä¸»è¦é€»è¾‘
        
        Args:
            data: è¾“å…¥æ•°æ® (channels, samples)
            num_passes: æ•°æ®éå†æ¬¡æ•°
        """
        n_chs, n_pts = data.shape
        
        if self.verbose:
            print(f"ä½¿ç”¨{'åœ¨çº¿' if self.use_rls_whitening else 'ç¦»çº¿'}ç™½åŒ–æ–¹æ³•")
            print(f"è¿è¡ŒORICAï¼Œé—å¿˜å› å­ç­–ç•¥: {self.ff_profile}")
        
        # åˆå§‹åŒ–ç™½åŒ–
        if not self.use_rls_whitening:
            if self.verbose:
                print("ä½¿ç”¨é¢„ç™½åŒ–æ–¹æ³•")
            # é¢„ç™½åŒ–ï¼ˆå¯¹é€šé“åæ–¹å·®åšç‰¹å¾åˆ†è§£ç™½åŒ–ï¼Œé¿å…æ ·æœ¬ç»´åæ–¹å·®ä¸éæ³•çŸ©é˜µå¼€æ–¹ï¼‰
            # data å½¢çŠ¶ä¸º (channels, samples)ï¼Œè¿™é‡Œä»¥é€šé“ä¸ºå˜é‡æ±‚åæ–¹å·®
            # cov_matrix = np.cov(data, rowvar=True)
            # # ç¨³å®šçš„ç‰¹å¾åˆ†è§£ç™½åŒ–ï¼šE * diag(1/sqrt(d)) * E.T
            # evals, evecs = np.linalg.eigh(cov_matrix)
            # evals = np.maximum(evals, 1e-8)
            # D_inv_sqrt = np.diag(2.0 / np.sqrt(evals))
            # self.whitening_matrix = evecs @ D_inv_sqrt @ evecs.T


            cov = np.cov(data, rowvar=True)
            self.whitening_matrix=2.0 *np.linalg.inv(sqrtm(cov))


        # # åˆå§‹åŒ–ç™½åŒ–
        # if not self.use_rls_whitening:
        #     if self.verbose:
        #         print("ä½¿ç”¨é¢„ç™½åŒ–æ–¹æ³•")
        #     # é¢„ç™½åŒ–ï¼ˆå¯¹é€šé“åæ–¹å·®åšç‰¹å¾åˆ†è§£ç™½åŒ–ï¼Œé¿å…æ ·æœ¬ç»´åæ–¹å·®ä¸éæ³•çŸ©é˜µå¼€æ–¹ï¼‰
        #     # data å½¢çŠ¶ä¸º (channels, samples)ï¼Œè¿™é‡Œä»¥é€šé“ä¸ºå˜é‡æ±‚åæ–¹å·®
        #     cov_matrix = np.cov(data, rowvar=True)
        #     # ç¨³å®šçš„ç‰¹å¾åˆ†è§£ç™½åŒ–ï¼šE * diag(1/sqrt(d)) * E.T
        #     evals, evecs = np.linalg.eigh(cov_matrix)
        #     evals = np.maximum(evals, 1e-8)
        #     D_inv_sqrt = np.diag(1.0 / np.sqrt(evals))
        #     self.whitening_matrix = evecs @ D_inv_sqrt @ evecs.T



        # # åˆå§‹åŒ–ç™½åŒ–
        # if not self.use_rls_whitening:
        #     if self.verbose:
        #         print("ä½¿ç”¨é¢„ç™½åŒ–æ–¹æ³•")
        #     # é¢„ç™½åŒ–ï¼ˆå¯¹é€šé“åæ–¹å·®åšç‰¹å¾åˆ†è§£ç™½åŒ–ï¼Œä¸MATLAB orica.må®Œå…¨ä¸€è‡´ï¼‰
        #     # data å½¢çŠ¶ä¸º (channels, samples)ï¼Œè¿™é‡Œä»¥é€šé“ä¸ºå˜é‡æ±‚åæ–¹å·®
        #     # MATLAB: state.icasphere = 2.0*inv(sqrtm(double(cov(data'))))
        #     cov_matrix = np.cov(data, rowvar=True)
        #     # ç¨³å®šçš„ç‰¹å¾åˆ†è§£ç™½åŒ–ï¼šE * diag(1/sqrt(d)) * E.T
        #     evals, evecs = np.linalg.eigh(cov_matrix)
        #     evals = np.maximum(evals, 1e-8)
        #     D_inv_sqrt = np.diag(1.0 / np.sqrt(evals))
        #     sphere_matrix = evecs @ D_inv_sqrt @ evecs.T
        #     # æ·»åŠ 2.0ç³»æ•°ï¼Œä¸MATLABå®Œå…¨ä¸€è‡´
        #     self.whitening_matrix = 2.0 * sphere_matrix

        
        # ç™½åŒ–æ•°æ®
        data = self.whitening_matrix @ data
        
        # å°†æ•°æ®åˆ†æˆå—è¿›è¡Œåœ¨çº¿å—æ›´æ–°
        min_block_size = min(self.block_size_ica, self.block_size_white)
        num_blocks = n_pts // min_block_size
        
        if self.verbose:
            import time
            start_time = time.time()
        
        for it in range(num_passes):
            for bi in range(num_blocks):
                # è®¡ç®—æ•°æ®èŒƒå›´
                start_idx = bi * n_pts // num_blocks
                end_idx = min(n_pts, (bi + 1) * n_pts // num_blocks)
                data_range = slice(start_idx, end_idx)
                block_data = data[:, data_range]
                
                # åœ¨çº¿ç™½åŒ–
                if self.use_rls_whitening:
                    self._dynamic_whitening(block_data)
                    block_data = self.whitening_matrix @ block_data
                
                # åŠ¨æ€ORICA
                self._dynamic_orica(block_data)
                
                if self.verbose and bi % (num_blocks // 10) == 0:
                    progress = (it * num_blocks + bi) / (num_passes * num_blocks) * 100
                    print(f" è¿›åº¦: {progress:.0f}%")
        
        if self.verbose:
            elapsed_time = time.time() - start_time
            print(f"å®Œæˆã€‚è€—æ—¶: {elapsed_time:.2f} ç§’")
        
        return self.W, self.whitening_matrix



    def fit_block_stream(self, data_stream, block_size=None, num_passes=1):
        """
        ä½¿ç”¨ fit_block è¿›è¡Œè®­ç»ƒï¼Œä½†è¾“å…¥/è¾“å‡ºä¸ fit_online_stream ä¿æŒä¸€è‡´ã€‚
        
        Args:
            data_stream: numpy.ndarray, å½¢çŠ¶ (samples, channels)
            block_size: å¯é€‰ï¼Œå—å¤§å°ï¼›ä¸å½±å“ fit_block å†…éƒ¨é€»è¾‘ï¼Œä»…ç”¨äºä¸ fit_online_stream æ¥å£ä¸€è‡´
            num_passes: intï¼Œfit_block éå†æ•°æ®çš„æ¬¡æ•°
        
        Returns:
            sources: numpy.ndarray, å½¢çŠ¶ (components, samples)ï¼Œä¸ fit_online_stream è¿”å›ä¸€è‡´
        """
        try:
            # 1) å‚æ•°ä¸æ•°æ®æ£€æŸ¥
            if block_size is None:
                block_size = self.block_size_ica

            if not isinstance(data_stream, np.ndarray) or data_stream.ndim != 2:
                raise ValueError(f"data_streamå¿…é¡»æ˜¯äºŒç»´æ•°ç»„ (samples, channels)ï¼Œæ”¶åˆ°: {type(data_stream)}, ndim={getattr(data_stream, 'ndim', None)}")

            n_samples, n_channels = data_stream.shape
            if n_samples < 1 or n_channels < 1:
                print(f"âš ï¸ æ•°æ®æµé•¿åº¦ä¸è¶³: {data_stream.shape}ï¼Œè¿”å›åŸå§‹æ•°æ®")
                return data_stream

            # 2) ä¿è¯æ¨¡å‹ç»´åº¦ä¸è¾“å…¥é€šé“ä¸€è‡´
            if self.n_components != n_channels:
                print(f"âš ï¸ ç»´åº¦ä¸åŒ¹é…: æ¨¡å‹n_components={self.n_components}, è¾“å…¥channels={n_channels}ï¼Œè‡ªåŠ¨è°ƒæ•´")
                self.n_components = n_channels
                self.W = np.eye(self.n_components)
                self.whitening_matrix = np.eye(self.n_components)
                if self.use_rls_whitening:
                    self.C = np.eye(self.n_components)
                    self.t = 0

            # 3) å‡å€¼ï¼ˆfit_online_stream/transform ä¼šç”¨åˆ°ï¼‰ï¼Œç¡®ä¿ä¸å½“å‰é€šé“åŒ¹é…
            if self.mean is None or self.mean.shape[0] != n_channels:
                self.mean = np.mean(data_stream, axis=0)

            # 4) ä½¿ç”¨ fit_block è®­ç»ƒï¼ˆfit_block æœŸæœ›å½¢çŠ¶ä¸º (channels, samples)ï¼‰
            data_cs = data_stream.T  # (channels, samples)
            self.fit_block(data_cs, num_passes=num_passes)

            # 5) è®­ç»ƒå®Œæˆåï¼ŒæŒ‰ transform çš„æ–¹å¼ä¸€æ¬¡æ€§å¾—åˆ° sources
            #    ä¸ fit_online_stream è¿”å›ä¸€è‡´ï¼šå½¢çŠ¶ (components, samples)
            X = data_stream
            # å»å‡å€¼ï¼ˆä¸ transform ä¸€è‡´ï¼‰
            if self.mean is not None and self.mean.shape[0] == n_channels:
                X = X - self.mean

            # ä½¿ç”¨å½“å‰ç™½åŒ–çŸ©é˜µè¿›è¡Œç™½åŒ–ï¼ˆä¸ transform ä¸€è‡´ï¼‰
            X_whitened = X @ self.whitening_matrix.T  # (samples, channels)

            # åº”ç”¨å·²è®­ç»ƒå¥½çš„ W
            Y = (self.W @ X_whitened.T)  # (components, samples)

            return Y  # å½¢çŠ¶ (components, samples)
        except Exception as e:
            print(f"âš ï¸ fit_block_streamå¤±è´¥: {e}")
            return data_stream.T if isinstance(data_stream, np.ndarray) and data_stream.ndim == 2 else data_stream

# ä½¿ç”¨ç¤ºä¾‹å’Œè¯´æ˜
"""
ä½¿ç”¨ partial_fit_new() çš„ç¤ºä¾‹ï¼š

# 1. åˆ›å»ºORICAå®ä¾‹
orica = ORICAZ(n_components=25, block_size_ica=8)

# 2. åˆå§‹åŒ–
init_data = np.random.randn(16, 25)  # (samples, channels)
orica.initialize(init_data)

# 3. ä½¿ç”¨ partial_fit_new å¤„ç†å—æ•°æ®
# æ–¹å¼1: å¤„ç†å•ä¸ªæ ·æœ¬ (25,)
single_sample = np.random.randn(25)
result_single = orica.partial_fit_new(single_sample)  # è¿”å› (25, 1)

# æ–¹å¼2: å¤„ç†å—æ•°æ® (25, 8)
block_data = np.random.randn(25, 8)  # 8ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ª25ä¸ªé€šé“
result_block = orica.partial_fit_new(block_data)  # è¿”å› (25, 8)

# æ–¹å¼3: å¤„ç†è½¬ç½®çš„å—æ•°æ® (8, 25) - ä¼šè‡ªåŠ¨è½¬ç½®ä¸º (25, 8)
block_data_transposed = np.random.randn(8, 25)  # 8ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ª25ä¸ªé€šé“
result_block_transposed = orica.partial_fit_new(block_data_transposed)  # è¿”å› (25, 8)

# 4. åœ¨çº¿æµå¤„ç†ç¤ºä¾‹
def process_stream_with_blocks(data_stream, block_size=8):
    results = []
    for i in range(0, len(data_stream), block_size):
        block = data_stream[i:i+block_size, :].T  # è½¬ç½®ä¸º (channels, block_size)
        result = orica.partial_fit_new(block)
        results.append(result)
    return np.hstack(results)  # åˆå¹¶æ‰€æœ‰ç»“æœ

# 5. ä¸åŸæœ‰ partial_fit çš„åŒºåˆ«
# - partial_fit: æ¯æ¬¡å¤„ç†1ä¸ªæ ·æœ¬ï¼Œè¿”å› (n_components,)
# - partial_fit_new: å¯ä»¥å¤„ç†å—æ•°æ®ï¼Œè¿”å› (n_components, block_size)
# - partial_fit_new åœ¨å†…éƒ¨å¯¹å—æ•°æ®è¿›è¡Œæ‰¹é‡å¤„ç†ï¼Œæé«˜æ•ˆç‡
"""
