#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EEGNet Online Learning Wrapper
æ”¯æŒåœ¨çº¿å­¦ä¹ çš„EEGNetæ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pickle
import os
from braindecode.models import EEGNetv1 as EEGNet
from sklearn.preprocessing import StandardScaler
import time

class EEGNetOnlineLearner:
    """EEGNetåœ¨çº¿å­¦ä¹ å™¨"""
    
    def __init__(self, model_name="EEGNet_Online_Learner"):
        self.model_name = model_name
        self.model = None
        self.optimizer = None
        self.criterion = None
        self.scaler = StandardScaler()
        self.is_trained = False
        
        # æ¨¡å‹å‚æ•°
        self.n_channels = 25 # æ ¹æ®æ‚¨çš„EEGé€šé“æ•°è°ƒæ•´
        self.input_time_length = 1000  # 2ç§’ * 500Hz
        self.n_classes = 2  # å·¦æ‰‹å’Œå³æ‰‹æƒ³è±¡ (7, 8)
        
        # åœ¨çº¿å­¦ä¹ å‚æ•°
        self.learning_rate = 1e-4
        self.batch_size = 1
        self.epochs_per_update = 1
        
        # æ•°æ®ç¼“å­˜
        self.feature_cache = []
        self.label_cache = []
        self.max_cache_size = 100  # æœ€å¤§ç¼“å­˜å¤§å°
        
        print(f"ğŸ§  Initialized {model_name}")
    
    def _create_model(self):
        """åˆ›å»ºEEGNetæ¨¡å‹"""
        if self.model is None:
            self.model = EEGNet(
                in_chans=self.n_channels,
                n_classes=self.n_classes,
                input_window_samples=self.input_time_length
            )
            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
            self.criterion = nn.CrossEntropyLoss()
            print(f"âœ… EEGNet model created: {self.n_channels} channels, {self.n_classes} classes")
    
    def pretrain(self, X, y, model_path=None):
        """é¢„è®­ç»ƒæ¨¡å‹"""
        print("ğŸ“ Starting EEGNet pre-training...")
        
        self._create_model()
        
        # æ•°æ®é¢„å¤„ç†
        X = np.array(X)
        y = np.array(y)
        
        # æ£€æŸ¥æ•°æ®å½¢çŠ¶å¹¶è°ƒæ•´
        if len(X.shape) == 2:
            # å¦‚æœæ˜¯2D (samples, features)ï¼Œéœ€è¦é‡å¡‘ä¸º3D (samples, channels, time)
            n_samples, n_features = X.shape
            n_channels = self.n_channels
            time_length = n_features // n_channels
            
            if n_features % n_channels == 0:
                X = X.reshape(n_samples, n_channels, time_length)
                print(f"âœ… Reshaped data: {X.shape}")
            else:
                print(f"âš ï¸ Cannot reshape {n_features} features into {n_channels} channels")
                return 0.0
        
        # æ ‡å‡†åŒ–æ¯ä¸ªé€šé“
        X_scaled = np.zeros_like(X)
        for i in range(X.shape[0]):
            for j in range(X.shape[1]):
                X_scaled[i, j, :] = (X[i, j, :] - np.mean(X[i, j, :])) / (np.std(X[i, j, :]) + 1e-8)
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        X_tensor = torch.FloatTensor(X_scaled)
        y_tensor = torch.LongTensor(y)
        
        # è®­ç»ƒæ¨¡å‹
        self.model.train()
        for epoch in range(50):  # é¢„è®­ç»ƒ50ä¸ªepoch
            self.optimizer.zero_grad()
            outputs = self.model(X_tensor)
            loss = self.criterion(outputs, y_tensor)
            loss.backward()
            self.optimizer.step()
            
            if epoch % 10 == 0:
                print(f"   Epoch {epoch}: Loss = {loss.item():.4f}")
        
        # è®¡ç®—å‡†ç¡®ç‡
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(X_tensor)
            _, predicted = torch.max(outputs.data, 1)
            accuracy = (predicted == y_tensor).sum().item() / len(y_tensor)
        
        self.is_trained = True
        print(f"âœ… Pre-training completed. Accuracy: {accuracy:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        if model_path:
            self.save_model(model_path)
        
        return accuracy
    
    def online_learn(self, features, labels):
        """åœ¨çº¿å­¦ä¹ """
        try:
            # å¦‚æœæ¨¡å‹è¿˜æ²¡æœ‰åˆ›å»ºï¼Œå…ˆåˆ›å»ºæ¨¡å‹
            if self.model is None:
                self._create_model()
            
            # å¤„ç†ç‰¹å¾æ•°æ®
            if len(features.shape) == 2:
                # å¦‚æœæ˜¯2D (channels, time)ï¼Œæ·»åŠ batchç»´åº¦
                features = features.reshape(1, features.shape[0], features.shape[1])
            
            # æ·»åŠ åˆ°ç¼“å­˜
            self.feature_cache.append(features)
            self.label_cache.append(labels[0])
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.feature_cache) > self.max_cache_size:
                self.feature_cache.pop(0)
                self.label_cache.pop(0)
            
            # å½“ç¼“å­˜è¾¾åˆ°ä¸€å®šå¤§å°æ—¶è¿›è¡Œè®­ç»ƒ
            if len(self.feature_cache) >= 3:  # æ¯3ä¸ªæ ·æœ¬è®­ç»ƒä¸€æ¬¡
                print("training")
                self._train_on_cache()
                self.is_trained = True  # æ ‡è®°æ¨¡å‹å·²è®­ç»ƒ
            
            return True
            
        except Exception as e:
            print(f"âŒ Online learning error: {e}")
            return False
    
    def _train_on_cache(self):
        """åŸºäºç¼“å­˜æ•°æ®è¿›è¡Œè®­ç»ƒ"""
        if len(self.feature_cache) < 2:
            return
        
        # å‡†å¤‡æ•°æ®
        X_cache = np.concatenate(self.feature_cache, axis=0)  # (batch, channels, time)
        y_cache = np.array(self.label_cache)
        
        # æ ‡å‡†åŒ–æ¯ä¸ªæ ·æœ¬çš„æ¯ä¸ªé€šé“
        X_scaled = np.zeros_like(X_cache)
        for i in range(X_cache.shape[0]):
            for j in range(X_cache.shape[1]):
                X_scaled[i, j, :] = (X_cache[i, j, :] - np.mean(X_cache[i, j, :])) / (np.std(X_cache[i, j, :]) + 1e-8)
        
        # è½¬æ¢ä¸ºå¼ é‡
        X_tensor = torch.FloatTensor(X_scaled)
        y_tensor = torch.LongTensor(y_cache)
        
        # è®­ç»ƒ
        self.model.train()
        for _ in range(self.epochs_per_update):
            self.optimizer.zero_grad()
            outputs = self.model(X_tensor)
            loss = self.criterion(outputs, y_tensor)
            loss.backward()
            self.optimizer.step()
    
    def predict(self, features):
        """é¢„æµ‹"""
        if not self.is_trained or self.model is None:
            print("âš ï¸ Model not trained yet.")
            # è¿”å›éšæœºé¢„æµ‹ (7 æˆ– 8)
            import random
            return np.array([random.choice([7, 8])])
        
        try:
            self.model.eval()
            with torch.no_grad():
                # å¤„ç†ç‰¹å¾æ•°æ®
                if len(features.shape) == 2:
                    # å¦‚æœæ˜¯2D (channels, time)ï¼Œæ·»åŠ batchç»´åº¦
                    features = features.reshape(1, features.shape[0], features.shape[1])
                
                # æ ‡å‡†åŒ–
                features_scaled = np.zeros_like(features)
                for i in range(features.shape[0]):
                    for j in range(features.shape[1]):
                        features_scaled[i, j, :] = (features[i, j, :] - np.mean(features[i, j, :])) / (np.std(features[i, j, :]) + 1e-8)
                
                X_tensor = torch.FloatTensor(features_scaled)
                
                # é¢„æµ‹
                outputs = self.model(X_tensor)
                _, predicted = torch.max(outputs, 1)
                
                return predicted.numpy()
                
        except Exception as e:
            print(f"âŒ Prediction error: {e}")
            return np.array([0])
    
    def predict_proba(self, features):
        """é¢„æµ‹æ¦‚ç‡"""
        if not self.is_trained or self.model is None:
            print("âš ï¸ Model not trained yet.")
            return np.array([[0.5, 0.5]])
        
        try:
            self.model.eval()
            with torch.no_grad():
                # å¤„ç†ç‰¹å¾æ•°æ®
                if len(features.shape) == 2:
                    # å¦‚æœæ˜¯2D (channels, time)ï¼Œæ·»åŠ batchç»´åº¦
                    features = features.reshape(1, features.shape[0], features.shape[1])
                
                # æ ‡å‡†åŒ–
                features_scaled = np.zeros_like(features)
                for i in range(features.shape[0]):
                    for j in range(features.shape[1]):
                        features_scaled[i, j, :] = (features[i, j, :] - np.mean(features[i, j, :])) / (np.std(features[i, j, :]) + 1e-8)
                
                X_tensor = torch.FloatTensor(features_scaled)
                
                # é¢„æµ‹æ¦‚ç‡
                outputs = self.model(X_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                
                return probabilities.numpy()
                
        except Exception as e:
            print(f"âŒ Probability prediction error: {e}")
            return np.array([[0.5, 0.5]])
    
    def save_model(self, filepath):
        """ä¿å­˜æ¨¡å‹"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # ä¿å­˜æ¨¡å‹çŠ¶æ€å’Œç›¸å…³ä¿¡æ¯
            model_data = {
                'model_state_dict': self.model.state_dict() if self.model else None,
                'optimizer_state_dict': self.optimizer.state_dict() if self.optimizer else None,
                'model_params': {
                    'n_channels': self.n_channels,
                    'input_time_length': self.input_time_length,
                    'n_classes': self.n_classes
                },
                'is_trained': self.is_trained
            }
            
            torch.save(model_data, filepath)
            print(f"ğŸ’¾ EEGNet model saved: {filepath}")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to save model: {e}")
            return False
    
    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹"""
        try:
            if not os.path.exists(filepath):
                print(f"âŒ Model file not found: {filepath}")
                return False
            
            # åŠ è½½æ¨¡å‹æ•°æ®
            model_data = torch.load(filepath, map_location='cpu')
            
            # æ£€æŸ¥æ¨¡å‹æ ¼å¼ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            if 'model_config' in model_data:
                # æ–°æ ¼å¼ï¼šæ¥è‡ªé¢„è®­ç»ƒè„šæœ¬
                print("ğŸ“‚ Loading pretrained model format...")
                self.n_channels = model_data['model_config']['n_channels']
                self.input_time_length = model_data['model_config']['input_time_length']
                self.n_classes = model_data['model_config']['n_classes']
                self.is_trained = True  # é¢„è®­ç»ƒæ¨¡å‹é»˜è®¤å·²è®­ç»ƒ
                
                # åˆ›å»ºæ¨¡å‹
                self._create_model()
                
                # åŠ è½½æ¨¡å‹çŠ¶æ€
                if model_data['model_state_dict']:
                    self.model.load_state_dict(model_data['model_state_dict'])
                
                # é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼ˆé¢„è®­ç»ƒæ¨¡å‹ä¸éœ€è¦åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰
                self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
                
                print(f"âœ… Pretrained EEGNet model loaded: {filepath}")
                print(f"   Channels: {self.n_channels}, Classes: {self.n_classes}")
                
            elif 'model_params' in model_data:
                # æ—§æ ¼å¼ï¼šæ¥è‡ªåœ¨çº¿å­¦ä¹ 
                print("ğŸ“‚ Loading online learning model format...")
                self.n_channels = model_data['model_params']['n_channels']
                self.input_time_length = model_data['model_params']['input_time_length']
                self.n_classes = model_data['model_params']['n_classes']
                self.is_trained = model_data['is_trained']
                
                # åˆ›å»ºæ¨¡å‹
                self._create_model()
                
                # åŠ è½½çŠ¶æ€
                if model_data['model_state_dict']:
                    self.model.load_state_dict(model_data['model_state_dict'])
                if model_data['optimizer_state_dict']:
                    self.optimizer.load_state_dict(model_data['optimizer_state_dict'])
                
                print(f"âœ… Online learning EEGNet model loaded: {filepath}")
            else:
                print("âŒ Unknown model format")
                return False
            
            # é‡æ–°åˆå§‹åŒ–scaler
            self.scaler = StandardScaler()
            
            return True
            
        except Exception as e:
            print(f"âŒ Failed to load model: {e}")
            return False
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_type': 'EEGNet',
            'n_channels': self.n_channels,
            'input_time_length': self.input_time_length,
            'n_classes': self.n_classes,
            'is_trained': self.is_trained,
            'cache_size': len(self.feature_cache)
        }

# æµ‹è¯•å‡½æ•°
def test_eegnet_online_learning():
    """æµ‹è¯•EEGNetåœ¨çº¿å­¦ä¹ åŠŸèƒ½"""
    print("ğŸ§ª Testing EEGNet Online Learning...")
    
    # åˆ›å»ºå­¦ä¹ å™¨
    learner = EEGNetOnlineLearner()
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    n_samples = 100
    n_features = 80  # å‡è®¾æœ‰80ä¸ªç‰¹å¾
    
    X = np.random.randn(n_samples, n_features)
    y = np.random.choice([7, 8], n_samples)
    
    # é¢„è®­ç»ƒ
    accuracy = learner.pretrain(X, y)
    print(f"Pre-training accuracy: {accuracy:.4f}")
    
    # åœ¨çº¿å­¦ä¹ æµ‹è¯•
    for i in range(10):
        features = np.random.randn(1, n_features)
        label = np.array([np.random.choice([7, 8])])
        
        # é¢„æµ‹
        prediction = learner.predict(features)
        proba = learner.predict_proba(features)
        
        # åœ¨çº¿å­¦ä¹ 
        success = learner.online_learn(features, label)
        
        print(f"Sample {i+1}: Pred={prediction[0]}, True={label[0]}, Success={success}")
    
    # ä¿å­˜æ¨¡å‹
    learner.save_model("./Quick30/eegnet_online_model.pt")
    
    print("âœ… EEGNet online learning test completed!")

if __name__ == "__main__":
    test_eegnet_online_learning() 