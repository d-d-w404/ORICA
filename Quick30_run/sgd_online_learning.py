import numpy as np
import pandas as pd
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import joblib
import os
import time

class SGDOnlineLearner:
    """SGDåœ¨çº¿å­¦ä¹ å™¨"""
    
    def __init__(self, model_name="SGD_Online_Learner"):
        self.model_name = model_name
        self.scaler = StandardScaler()
        
        # å°è¯•ä¸åŒçš„æŸå¤±å‡½æ•°ï¼Œä¼˜å…ˆé€‰æ‹©æ”¯æŒæ¦‚ç‡é¢„æµ‹çš„
        loss_options = ['log_loss', 'modified_huber', 'squared_loss']
        selected_loss = None
        
        for loss in loss_options:
            try:
                test_model = SGDClassifier(loss=loss, max_iter=1)
                # å¦‚æœèƒ½åˆ›å»ºæˆåŠŸï¼Œå°±ä½¿ç”¨è¿™ä¸ªæŸå¤±å‡½æ•°
                selected_loss = loss
                print(f"âœ… ä½¿ç”¨æŸå¤±å‡½æ•°: {loss}")
                break
            except Exception as e:
                print(f"âŒ æŸå¤±å‡½æ•° {loss} ä¸å¯ç”¨: {e}")
                continue
        
        if selected_loss is None:
            # å¦‚æœéƒ½ä¸è¡Œï¼Œä½¿ç”¨é»˜è®¤çš„
            selected_loss = 'modified_huber'
            print(f"âš ï¸ ä½¿ç”¨é»˜è®¤æŸå¤±å‡½æ•°: {selected_loss}")
        
        self.model = SGDClassifier(
            loss=selected_loss,  # ä½¿ç”¨æ£€æµ‹åˆ°çš„æŸå¤±å‡½æ•°
            penalty='l2',        # L2æ­£åˆ™åŒ–
            alpha=0.001,         # æ­£åˆ™åŒ–å¼ºåº¦
            max_iter=1,          # æ¯æ¬¡åªè¿­ä»£1æ¬¡ï¼Œé€‚åˆåœ¨çº¿å­¦ä¹ 
            random_state=42,
            tol=1e-3
        )
        self.is_fitted = False
        self.classes_ = None
        self.training_history = []
        
    def pretrain(self, X, y, save_path='./Quick30/sgd_pretrained_model.pkl'):
        """é¢„è®­ç»ƒæ¨¡å‹"""
        print(f"ğŸ”„ å¼€å§‹é¢„è®­ç»ƒ {self.model_name}...")
        print(f"   æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
        
        # æ•°æ®é¢„å¤„ç†
        X_scaled = self.scaler.fit_transform(X)
        
        # è·å–å”¯ä¸€ç±»åˆ«
        self.classes_ = np.unique(y)
        print(f"   ç±»åˆ«: {self.classes_}")
        
        # é¢„è®­ç»ƒæ¨¡å‹
        self.model.fit(X_scaled, y)
        self.is_fitted = True
        
        # è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹
        y_pred = self.model.predict(X_scaled)
        accuracy = accuracy_score(y, y_pred)
        print(f"âœ… é¢„è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.4f}")
        
        # ä¿å­˜é¢„è®­ç»ƒæ¨¡å‹
        self.save_model(save_path)
        print(f"ğŸ’¾ é¢„è®­ç»ƒæ¨¡å‹å·²ä¿å­˜: {save_path}")
        
        return accuracy
    
    def online_learn(self, X_new, y_new, verbose=True):
        """åœ¨çº¿å­¦ä¹ æ–°æ•°æ®"""
        if not self.is_fitted:
            print("âŒ æ¨¡å‹å°šæœªé¢„è®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ pretrain()")
            return False
        
        # æ ‡å‡†åŒ–æ–°æ•°æ®
        X_new_scaled = self.scaler.transform(X_new)
        
        # åœ¨çº¿å­¦ä¹ 
        self.model.partial_fit(X_new_scaled, y_new, classes=self.classes_)
        
        # è®°å½•å­¦ä¹ å†å²
        timestamp = time.time()
        self.training_history.append({
            'timestamp': timestamp,
            'samples_added': len(X_new),
            'new_labels': y_new.tolist() if hasattr(y_new, 'tolist') else y_new
        })
        
        if verbose:
            print(f"âœ… åœ¨çº¿å­¦ä¹ å®Œæˆï¼Œæ·»åŠ äº† {len(X_new)} ä¸ªæ ·æœ¬")
        
        return True
    
    def predict(self, X):
        """é¢„æµ‹"""
        if not self.is_fitted:
            print("âŒ æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None
        
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
    
    def predict_proba(self, X):
        """é¢„æµ‹æ¦‚ç‡"""
        if not self.is_fitted:
            print("âŒ æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None
        
        X_scaled = self.scaler.transform(X)
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæ¦‚ç‡é¢„æµ‹
        if hasattr(self.model, 'predict_proba'):
            return self.model.predict_proba(X_scaled)
        else:
            # å¦‚æœä¸æ”¯æŒæ¦‚ç‡é¢„æµ‹ï¼Œä½¿ç”¨å†³ç­–å‡½æ•°è½¬æ¢ä¸ºæ¦‚ç‡
            try:
                decision_scores = self.model.decision_function(X_scaled)
                # ä½¿ç”¨sigmoidå‡½æ•°å°†å†³ç­–åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡
                import numpy as np
                proba = 1 / (1 + np.exp(-decision_scores))
                # ç¡®ä¿æ¦‚ç‡åœ¨[0,1]èŒƒå›´å†…
                proba = np.clip(proba, 0, 1)
                # è¿”å›äºŒåˆ†ç±»æ¦‚ç‡
                return np.column_stack([1 - proba, proba])
            except Exception as e:
                print(f"âŒ æ¦‚ç‡é¢„æµ‹å¤±è´¥: {e}")
                # è¿”å›é»˜è®¤æ¦‚ç‡
                return np.array([[0.5, 0.5]])
    
    def evaluate(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹"""
        if not self.is_fitted:
            print("âŒ æ¨¡å‹å°šæœªè®­ç»ƒ")
            return None
        
        y_pred = self.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:")
        print(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"   é¢„æµ‹æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred))
        
        return accuracy
    
    def save_model(self, path):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'classes': self.classes_,
            'is_fitted': self.is_fitted,
            'training_history': self.training_history
        }
        joblib.dump(model_data, path)
    
    def load_model(self, path):
        """åŠ è½½æ¨¡å‹"""
        model_data = joblib.load(path)
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.classes_ = model_data['classes']
        self.is_fitted = model_data['is_fitted']
        self.training_history = model_data['training_history']
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {path}")
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {
            'model_name': self.model_name,
            'is_fitted': self.is_fitted,
            'classes': self.classes_,
            'training_samples': len(self.training_history),
            'coef_shape': self.model.coef_.shape if self.is_fitted else None
        }
        return info

def demo_online_learning():
    """æ¼”ç¤ºåœ¨çº¿å­¦ä¹ è¿‡ç¨‹"""
    
    print("ğŸš€ SGDåœ¨çº¿å­¦ä¹ æ¼”ç¤º")
    print("="*60)
    
    # 1. åŠ è½½æ•°æ®
    data_file = './Quick30/labeled_eeg_data2.npz'
    if not os.path.exists(data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return
    
    data = np.load(data_file)
    X = data['X']
    y = data['y']
    
    # å¦‚æœæ ‡ç­¾æ˜¯å¤šç»´çš„ï¼Œå–ç¬¬ä¸€åˆ—
    if len(y.shape) > 1:
        y = y[:, 0]
    
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"ğŸ·ï¸ æ ‡ç­¾åˆ†å¸ƒ: {np.unique(y, return_counts=True)}")
    
    # 2. åˆ›å»ºåœ¨çº¿å­¦ä¹ å™¨
    learner = SGDOnlineLearner("EEG_SGD_Online_Learner")
    
    # 3. é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨å‰80%çš„æ•°æ®ï¼‰
    split_idx = int(0.8 * len(X))
    X_train = X[:split_idx]
    y_train = y[:split_idx]
    X_test = X[split_idx:]
    y_test = y[split_idx:]
    
    print(f"\nğŸ“ˆ é¢„è®­ç»ƒé˜¶æ®µ:")
    print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    pretrain_accuracy = learner.pretrain(X_train, y_train)
    
    # 4. è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹
    print(f"\nğŸ“Š é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°:")
    learner.evaluate(X_test, y_test)
    
    # 5. åœ¨çº¿å­¦ä¹ æ¼”ç¤º
    print(f"\nğŸ”„ åœ¨çº¿å­¦ä¹ é˜¶æ®µ:")
    print("="*40)
    
    # å°†å‰©ä½™æ•°æ®åˆ†æˆå°æ‰¹æ¬¡è¿›è¡Œåœ¨çº¿å­¦ä¹ 
    batch_size = 2  # æ¯æ¬¡å­¦ä¹ 2ä¸ªæ ·æœ¬
    online_accuracies = []
    
    for i in range(0, len(X_test), batch_size):
        X_batch = X_test[i:i+batch_size]
        y_batch = y_test[i:i+batch_size]
        
        # åœ¨çº¿å­¦ä¹ 
        learner.online_learn(X_batch, y_batch)
        
        # è¯„ä¼°å½“å‰æ¨¡å‹
        current_accuracy = learner.evaluate(X_test, y_test)
        online_accuracies.append(current_accuracy)
        
        print(f"   æ‰¹æ¬¡ {i//batch_size + 1}: æ·»åŠ äº† {len(X_batch)} ä¸ªæ ·æœ¬")
        print(f"   å½“å‰å‡†ç¡®ç‡: {current_accuracy:.4f}")
        print("-" * 30)
    
    # 6. å¯è§†åŒ–ç»“æœ
    print(f"\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('SGDåœ¨çº¿å­¦ä¹ ç»“æœ', fontsize=16)
    
    # 1. åœ¨çº¿å­¦ä¹ å‡†ç¡®ç‡å˜åŒ–
    batch_numbers = range(1, len(online_accuracies) + 1)
    axes[0, 0].plot(batch_numbers, online_accuracies, 'bo-', linewidth=2, markersize=8)
    axes[0, 0].axhline(y=pretrain_accuracy, color='r', linestyle='--', 
                        label=f'é¢„è®­ç»ƒå‡†ç¡®ç‡: {pretrain_accuracy:.3f}')
    axes[0, 0].set_title('åœ¨çº¿å­¦ä¹ å‡†ç¡®ç‡å˜åŒ–')
    axes[0, 0].set_xlabel('æ‰¹æ¬¡')
    axes[0, 0].set_ylabel('å‡†ç¡®ç‡')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. æ¨¡å‹æƒé‡åˆ†å¸ƒ
    if learner.is_fitted:
        coef = learner.model.coef_[0]
        axes[0, 1].hist(coef, bins=30, alpha=0.7, color='skyblue')
        axes[0, 1].set_title('æ¨¡å‹æƒé‡åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('æƒé‡å€¼')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        axes[0, 1].grid(True, alpha=0.3)
    
    # 3. å­¦ä¹ å†å²
    if learner.training_history:
        timestamps = [h['timestamp'] for h in learner.training_history]
        samples_added = [h['samples_added'] for h in learner.training_history]
        
        axes[1, 0].plot(range(1, len(timestamps) + 1), samples_added, 'go-')
        axes[1, 0].set_title('åœ¨çº¿å­¦ä¹ å†å²')
        axes[1, 0].set_xlabel('å­¦ä¹ æ¬¡æ•°')
        axes[1, 0].set_ylabel('æ·»åŠ æ ·æœ¬æ•°')
        axes[1, 0].grid(True, alpha=0.3)
    
    # 4. æ¨¡å‹ä¿¡æ¯
    model_info = learner.get_model_info()
    info_text = f"""
æ¨¡å‹ä¿¡æ¯:
- æ¨¡å‹åç§°: {model_info['model_name']}
- æ˜¯å¦å·²è®­ç»ƒ: {model_info['is_fitted']}
- ç±»åˆ«æ•°: {len(model_info['classes']) if model_info['classes'] is not None else 'N/A'}
- è®­ç»ƒæ ·æœ¬æ•°: {model_info['training_samples']}
- æƒé‡å½¢çŠ¶: {model_info['coef_shape']}
- é¢„è®­ç»ƒå‡†ç¡®ç‡: {pretrain_accuracy:.4f}
- æœ€ç»ˆå‡†ç¡®ç‡: {online_accuracies[-1] if online_accuracies else 'N/A':.4f}
    """
    
    axes[1, 1].text(0.1, 0.5, info_text, transform=axes[1, 1].transAxes,
                     fontsize=10, verticalalignment='center',
                     bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.5))
    axes[1, 1].set_title('æ¨¡å‹ä¿¡æ¯')
    axes[1, 1].axis('off')
    
    plt.tight_layout()
    plt.savefig('./Quick30/sgd_online_learning_results.png', dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜: ./Quick30/sgd_online_learning_results.png")
    
    # 7. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = './Quick30/sgd_final_online_model.pkl'
    learner.save_model(final_model_path)
    print(f"âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
    
    # 8. ä½¿ç”¨ç¤ºä¾‹
    print(f"\nğŸ’¡ æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹:")
    print(f"```python")
    print(f"# åŠ è½½æ¨¡å‹")
    print(f"learner = SGDOnlineLearner()")
    print(f"learner.load_model('{final_model_path}')")
    print(f"")
    print(f"# é¢„æµ‹æ–°æ•°æ®")
    print(f"new_features = np.random.randn(1, {X.shape[1]})")
    print(f"prediction = learner.predict(new_features)")
    print(f"print(f'é¢„æµ‹ç»“æœ: {{prediction}}')")
    print(f"")
    print(f"# åœ¨çº¿å­¦ä¹ æ–°æ•°æ®")
    print(f"new_X = np.random.randn(2, {X.shape[1]})")
    print(f"new_y = np.array([1, 0])")
    print(f"learner.online_learn(new_X, new_y)")
    print(f"```")
    
    print("\n" + "="*60)
    print("âœ… SGDåœ¨çº¿å­¦ä¹ æ¼”ç¤ºå®Œæˆ!")
    print("="*60)

if __name__ == "__main__":
    demo_online_learning() 