#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ORICA_REST_new æµ‹è¯•è„šæœ¬
è¯»å– .set æ–‡ä»¶ï¼Œåº”ç”¨ORICAç®—æ³•ï¼Œä¿å­˜ç»“æœ
"""

import numpy as np
import scipy.io as sio
import os
import sys
from datetime import datetime
import argparse

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ORICA_REST_new
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from ORICA_REST_new import ORICAZ
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ ORICA_REST_newï¼Œè¯·ç¡®ä¿æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)

def load_set_file(set_file_path):
    """
    è¯»å– .set æ–‡ä»¶
    
    Args:
        set_file_path: .set æ–‡ä»¶è·¯å¾„
        
    Returns:
        data: numpyæ•°ç»„ï¼Œå½¢çŠ¶ (samples, channels)
        channel_names: é€šé“åç§°åˆ—è¡¨
        sample_rate: é‡‡æ ·ç‡
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(set_file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {set_file_path}")
        
        # è¯»å– .set æ–‡ä»¶
        print(f"ğŸ“ æ­£åœ¨è¯»å–æ–‡ä»¶: {set_file_path}")
        
        # ä½¿ç”¨ scipy.io è¯»å– .set æ–‡ä»¶
        # æ³¨æ„ï¼š.set æ–‡ä»¶æ˜¯EEGLABæ ¼å¼ï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
        # è¿™é‡Œæˆ‘ä»¬å°è¯•ç›´æ¥è¯»å–ï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›æ›¿ä»£æ–¹æ¡ˆ
        
        try:
            # å°è¯•ç›´æ¥è¯»å–
            mat_data = sio.loadmat(set_file_path)
            print(f"âœ… æˆåŠŸè¯»å– .set æ–‡ä»¶")
            
            # æŸ¥æ‰¾æ•°æ®å­—æ®µ
            data_keys = [key for key in mat_data.keys() if not key.startswith('__')]
            print(f"ğŸ“Š æ–‡ä»¶åŒ…å«çš„å­—æ®µ: {data_keys}")
            
            # é€šå¸¸EEGæ•°æ®å­˜å‚¨åœ¨ 'EEG' å­—æ®µä¸­ï¼Œéœ€è¦æ­£ç¡®æå–dataå­å­—æ®µ
            if 'EEG' in mat_data:
                eeg_data = mat_data['EEG']
                print(f"ğŸ“Š EEGç»“æ„ä½“å­—æ®µ: {eeg_data.dtype.names if hasattr(eeg_data, 'dtype') and hasattr(eeg_data.dtype, 'names') else 'æ— å­—æ®µä¿¡æ¯'}")
                
                if isinstance(eeg_data, np.ndarray) and eeg_data.dtype.names:
                    # EEGæ˜¯ç»“æ„ä½“æ•°ç»„ï¼Œéœ€è¦æå–dataå­—æ®µ
                    if 'data' in eeg_data.dtype.names:
                        data = eeg_data['data'][0, 0]  # æå–ç¬¬ä¸€ä¸ªå…ƒç´ çš„dataå­—æ®µ
                        print(f"âœ… ä»EEGç»“æ„ä½“ä¸­æå–dataå­—æ®µï¼Œå½¢çŠ¶: {data.shape}")
                    else:
                        raise ValueError("EEGç»“æ„ä½“ä¸­æœªæ‰¾åˆ°'data'å­—æ®µ")
                elif isinstance(eeg_data, np.ndarray):
                    data = eeg_data
                else:
                    raise ValueError("æ— æ³•è§£æEEGæ•°æ®ç»“æ„")
            elif 'data' in mat_data:
                data = mat_data['data']
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†å­—æ®µï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼æ•°ç»„
                numeric_keys = [key for key in data_keys if isinstance(mat_data[key], np.ndarray) and mat_data[key].dtype.kind in 'fc']
                if numeric_keys:
                    data = mat_data[numeric_keys[0]]
                    print(f"âš ï¸ ä½¿ç”¨å­—æ®µ '{numeric_keys[0]}' ä½œä¸ºæ•°æ®æº")
                else:
                    raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°å€¼æ•°æ®å­—æ®µ")
            
            # ç¡®ä¿æ•°æ®æ˜¯äºŒç»´çš„
            print(f"ğŸ” åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}, æ•°æ®ç±»å‹: {data.dtype}")
            
            if data.ndim == 3:
                # å¦‚æœæ˜¯3Dæ•°æ® (channels, samples, epochs)ï¼Œå–ç¬¬ä¸€ä¸ªepoch
                data = data[:, :, 0].T  # è½¬ç½®ä¸º (samples, channels)
                print(f"âš ï¸ 3Dæ•°æ®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªepochï¼Œå½¢çŠ¶: {data.shape}")
            elif data.ndim == 2:
                # å¦‚æœæ˜¯2Dæ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ç½®
                if data.shape[0] < data.shape[1]:
                    # å¦‚æœç¬¬ä¸€ä¸ªç»´åº¦å°äºç¬¬äºŒä¸ªç»´åº¦ï¼Œå¯èƒ½æ˜¯ (channels, samples)
                    data = data.T  # è½¬ç½®ä¸º (samples, channels)
                    print(f"âš ï¸ æ•°æ®å·²è½¬ç½®ï¼Œå½¢çŠ¶: {data.shape}")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç»´åº¦: {data.ndim}")
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºæ•°å€¼ç±»å‹
            if not np.issubdtype(data.dtype, np.number):
                print(f"âš ï¸ æ•°æ®ä¸æ˜¯æ•°å€¼ç±»å‹ï¼Œå°è¯•è½¬æ¢...")
                try:
                    data = data.astype(np.float64)
                    print(f"âœ… æ•°æ®å·²è½¬æ¢ä¸ºfloat64ç±»å‹")
                except Exception as e:
                    print(f"âŒ æ•°æ®è½¬æ¢å¤±è´¥: {e}")
                    raise ValueError(f"æ— æ³•å°†æ•°æ®è½¬æ¢ä¸ºæ•°å€¼ç±»å‹: {data.dtype}")
            
            # è·å–é€šé“ä¿¡æ¯
            channel_names = []
            if 'EEG' in mat_data and hasattr(eeg_data, 'dtype') and hasattr(eeg_data.dtype, 'names'):
                if 'chanlocs' in eeg_data.dtype.names:
                    chanlocs = eeg_data['chanlocs'][0, 0]
                    if hasattr(chanlocs, 'dtype') and hasattr(chanlocs.dtype, 'names'):
                        if 'labels' in chanlocs.dtype.names:
                            try:
                                labels = chanlocs['labels'][0, 0]
                                channel_names = [str(label[0]) for label in labels]
                                print(f"âœ… ä»EEGç»“æ„ä½“æå–é€šé“åç§°: {len(channel_names)} ä¸ªé€šé“")
                            except Exception as e:
                                print(f"âš ï¸ é€šé“åç§°æå–å¤±è´¥: {e}")
                        else:
                            print(f"âš ï¸ chanlocsä¸­æœªæ‰¾åˆ°'labels'å­—æ®µ")
                    else:
                        print(f"âš ï¸ chanlocsä¸æ˜¯ç»“æ„ä½“")
                else:
                    print(f"âš ï¸ EEGç»“æ„ä½“ä¸­æœªæ‰¾åˆ°'chanlocs'å­—æ®µ")
            
            # å¦‚æœæ²¡æœ‰é€šé“ä¿¡æ¯ï¼Œåˆ›å»ºé»˜è®¤é€šé“å
            if not channel_names:
                # ä»æ•°æ®å½¢çŠ¶æ¨æ–­é€šé“æ•°
                n_channels = data.shape[1] if data.ndim >= 2 else 1
                channel_names = [f'Ch{i+1:02d}' for i in range(n_channels)]
                print(f"âš ï¸ ä½¿ç”¨é»˜è®¤é€šé“åç§°: {len(channel_names)} ä¸ªé€šé“")
            
            # è·å–é‡‡æ ·ç‡
            sample_rate = 1000  # é»˜è®¤é‡‡æ ·ç‡
            if 'EEG' in mat_data and hasattr(eeg_data, 'dtype') and hasattr(eeg_data.dtype, 'names'):
                if 'srate' in eeg_data.dtype.names:
                    try:
                        sample_rate = int(eeg_data['srate'][0, 0])
                        print(f"âœ… ä»EEGç»“æ„ä½“æå–é‡‡æ ·ç‡: {sample_rate} Hz")
                    except Exception as e:
                        print(f"âš ï¸ é‡‡æ ·ç‡æå–å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼: {sample_rate} Hz")
                else:
                    print(f"âš ï¸ EEGç»“æ„ä½“ä¸­æœªæ‰¾åˆ°'srate'å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼: {sample_rate} Hz")
            else:
                print(f"âš ï¸ ä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡: {sample_rate} Hz")
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
            print(f"   - æ•°æ®å½¢çŠ¶: {data.shape}")
            print(f"   - é€šé“æ•°: {data.shape[1]}")
            print(f"   - æ ·æœ¬æ•°: {data.shape[0]}")
            print(f"   - é‡‡æ ·ç‡: {sample_rate} Hz")
            print(f"   - é€šé“åç§°: {channel_names[:5]}{'...' if len(channel_names) > 5 else ''}")
            
            return data, channel_names, sample_rate
            
        except Exception as e:
            print(f"âš ï¸ ç›´æ¥è¯»å–å¤±è´¥: {e}")
            print("ğŸ’¡ å°è¯•ä½¿ç”¨æ›¿ä»£æ–¹æ³•...")
            
            # æ›¿ä»£æ–¹æ¡ˆï¼šå¦‚æœ .set æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå°è¯•è¯»å–å¯¹åº”çš„ .fdt æ–‡ä»¶
            fdt_file_path = set_file_path.replace('.set', '.fdt')
            if os.path.exists(fdt_file_path):
                print(f"ğŸ“ å°è¯•è¯»å–å¯¹åº”çš„ .fdt æ–‡ä»¶: {fdt_file_path}")
                # è¯»å– .fdt æ–‡ä»¶ï¼ˆEEGLABçš„äºŒè¿›åˆ¶æ•°æ®æ–‡ä»¶ï¼‰
                try:
                    # è·å–é€šé“æ•°å’Œé‡‡æ ·ç‚¹æ•°ä¿¡æ¯
                    nbchan = 16  # é»˜è®¤å€¼
                    pnts = 1000  # é»˜è®¤å€¼
                    
                    if 'nbchan' in eeg_data.dtype.names:
                        try:
                            nbchan_val = eeg_data['nbchan'][0, 0]
                            if hasattr(nbchan_val, 'item'):
                                nbchan = int(nbchan_val.item())
                            else:
                                nbchan = int(nbchan_val)
                        except Exception as e:
                            print(f"âš ï¸ é€šé“æ•°æå–å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼: {nbchan}")
                    
                    if 'pnts' in eeg_data.dtype.names:
                        try:
                            pnts_val = eeg_data['pnts'][0, 0]
                            if hasattr(pnts_val, 'item'):
                                pnts = int(pnts_val.item())
                            else:
                                pnts = int(pnts_val)
                        except Exception as e:
                            print(f"âš ï¸ é‡‡æ ·ç‚¹æ•°æå–å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼: {pnts}")
                    print(f"ğŸ“Š ä»EEGç»“æ„ä½“è·å–ä¿¡æ¯: é€šé“æ•°={nbchan}, é‡‡æ ·ç‚¹æ•°={pnts}")
                    
                    # è·å–é€šé“åç§°å’Œé‡‡æ ·ç‡ä¿¡æ¯
                    channel_names = []
                    sample_rate = 1000  # é»˜è®¤é‡‡æ ·ç‡
                    
                    # å°è¯•ä»EEGç»“æ„ä½“æå–é€šé“åç§°
                    if 'chanlocs' in eeg_data.dtype.names:
                        try:
                            chanlocs = eeg_data['chanlocs'][0, 0]
                            if hasattr(chanlocs, 'dtype') and hasattr(chanlocs.dtype, 'names'):
                                if 'labels' in chanlocs.dtype.names:
                                    labels = chanlocs['labels'][0, 0]
                                    channel_names = [str(label[0]) for label in labels]
                                    print(f"âœ… ä»EEGç»“æ„ä½“æå–é€šé“åç§°: {len(channel_names)} ä¸ªé€šé“")
                        except Exception as e:
                            print(f"âš ï¸ é€šé“åç§°æå–å¤±è´¥: {e}")
                    
                    # å¦‚æœæ²¡æœ‰é€šé“ä¿¡æ¯ï¼Œåˆ›å»ºé»˜è®¤é€šé“å
                    if not channel_names:
                        channel_names = [f'Ch{i+1:02d}' for i in range(nbchan)]
                        print(f"âš ï¸ ä½¿ç”¨é»˜è®¤é€šé“åç§°: {len(channel_names)} ä¸ªé€šé“")
                    
                    # å°è¯•ä»EEGç»“æ„ä½“æå–é‡‡æ ·ç‡
                    if 'srate' in eeg_data.dtype.names:
                        try:
                            sample_rate = int(eeg_data['srate'][0, 0])
                            print(f"âœ… ä»EEGç»“æ„ä½“æå–é‡‡æ ·ç‡: {sample_rate} Hz")
                        except Exception as e:
                            print(f"âš ï¸ é‡‡æ ·ç‡æå–å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼: {sample_rate} Hz")
                    else:
                        print(f"âš ï¸ ä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡: {sample_rate} Hz")
                    
                    # è¯»å– .fdt æ–‡ä»¶
                    with open(fdt_file_path, 'rb') as f:
                        # è¯»å–äºŒè¿›åˆ¶æ•°æ®
                        raw_data = np.fromfile(f, dtype=np.float32)
                    
                    # é‡å¡‘æ•°æ®ä¸º (channels, samples) ç„¶åè½¬ç½®ä¸º (samples, channels)
                    if len(raw_data) == nbchan * pnts:
                        data = raw_data.reshape(nbchan, pnts).T  # è½¬ç½®ä¸º (samples, channels)
                        print(f"âœ… æˆåŠŸè¯»å– .fdt æ–‡ä»¶ï¼Œæ•°æ®å½¢çŠ¶: {data.shape}")
                    else:
                        # å¦‚æœæ•°æ®é•¿åº¦ä¸åŒ¹é…ï¼Œå°è¯•è‡ªåŠ¨æ¨æ–­
                        print(f"âš ï¸ æ•°æ®é•¿åº¦ä¸åŒ¹é…ï¼Œå°è¯•è‡ªåŠ¨æ¨æ–­...")
                        if len(raw_data) % nbchan == 0:
                            inferred_pnts = len(raw_data) // nbchan
                            data = raw_data.reshape(nbchan, inferred_pnts).T
                            print(f"âœ… æ¨æ–­é‡‡æ ·ç‚¹æ•°: {inferred_pnts}, æ•°æ®å½¢çŠ¶: {data.shape}")
                        else:
                            raise ValueError(f"æ— æ³•æ¨æ–­æ•°æ®ç»´åº¦: æ€»é•¿åº¦={len(raw_data)}, é€šé“æ•°={nbchan}")
                    
                    return data, channel_names, sample_rate
                    
                except Exception as e:
                    print(f"âŒ .fdt æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                    raise ValueError(f"æ— æ³•è¯»å– .fdt æ–‡ä»¶: {e}")
            else:
                raise ValueError(f"æ— æ³•è¯»å– .set æ–‡ä»¶ï¼Œä¸”æœªæ‰¾åˆ°å¯¹åº”çš„ .fdt æ–‡ä»¶")
                
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        raise

def apply_orica(data, n_components=None, block_size=8, num_passes=1, use_rls_whitening=True):
    """
    åº”ç”¨ORICAç®—æ³•
    
    Args:
        data: è¾“å…¥æ•°æ® (samples, channels)
        n_components: ç‹¬ç«‹æˆåˆ†æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é€šé“æ•°
        block_size: å—å¤§å°
        num_passes: è®­ç»ƒéæ•°
        use_rls_whitening: æ˜¯å¦ä½¿ç”¨RLSç™½åŒ–
        
    Returns:
        sources: ORICAåˆ†ç¦»åçš„æºä¿¡å· (components, samples)
        orica_model: è®­ç»ƒå¥½çš„ORICAæ¨¡å‹
    """
    try:
        n_samples, n_channels = data.shape
        
        # è®¾ç½®ç‹¬ç«‹æˆåˆ†æ•°é‡
        if n_components is None:
            n_components = n_channels
        
        print(f"ğŸ”§ é…ç½®ORICAå‚æ•°:")
        print(f"   - ç‹¬ç«‹æˆåˆ†æ•°: {n_components}")
        print(f"   - å—å¤§å°: {block_size}")
        print(f"   - è®­ç»ƒéæ•°: {num_passes}")
        print(f"   - RLSç™½åŒ–: {'æ˜¯' if use_rls_whitening else 'å¦'}")
        
        # åˆ›å»ºORICAæ¨¡å‹
        orica_model = ORICAZ(
            n_components=n_components,
            block_size_ica=block_size,
            use_rls_whitening=use_rls_whitening,
            verbose=True
        )
        
        # ä½¿ç”¨ fit_block_stream è¿›è¡Œè®­ç»ƒ
        print(f"ğŸš€ å¼€å§‹ORICAè®­ç»ƒ...")
        sources = orica_model.fit_block_stream(data, block_size=block_size, num_passes=num_passes)
        
        print(f"âœ… ORICAè®­ç»ƒå®Œæˆ:")
        print(f"   - æºä¿¡å·å½¢çŠ¶: {sources.shape}")
        print(f"   - è§£æ··çŸ©é˜µå½¢çŠ¶: {orica_model.get_W().shape}")
        print(f"   - ç™½åŒ–çŸ©é˜µå½¢çŠ¶: {orica_model.get_whitening_matrix().shape}")
        
        return sources, orica_model
        
    except Exception as e:
        print(f"âŒ ORICAè®­ç»ƒå¤±è´¥: {e}")
        raise

def save_results(sources, channel_names, sample_rate, output_dir, base_filename):
    """
    ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    
    Args:
        sources: ORICAåˆ†ç¦»åçš„æºä¿¡å· (components, samples)
        channel_names: é€šé“åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        base_filename: åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    """
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æºä¿¡å·ä¸º .mat æ–‡ä»¶
        mat_filename = f"{base_filename}_orica_sources_{timestamp}.mat"
        mat_path = os.path.join(output_dir, mat_filename)
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        save_data = {
            'sources': sources,
            'channel_names': channel_names,
            'sample_rate': sample_rate,
            'timestamp': timestamp,
            'algorithm': 'ORICA_REST_new',
            'source_count': sources.shape[0],
            'sample_count': sources.shape[1]
        }
        
        sio.savemat(mat_path, save_data)
        print(f"ğŸ’¾ æºä¿¡å·å·²ä¿å­˜åˆ°: {mat_path}")
        
        # ä¿å­˜æºä¿¡å·ä¸º .txt æ–‡ä»¶ï¼ˆä¾¿äºæŸ¥çœ‹ï¼‰
        txt_filename = f"{base_filename}_orica_sources_{timestamp}.txt"
        txt_path = os.path.join(output_dir, txt_filename)
        
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(f"ORICAç®—æ³•ç»“æœ - {timestamp}\n")
            f.write(f"ç®—æ³•: ORICA_REST_new\n")
            f.write(f"æºä¿¡å·æ•°é‡: {sources.shape[0]}\n")
            f.write(f"æ ·æœ¬æ•°é‡: {sources.shape[1]}\n")
            f.write(f"é‡‡æ ·ç‡: {sample_rate} Hz\n")
            f.write(f"é€šé“åç§°: {', '.join(channel_names)}\n")
            f.write("\n" + "="*50 + "\n\n")
            
            # ä¿å­˜æºä¿¡å·æ•°æ®ï¼ˆå®Œæ•´æ ·æœ¬ï¼‰
            f.write(f"æºä¿¡å·æ•°æ® (å®Œæ•´{sources.shape[1]}ä¸ªæ ·æœ¬):\n")
            f.write("æº\\æ ·æœ¬\t" + "\t".join([f"{i+1:3d}" for i in range(sources.shape[1])]) + "\n")
            
            for i in range(sources.shape[0]):
                # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹ï¼Œé¿å…å­—ç¬¦ä¸²æ ¼å¼åŒ–é”™è¯¯
                row_data = []
                for j in range(sources.shape[1]):
                    try:
                        value = float(sources[i, j])
                        row_data.append(f"{value:8.4f}")
                    except (ValueError, TypeError):
                        row_data.append(f"{str(sources[i, j]):>8}")
                f.write(f"æº{i+1:2d}\t" + "\t".join(row_data) + "\n")
        
        print(f"ğŸ’¾ æ–‡æœ¬ç»“æœå·²ä¿å­˜åˆ°: {txt_path}")
        
        # ä¿å­˜æºä¿¡å·ä¸º .npy æ–‡ä»¶ï¼ˆnumpyæ ¼å¼ï¼‰
        npy_filename = f"{base_filename}_orica_sources_{timestamp}.npy"
        npy_path = os.path.join(output_dir, npy_filename)
        
        np.save(npy_path, sources)
        print(f"ğŸ’¾ NumPyæ ¼å¼ç»“æœå·²ä¿å­˜åˆ°: {npy_path}")
        
        return mat_path, txt_path, npy_path
        
    except Exception as e:
        print(f"âŒ ç»“æœä¿å­˜å¤±è´¥: {e}")
        raise

def save_whitening_results(X_whitened, sphere, channel_names, sample_rate, output_dir, base_filename):
    """
    ä¿å­˜ç™½åŒ–ç»“æœï¼ˆç™½åŒ–åçš„æ•°æ®ä¸ç™½åŒ–çŸ©é˜µ/çƒåŒ–çŸ©é˜µï¼‰
    
    Args:
        X_whitened: ç™½åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ (samples, channels)
        sphere: ç™½åŒ–çŸ©é˜µï¼ˆicasphereï¼‰ï¼Œå½¢çŠ¶ (channels, channels)
        channel_names: é€šé“åç§°åˆ—è¡¨
        sample_rate: é‡‡æ ·ç‡
        output_dir: è¾“å‡ºç›®å½•
        base_filename: åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    """
    try:
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜ä¸º .mat
        mat_filename = f"{base_filename}_whitening_{timestamp}.mat"
        mat_path = os.path.join(output_dir, mat_filename)
        sio.savemat(mat_path, {
            'whitened': X_whitened,
            'sphere': sphere,
            'channel_names': channel_names,
            'sample_rate': sample_rate,
            'timestamp': timestamp
        })
        print(f"ğŸ’¾ ç™½åŒ–ç»“æœå·²ä¿å­˜åˆ°: {mat_path}")

        # ä¿å­˜ä¸º .txt æ–‡ä»¶
        txt_w_filename = f"{base_filename}_whitened_{timestamp}.txt"
        txt_w_path = os.path.join(output_dir, txt_w_filename)
        
        # ä¿å­˜ç™½åŒ–åçš„æ•°æ®ä¸ºtxt
        with open(txt_w_path, 'w', encoding='utf-8') as f:
            # å†™å…¥é€šé“åç§°ä½œä¸ºç¬¬ä¸€è¡Œ
            f.write("é€šé“åç§°: " + " ".join(channel_names) + "\n")
            f.write(f"é‡‡æ ·ç‡: {sample_rate}\n")
            f.write("ç™½åŒ–åæ•°æ®:\n")
            # å†™å…¥æ•°æ®ï¼Œæ¯è¡Œä¸€ä¸ªé€šé“ï¼ˆæº1ã€æº2...ï¼‰ï¼Œæ¯åˆ—ä¸€ä¸ªæ ·æœ¬
            # æ³¨æ„ï¼šX_whitenedçš„å½¢çŠ¶æ˜¯ (samples, channels)ï¼Œéœ€è¦è½¬ç½®ä¸º (channels, samples)
            X_whitened_T = X_whitened.T  # è½¬ç½®ä¸º (channels, samples)
            for i in range(X_whitened_T.shape[0]):
                row_str = f"æº{i+1:2d}\t" + "\t".join([f"{val:.6f}" for val in X_whitened_T[i, :]])
                f.write(row_str + "\n")
        
        print(f"ğŸ’¾ ç™½åŒ–æ•°æ®(TXT)å·²ä¿å­˜åˆ°: {txt_w_path}")


        txt_s_filename = f"{base_filename}_sphere_{timestamp}.txt"
        txt_s_path = os.path.join(output_dir, txt_s_filename)
        
        # ä¿å­˜ç™½åŒ–çŸ©é˜µä¸ºtxt
        with open(txt_s_path, 'w') as f:
            f.write(f"ç™½åŒ–çŸ©é˜µ (å½¢çŠ¶: {sphere.shape})\n")
            f.write("é€šé“åç§°: " + " ".join(channel_names) + "\n")
            f.write("çŸ©é˜µæ•°æ®:\n")
            # å†™å…¥çŸ©é˜µï¼Œæ¯è¡Œä¸€ä¸ªé€šé“
            for i in range(sphere.shape[0]):
                row_str = " ".join([f"{val:.6f}" for val in sphere[i, :]])
                f.write(row_str + "\n")
        
        print(f"ğŸ’¾ ç™½åŒ–çŸ©é˜µ(TXT)å·²ä¿å­˜åˆ°: {txt_s_path}")

        return mat_path, txt_w_path, txt_s_path
    except Exception as e:
        print(f"âŒ ç™½åŒ–ç»“æœä¿å­˜å¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ORICA_REST_new æµ‹è¯•è„šæœ¬')
    parser.add_argument('input_file', help='è¾“å…¥çš„ .set æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output_dir', default='./ORICA_results', help='è¾“å‡ºç›®å½• (é»˜è®¤: ./ORICA_results)')
    parser.add_argument('-c', '--components', type=int, help='ç‹¬ç«‹æˆåˆ†æ•°é‡ (é»˜è®¤: ä½¿ç”¨é€šé“æ•°)')
    parser.add_argument('-b', '--block_size', type=int, default=8, help='å—å¤§å° (é»˜è®¤: 8)')
    parser.add_argument('-p', '--passes', type=int, default=1, help='è®­ç»ƒéæ•° (é»˜è®¤: 1)')
    parser.add_argument('-r', '--rls', action='store_true', help='ä½¿ç”¨RLSç™½åŒ–')
    
    args = parser.parse_args()
    
    try:
        print("="*60)
        print("ğŸš€ ORICA_REST_new æµ‹è¯•è„šæœ¬")
        print("="*60)
        
        # 1. è¯»å–è¾“å…¥æ–‡ä»¶
        print("\nğŸ“‚ æ­¥éª¤1: è¯»å–è¾“å…¥æ–‡ä»¶")
        data, channel_names, sample_rate = load_set_file(args.input_file)
        
        # 2. åº”ç”¨ORICAç®—æ³•
        print("\nğŸ”¬ æ­¥éª¤2: åº”ç”¨ORICAç®—æ³•")
        sources, orica_model = apply_orica(
            data=data,
            n_components=args.components,
            block_size=args.block_size,
            num_passes=args.passes,
            use_rls_whitening=args.rls
        )

        # 2.1 è®¡ç®—å¹¶ä¿å­˜ç™½åŒ–ç»“æœï¼ˆä¸ transform ç›¸åŒé€»è¾‘ï¼‰
        try:
            X = data.copy()
            if getattr(orica_model, 'mean', None) is not None and orica_model.mean.shape[0] == X.shape[1]:
                X = X - orica_model.mean
            sphere = orica_model.get_whitening_matrix()
            X_whitened = X @ sphere.T
            base_filename = os.path.splitext(os.path.basename(args.input_file))[0]
            save_whitening_results(X_whitened, sphere, channel_names, sample_rate, args.output_dir, base_filename)
        except Exception as e:
            print(f"âš ï¸ ç™½åŒ–ç»“æœä¿å­˜å¤±è´¥(éè‡´å‘½): {e}")
        
        # 3. ä¿å­˜ç»“æœ
        print("\nğŸ’¾ æ­¥éª¤3: ä¿å­˜ç»“æœ")
        base_filename = os.path.splitext(os.path.basename(args.input_file))[0]
        mat_path, txt_path, npy_path = save_results(
            sources, channel_names, sample_rate, args.output_dir, base_filename
        )
        
        print("\n" + "="*60)
        print("ğŸ‰ å¤„ç†å®Œæˆï¼")
        print("="*60)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"ğŸ“Š æºä¿¡å·æ–‡ä»¶: {os.path.basename(mat_path)}")
        print(f"ğŸ“ æ–‡æœ¬ç»“æœ: {os.path.basename(txt_path)}")
        print(f"ğŸ”¢ NumPyæ ¼å¼: {os.path.basename(npy_path)}")
        
        # 4. æ˜¾ç¤ºç»“æœæ‘˜è¦
        print(f"\nğŸ“ˆ ç»“æœæ‘˜è¦:")
        print(f"   - è¾“å…¥æ•°æ®: {data.shape[0]} æ ·æœ¬ Ã— {data.shape[1]} é€šé“")
        print(f"   - è¾“å‡ºæºä¿¡å·: {sources.shape[0]} æˆåˆ† Ã— {sources.shape[1]} æ ·æœ¬")
        print(f"   - æ•°æ®èŒƒå›´: [{np.min(sources):.4f}, {np.max(sources):.4f}]")
        print(f"   - æ ‡å‡†å·®: {np.std(sources):.4f}")
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼å’Œå‚æ•°è®¾ç½®")
        sys.exit(1)

if __name__ == "__main__":
    # ç›´æ¥è®¾ç½®å‚æ•°ï¼Œæ— éœ€äº¤äº’
    try:
        # é¢„è®¾å‚æ•°
        input_file = r"D:\work\matlab_project\orica-master\orica-master\SIM_STAT_16ch_3min.set"
        output_dir = "./ORICA_results"
        n_components = 16  # è®¾ç½®ä¸º16ï¼Œä¸æ‚¨çš„é€šé“æ•°åŒ¹é…
        block_size = 8
        num_passes = 1
        use_rls = False
        
        print("="*60)
        print("ğŸš€ ORICA_REST_new æµ‹è¯•è„šæœ¬")
        print("="*60)
        
        print(f"ğŸ“ ä½¿ç”¨é¢„è®¾æ–‡ä»¶è·¯å¾„: {input_file}")
        print(f"ğŸ“‹ å‚æ•°è®¾ç½®:")
        print(f"   - è¾“å‡ºç›®å½•: {output_dir}")
        print(f"   - ç‹¬ç«‹æˆåˆ†æ•°: {n_components}")
        print(f"   - å—å¤§å°: {block_size}")
        print(f"   - è®­ç»ƒéæ•°: {num_passes}")
        print(f"   - RLSç™½åŒ–: {'æ˜¯' if use_rls else 'å¦'}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_file):
            print(f"âŒ é¢„è®¾æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            sys.exit(1)
        
        # 1. è¯»å–è¾“å…¥æ–‡ä»¶
        print("\nğŸ“‚ æ­¥éª¤1: è¯»å–è¾“å…¥æ–‡ä»¶")
        data, channel_names, sample_rate = load_set_file(input_file)
        
        # 2. åº”ç”¨ORICAç®—æ³•
        print("\nğŸ”¬ æ­¥éª¤2: åº”ç”¨ORICAç®—æ³•")
        sources, orica_model = apply_orica(
            data=data,
            n_components=n_components,
            block_size=block_size,
            num_passes=num_passes,
            use_rls_whitening=use_rls
        )

        # 2.1 è®¡ç®—å¹¶ä¿å­˜ç™½åŒ–ç»“æœï¼ˆä¸ transform ç›¸åŒé€»è¾‘ï¼‰
        try:
            X = data.copy()
            if getattr(orica_model, 'mean', None) is not None and orica_model.mean.shape[0] == X.shape[1]:
                X = X - orica_model.mean
            sphere = orica_model.get_whitening_matrix()
            #X_whitened = X @ sphere.T
            X_whitened = sphere @ X.T
            print("xxxxxxxx")
            print(X_whitened)
            base_filename = os.path.splitext(os.path.basename(input_file))[0]
            save_whitening_results(X_whitened, sphere, channel_names, sample_rate, output_dir, base_filename)
        except Exception as e:
            print(f"âš ï¸ ç™½åŒ–ç»“æœä¿å­˜å¤±è´¥(éè‡´å‘½): {e}")
        
        # 3. ä¿å­˜ç»“æœ
        print("\nğŸ’¾ æ­¥éª¤3: ä¿å­˜ç»“æœ")
        base_filename = os.path.splitext(os.path.basename(input_file))[0]
        mat_path, txt_path, npy_path = save_results(
            sources, channel_names, sample_rate, output_dir, base_filename
        )
        
        print("\n" + "="*60)
        print("ğŸ‰ å¤„ç†å®Œæˆï¼")
        print("="*60)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“Š æºä¿¡å·æ–‡ä»¶: {os.path.basename(mat_path)}")
        print(f"ğŸ“ æ–‡æœ¬ç»“æœ: {os.path.basename(txt_path)}")
        print(f"ğŸ”¢ NumPyæ ¼å¼: {os.path.basename(npy_path)}")
        
        # 4. æ˜¾ç¤ºç»“æœæ‘˜è¦
        print(f"\nğŸ“ˆ ç»“æœæ‘˜è¦:")
        print(f"   - è¾“å…¥æ•°æ®: {data.shape[0]} æ ·æœ¬ Ã— {data.shape[1]} é€šé“")
        print(f"   - è¾“å‡ºæºä¿¡å·: {sources.shape[0]} æˆåˆ† Ã— {sources.shape[1]} æ ·æœ¬")
        print(f"   - æ•°æ®èŒƒå›´: [{np.min(sources):.4f}, {np.max(sources):.4f}]")
        print(f"   - æ ‡å‡†å·®: {np.std(sources):.4f}")
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼å’Œå‚æ•°è®¾ç½®")
        sys.exit(1)
