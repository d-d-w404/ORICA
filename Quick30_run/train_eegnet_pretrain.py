#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨æ”¶é›†çš„åŸå§‹æ•°æ®è®­ç»ƒEEGNeté¢„è®­ç»ƒæ¨¡å‹
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from braindecode.models import EEGNetv1 as EEGNet
import os
import time
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

class EEGNetPretrainer:
    """EEGNeté¢„è®­ç»ƒå™¨"""
    
    def __init__(self, model_name="EEGNet_Pretrainer"):
        self.model_name = model_name
        self.model = None
        self.optimizer = None
        self.criterion = None
        self.scaler = StandardScaler()
        self.is_trained = False
        
        # æ¨¡å‹å‚æ•°
        self.n_channels = None  # å°†ä»æ•°æ®ä¸­è‡ªåŠ¨è·å–
        self.input_time_length = 1000  # 2ç§’ * 500Hz
        self.n_classes = None  # å°†ä»æ•°æ®ä¸­è‡ªåŠ¨è·å–
        
        # è®­ç»ƒå‚æ•°
        self.learning_rate = 5e-4
        self.batch_size = 8
        self.epochs = 300
        self.validation_split = 0.15
        
        # è®­ç»ƒå†å²
        self.train_losses = []
        self.val_losses = []
        self.train_accuracies = []
        self.val_accuracies = []
        
        print(f"ğŸ§  Initialized {model_name}")
    
    def load_and_preprocess_data(self, data_path):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print(f"ğŸ“‚ Loading data from: {data_path}")
        
        try:
            # åŠ è½½æ•°æ®
            data = np.load(data_path)
            X = data['X']  # åŸå§‹EEGæ•°æ®
            y = data['y']  # æ ‡ç­¾æ•°æ®
            
            print(f"ğŸ“Š Data loaded successfully:")
            print(f"   X shape: {X.shape}")
            print(f"   y shape: {y.shape}")
            print(f"   Data type: {X.dtype}")
            
            # è‡ªåŠ¨è®¾ç½®æ¨¡å‹å‚æ•°
            self.n_channels = X.shape[1]  # é€šé“æ•°
            self.n_classes = len(np.unique(y))  # ç±»åˆ«æ•°
            
            print(f"ğŸ”§ Model parameters set:")
            print(f"   Channels: {self.n_channels}")
            print(f"   Classes: {self.n_classes}")
            print(f"   Time length: {self.input_time_length}")
            
            # æ•°æ®é¢„å¤„ç†
            X_processed, y_processed = self._preprocess_data(X, y)
            
            return X_processed, y_processed
            
        except Exception as e:
            print(f"âŒ Error loading data: {e}")
            return None, None
    
    def _preprocess_data(self, X, y):
        """é¢„å¤„ç†æ•°æ®"""
        print("ğŸ”„ Preprocessing data...")
        
        # 1. æ ‡å‡†åŒ–æ¯ä¸ªé€šé“çš„æ—¶é—´åºåˆ—
        X_processed = np.zeros_like(X)
        for i in range(X.shape[0]):  # å¯¹æ¯ä¸ªæ ·æœ¬
            for j in range(X.shape[1]):  # å¯¹æ¯ä¸ªé€šé“
                # æ ‡å‡†åŒ–æ—¶é—´åºåˆ—
                mean_val = np.mean(X[i, j, :])
                std_val = np.std(X[i, j, :])
                if std_val > 0:
                    X_processed[i, j, :] = (X[i, j, :] - mean_val) / std_val
                else:
                    X_processed[i, j, :] = X[i, j, :] - mean_val
        
        # 2. å¤„ç†æ ‡ç­¾
        # å¦‚æœæ ‡ç­¾æ˜¯å¤šç»´çš„ï¼Œå–ç¬¬ä¸€ä¸ªç»´åº¦
        if len(y.shape) > 1:
            y_processed = y[:, 0]
        else:
            y_processed = y
        
        # 3. ç¡®ä¿æ ‡ç­¾æ˜¯è¿ç»­çš„æ•´æ•° (0, 1, 2, ...)
        unique_labels = np.unique(y_processed)
        label_mapping = {label: i for i, label in enumerate(unique_labels)}
        y_processed = np.array([label_mapping[label] for label in y_processed])
        
        print(f"âœ… Data preprocessing completed:")
        print(f"   Processed X shape: {X_processed.shape}")
        print(f"   Processed y shape: {y_processed.shape}")
        print(f"   Unique labels: {unique_labels} -> {list(range(len(unique_labels)))}")
        
        return X_processed, y_processed
    
    def create_model(self):
        """åˆ›å»ºEEGNetæ¨¡å‹"""
        if self.n_channels is None or self.n_classes is None:
            print("âŒ Model parameters not set. Please load data first.")
            return False
        
        print("ğŸ”¨ Creating EEGNet model...")
        
        self.model = EEGNet(
            in_chans=self.n_channels,
            n_classes=self.n_classes,
            input_window_samples=self.input_time_length
        )
        
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
        self.criterion = nn.CrossEntropyLoss()
        
        print(f"âœ… EEGNet model created:")
        print(f"   Input channels: {self.n_channels}")
        print(f"   Output classes: {self.n_classes}")
        print(f"   Time length: {self.input_time_length}")
        
        return True
    
    def prepare_data_loaders(self, X, y):
        """å‡†å¤‡æ•°æ®åŠ è½½å™¨"""
        print("ğŸ“¦ Preparing data loaders...")
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=self.validation_split, random_state=42, stratify=y
        )
        
        print(f"ğŸ“Š Data split:")
        print(f"   Training samples: {len(X_train)}")
        print(f"   Validation samples: {len(X_val)}")
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        X_train_tensor = torch.FloatTensor(X_train)
        y_train_tensor = torch.LongTensor(y_train)
        X_val_tensor = torch.FloatTensor(X_val)
        y_val_tensor = torch.LongTensor(y_val)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.batch_size, 
            shuffle=True
        )
        val_loader = DataLoader(
            val_dataset, 
            batch_size=self.batch_size, 
            shuffle=False
        )
        
        return train_loader, val_loader
    
    def train_model(self, train_loader, val_loader):
        """è®­ç»ƒæ¨¡å‹"""
        if self.model is None:
            print("âŒ Model not created. Please create model first.")
            return False
        
        print(f"ğŸš€ Starting training...")
        print(f"   Epochs: {self.epochs}")
        print(f"   Batch size: {self.batch_size}")
        print(f"   Learning rate: {self.learning_rate}")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.epochs):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for batch_X, batch_y in train_loader:
                self.optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = self.criterion(outputs, batch_y)
                loss.backward()
                self.optimizer.step()
                
                train_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                train_total += batch_y.size(0)
                train_correct += (predicted == batch_y).sum().item()
            
            # éªŒè¯é˜¶æ®µ
            self.model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0
            
            with torch.no_grad():
                for batch_X, batch_y in val_loader:
                    outputs = self.model(batch_X)
                    loss = self.criterion(outputs, batch_y)
                    
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    val_total += batch_y.size(0)
                    val_correct += (predicted == batch_y).sum().item()
            
            # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
            avg_train_loss = train_loss / len(train_loader)
            avg_val_loss = val_loss / len(val_loader)
            train_accuracy = train_correct / train_total
            val_accuracy = val_correct / val_total
            
            # ä¿å­˜è®­ç»ƒå†å²
            self.train_losses.append(avg_train_loss)
            self.val_losses.append(avg_val_loss)
            self.train_accuracies.append(train_accuracy)
            self.val_accuracies.append(val_accuracy)
            
            # æ‰“å°è¿›åº¦
            if (epoch + 1) % 10 == 0:
                print(f"Epoch [{epoch+1}/{self.epochs}]")
                print(f"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}")
                print(f"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}")
        
        self.is_trained = True
        print("âœ… Training completed!")
        
        return True
    
    def evaluate_model(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹"""
        if not self.is_trained:
            print("âŒ Model not trained yet.")
            return None
        
        print("ğŸ” Evaluating model...")
        
        self.model.eval()
        X_test_tensor = torch.FloatTensor(X_test)
        y_test_tensor = torch.LongTensor(y_test)
        
        with torch.no_grad():
            outputs = self.model(X_test_tensor)
            _, predicted = torch.max(outputs.data, 1)
            
            # è®¡ç®—å‡†ç¡®ç‡
            correct = (predicted == y_test_tensor).sum().item()
            total = y_test_tensor.size(0)
            accuracy = correct / total
            
            print(f"ğŸ“Š Test Results:")
            print(f"   Accuracy: {accuracy:.4f} ({correct}/{total})")
            
            # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
            unique_labels = np.unique(y_test)
            for label in unique_labels:
                mask = y_test == label
                class_correct = (predicted[mask] == y_test_tensor[mask]).sum().item()
                class_total = mask.sum()
                class_accuracy = class_correct / class_total
                print(f"   Class {label}: {class_accuracy:.4f} ({class_correct}/{class_total})")
        
        return accuracy
    
    def save_model(self, filepath):
        """ä¿å­˜æ¨¡å‹"""
        if not self.is_trained:
            print("âŒ Model not trained yet.")
            return False
        
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # ä¿å­˜æ¨¡å‹çŠ¶æ€
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'model_config': {
                    'n_channels': self.n_channels,
                    'n_classes': self.n_classes,
                    'input_time_length': self.input_time_length
                },
                'training_history': {
                    'train_losses': self.train_losses,
                    'val_losses': self.val_losses,
                    'train_accuracies': self.train_accuracies,
                    'val_accuracies': self.val_accuracies
                }
            }, filepath)
            
            print(f"âœ… Model saved to: {filepath}")
            return True
            
        except Exception as e:
            print(f"âŒ Error saving model: {e}")
            return False
    
    def plot_training_history(self, save_path=None):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        if not self.train_losses:
            print("âŒ No training history available.")
            return
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # ç»˜åˆ¶æŸå¤±
        ax1.plot(self.train_losses, label='Train Loss')
        ax1.plot(self.val_losses, label='Validation Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # ç»˜åˆ¶å‡†ç¡®ç‡
        ax2.plot(self.train_accuracies, label='Train Accuracy')
        ax2.plot(self.val_accuracies, label='Validation Accuracy')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š Training history plot saved to: {save_path}")
        
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  EEGNet Pretraining Script")
    print("=" * 50)
    
    # åˆ›å»ºé¢„è®­ç»ƒå™¨
    trainer = EEGNetPretrainer()
    
    # æ•°æ®è·¯å¾„
    data_path = './Quick30/labeled_raw_eeg_data_listen_processed.npz'
    model_save_path = './Quick30/eegnet_pretrained_model_listen_processed.pt'
    plot_save_path = './Quick30/training_history.png'
    
    # 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    X, y = trainer.load_and_preprocess_data(data_path)
    if X is None:
        print("âŒ Failed to load data. Exiting.")
        return
    
    # 2. åˆ›å»ºæ¨¡å‹
    if not trainer.create_model():
        print("âŒ Failed to create model. Exiting.")
        return
    
    # 3. å‡†å¤‡æ•°æ®åŠ è½½å™¨
    train_loader, val_loader = trainer.prepare_data_loaders(X, y)
    
    # 4. è®­ç»ƒæ¨¡å‹
    if not trainer.train_model(train_loader, val_loader):
        print("âŒ Training failed. Exiting.")
        return
    
    # 5. è¯„ä¼°æ¨¡å‹
    # ä½¿ç”¨éªŒè¯é›†è¿›è¡Œè¯„ä¼°
    # æ­£ç¡®è·å–éªŒè¯é›†æ•°æ®
    X_val_tensor = val_loader.dataset.tensors[0]  # è·å–Xæ•°æ®
    y_val_tensor = val_loader.dataset.tensors[1]  # è·å–yæ•°æ®
    X_val = X_val_tensor.numpy()
    y_val = y_val_tensor.numpy()
    trainer.evaluate_model(X_val, y_val)
    
    # 6. ä¿å­˜æ¨¡å‹
    trainer.save_model(model_save_path)
    
    # 7. ç»˜åˆ¶è®­ç»ƒå†å²
    trainer.plot_training_history(plot_save_path)
    
    print("\nğŸ‰ Pretraining completed successfully!")
    print(f"ğŸ“ Model saved: {model_save_path}")
    print(f"ğŸ“Š Training history: {plot_save_path}")
    print("\nğŸ’¡ You can now use this model for online learning!")

if __name__ == "__main__":
    main()