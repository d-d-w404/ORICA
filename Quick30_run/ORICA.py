import numpy as np
from scipy.stats import kurtosis
from sklearn.feature_selection import mutual_info_regression
from ORICA_calibration import ORICACalibration

class ORICA:
    def __init__(self, n_components, learning_rate=0.001, ortho_every=10, 
                 use_rls_whitening=True, forgetting_factor=0.98, 
                 nonlinearity='gaussian'):
        """
        ORICA with RLS whitening support
        
        Args:
            n_components: ç‹¬ç«‹æˆåˆ†æ•°é‡
            learning_rate: å­¦ä¹ ç‡
            ortho_every: æ¯éš”å¤šå°‘æ¬¡è¿­ä»£æ­£äº¤åŒ–
            use_rls_whitening: æ˜¯å¦ä½¿ç”¨RLSç™½åŒ–
            forgetting_factor: RLSé—å¿˜å› å­ (0 < Î» < 1)
            nonlinearity: éçº¿æ€§å‡½æ•°ç±»å‹ ('gaussian', 'tanh')
        """
        self.n_components = n_components
        self.learning_rate = learning_rate
        self.W = np.eye(n_components)  # è§£æ··çŸ©é˜µ
        self.mean = None
        self.whitening_matrix = None
        self.whitened = False
        self.update_count = 0
        self.ortho_every = ortho_every  # æ¯éš”å¤šå°‘æ¬¡è¿­ä»£æ­£äº¤åŒ–
        
        # RLSç™½åŒ–å‚æ•°
        self.use_rls_whitening = use_rls_whitening
        self.forgetting_factor = forgetting_factor
        self.nonlinearity = nonlinearity
        
        # RLSç™½åŒ–ç›¸å…³å˜é‡
        if self.use_rls_whitening:
            self.C = None  # åæ–¹å·®çŸ©é˜µçš„é€†
            self.t = 0     # æ—¶é—´æ­¥è®¡æ•°å™¨

    def _center(self, X):
        """å»å‡å€¼"""
        self.mean = np.mean(X, axis=0)
        return X - self.mean

    def _whiten(self, X):
        """ä¼ ç»Ÿæ‰¹é‡ç™½åŒ– - ä½¿ç”¨ç‰¹å¾å€¼åˆ†è§£"""
        cov = np.cov(X, rowvar=False)
        d, E = np.linalg.eigh(cov)
        D_inv = np.diag(1.0 / np.sqrt(d + 1e-2))  # é˜²æ­¢é™¤0
        self.whitening_matrix = E @ D_inv @ E.T
        return X @ self.whitening_matrix.T

    def _rls_whiten_initialize(self, X):
        """åˆå§‹åŒ–RLSç™½åŒ–"""
        # Xçš„å½¢çŠ¶æ˜¯ (samples, channels)ï¼Œéœ€è¦è½¬ç½®ä¸º (channels, samples)
        # if X.shape[0] < X.shape[1]:  # å¦‚æœç¬¬ä¸€ä¸ªç»´åº¦å°äºç¬¬äºŒä¸ªç»´åº¦ï¼Œè¯´æ˜æ˜¯ (samples, channels)
        #     n_channels = X.shape[1]
        # else:
        n_channels = X.shape[1]
        
        # åˆå§‹åŒ–åæ–¹å·®çŸ©é˜µçš„é€†ä¸ºå•ä½çŸ©é˜µ
        self.C = np.eye(n_channels)
        self.whitening_matrix = np.eye(n_channels)
        self.t = 0
        print(f"ğŸ”§ RLSç™½åŒ–åˆå§‹åŒ–: é€šé“æ•°={n_channels}, CçŸ©é˜µå½¢çŠ¶={self.C.shape}")

    def _rls_whiten_update(self, x_t):
        """
        RLSç™½åŒ–å•æ­¥æ›´æ–°
        
        Args:
            x_t: å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ® (n_channels, 1)
        """
        if self.C is None:
            raise ValueError("RLS whitening not initialized. Call initialize() first.")
        
        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        expected_channels = self.C.shape[0]
        actual_channels = x_t.shape[0]
        
        if expected_channels != actual_channels:
            print(f"âš ï¸ RLSç™½åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{expected_channels}é€šé“ï¼Œå®é™…{actual_channels}é€šé“")
            # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.C = np.eye(actual_channels)
            self.whitening_matrix = np.eye(actual_channels)
            self.t = 0
            print(f"âœ… é‡æ–°åˆå§‹åŒ–RLSç™½åŒ–ï¼Œæ–°ç»´åº¦: {actual_channels}")
        
        # RLSæ›´æ–°è§„åˆ™
        lambda_t = self.forgetting_factor
        self.t += 1
        
        # è®¡ç®—å¢ç›Šå‘é‡
        k = self.C @ x_t
        denominator = lambda_t + x_t.T @ k
        k = k / denominator
        
        # æ›´æ–°åæ–¹å·®çŸ©é˜µçš„é€†
        self.C = (self.C - k @ x_t.T @ self.C) / lambda_t
        
        # æ›´æ–°ç™½åŒ–çŸ©é˜µ
        # ç™½åŒ–çŸ©é˜µæ˜¯åæ–¹å·®çŸ©é˜µé€†çš„å¹³æ–¹æ ¹
        eigenvals, eigenvecs = np.linalg.eigh(self.C)
        eigenvals = np.maximum(eigenvals, 1e-6)  # é˜²æ­¢è´Ÿå€¼
        self.whitening_matrix = eigenvecs @ np.diag(np.sqrt(eigenvals)) @ eigenvecs.T
        
        # è¿”å›ç™½åŒ–åçš„æ•°æ®
        return self.whitening_matrix @ x_t

    def _g(self, y):
        """
        éçº¿æ€§å‡½æ•°
        
        Args:
            y: è¾“å…¥ä¿¡å·
            
        Returns:
            g_y: éçº¿æ€§å‡½æ•°å€¼
            g_prime: å¯¼æ•°
        """
        if self.nonlinearity == 'gaussian':
            # é«˜æ–¯éçº¿æ€§å‡½æ•°
            g_y = y * np.exp(-0.5 * y**2)
            g_prime = (1 - y**2) * np.exp(-0.5 * y**2)
        elif self.nonlinearity == 'tanh':
            # åŒæ›²æ­£åˆ‡éçº¿æ€§å‡½æ•°
            g_y = np.tanh(y)
            g_prime = 1 - np.tanh(y)**2
        else:
            raise ValueError(f"Unknown nonlinearity: {self.nonlinearity}")
        
        return g_y, g_prime

    def initialize(self, X_init):
        """åˆå§‹åŒ–ORICA"""
        # æ£€æŸ¥å¹¶è°ƒæ•´n_componentsä»¥åŒ¹é…æ•°æ®ç»´åº¦
        if X_init.shape[1] != self.n_components:  # X_initæ˜¯ (samples, channels) æ ¼å¼
            print(f"âš ï¸ åˆå§‹åŒ–ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{X_init.shape[1]}é€šé“")
            self.n_components = X_init.shape[1]
            # é‡æ–°åˆ›å»ºWçŸ©é˜µä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.W = np.eye(self.n_components)
            print(f"âœ… è°ƒæ•´n_componentsä¸º{self.n_components}")
        
        # å»å‡å€¼
        X_init = self._center(X_init)
        
        # ç™½åŒ–
        if self.use_rls_whitening:
            # ä½¿ç”¨RLSç™½åŒ–åˆå§‹åŒ–
            self._rls_whiten_initialize(X_init)
            # å¯¹åˆå§‹æ•°æ®è¿›è¡Œæ‰¹é‡ç™½åŒ–
            X_init = self._whiten(X_init)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ‰¹é‡ç™½åŒ–
            X_init = self._whiten(X_init)
        
        self.whitened = True
        print(f"âœ… ORICAåˆå§‹åŒ–å®Œæˆ: n_components={self.n_components}, æ•°æ®å½¢çŠ¶={X_init.shape}")
        #test (2500, 25)
        return X_init

    def partial_fit(self, x_t):
        """
        å•ä¸ªæ ·æœ¬åœ¨çº¿æ›´æ–°
        
        Args:
            x_t: å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ® (n_channels,)
        """
        x_t = x_t.reshape(-1, 1)# ä» (25,) å˜ä¸º (25, 1)
        if not self.whitened:
            raise ValueError("Must call `initialize` with initial batch before `partial_fit`.")
        
        # æ£€æŸ¥è¾“å…¥ç»´åº¦æ˜¯å¦ä¸å½“å‰æ¨¡å‹åŒ¹é…
        if x_t.shape[0] != self.n_components:
            print(f"âš ï¸ partial_fitç»´åº¦ä¸åŒ¹é…: æœŸæœ›{self.n_components}é€šé“ï¼Œå®é™…{x_t.shape[0]}é€šé“")
            # é‡æ–°åˆå§‹åŒ–ä»¥åŒ¹é…æ–°çš„ç»´åº¦
            self.n_components = x_t.shape[0]
            self.W = np.eye(self.n_components)
            # é‡æ–°åˆå§‹åŒ–ç™½åŒ–
            if self.use_rls_whitening:
                self.C = np.eye(self.n_components)
                self.whitening_matrix = np.eye(self.n_components)
                self.t = 0
            else:
                self.whitening_matrix = np.eye(self.n_components)
            print(f"âœ… é‡æ–°åˆå§‹åŒ–ORICAï¼Œæ–°ç»´åº¦: {self.n_components}")
        
        # å»å‡å€¼
        if self.mean is not None and self.mean.shape[0] == x_t.shape[0]:
            x_t = x_t - self.mean.reshape(-1, 1)
        else:
            # å¦‚æœmeanç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—
            print(f"âš ï¸ å‡å€¼ç»´åº¦ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—")
            self.mean = np.zeros(x_t.shape[0])
        
        # ç™½åŒ–
        if self.use_rls_whitening:
            # RLSç™½åŒ–æ›´æ–°
            x_t_whitened = self._rls_whiten_update(x_t)
        else:
            # ä¼ ç»Ÿç™½åŒ–
            x_t_whitened = self.whitening_matrix @ x_t
        
        # ICAæ›´æ–°
        y_t = self.W @ x_t_whitened
        g_y, _ = self._g(y_t)
        
        # ORICAæ›´æ–°è§„åˆ™
        I = np.eye(self.n_components)
        delta_W = self.learning_rate * ((I - g_y @ y_t.T) @ self.W)
        self.W += delta_W

        # æ­£äº¤åŒ–
        self.update_count += 1
        if self.update_count % self.ortho_every == 0:
            U, _, Vt = np.linalg.svd(self.W)
            self.W = U @ Vt

        return y_t.ravel()

    def transform(self, X):
        """å˜æ¢æ•°æ®"""
        if not self.whitened:
            raise ValueError("Model must be initialized first with `initialize()`.")
        
        # å»å‡å€¼
        X = X - self.mean
        
        # ç™½åŒ–
        if self.use_rls_whitening:
            # ä½¿ç”¨å½“å‰çš„ç™½åŒ–çŸ©é˜µ
            X_whitened = X @ self.whitening_matrix.T
        else:
            # ä¼ ç»Ÿç™½åŒ–
            X_whitened = X @ self.whitening_matrix.T
        
        # ICAå˜æ¢
        Y = (self.W @ X_whitened.T).T
        return Y

    def inverse_transform(self, Y):
        """é€†å˜æ¢"""
        Xw = np.linalg.pinv(self.W) @ Y.T
        X = Xw.T @ np.linalg.pinv(self.whitening_matrix).T + self.mean
        return X

    def get_W(self):
        """è·å–è§£æ··çŸ©é˜µ"""
        return self.W

    def get_whitening_matrix(self):
        """è·å–ç™½åŒ–çŸ©é˜µ"""
        return self.whitening_matrix

    def evaluate_separation(self, Y):
        """è¯„ä¼°åˆ†ç¦»æ•ˆæœ - ä½¿ç”¨å³°åº¦"""
        k = kurtosis(Y, axis=0, fisher=False)
        return k

    def rank_components_by_kurtosis(self, Y):
        """æŒ‰å³°åº¦æ’åºæˆåˆ†"""
        k = self.evaluate_separation(Y)
        indices = np.argsort(-np.abs(k))
        return indices, k

    def calc_mutual_info_matrix(self, sources):
        """è®¡ç®—äº’ä¿¡æ¯çŸ©é˜µ"""
        n = sources.shape[0]
        MI = np.zeros((n, n))
        for i in range(n):
            for j in range(n):
                if i != j:
                    MI[i, j] = mutual_info_regression(
                        sources[i, :].reshape(-1, 1), sources[j, :]
                    )[0]
        return MI

    def set_nonlinearity(self, nonlinearity):
        """è®¾ç½®éçº¿æ€§å‡½æ•°ç±»å‹"""
        if nonlinearity not in ['gaussian', 'tanh']:
            raise ValueError("nonlinearity must be 'gaussian' or 'tanh'")
        self.nonlinearity = nonlinearity

    def set_forgetting_factor(self, forgetting_factor):
        """è®¾ç½®RLSé—å¿˜å› å­"""
        if not (0 < forgetting_factor < 1):
            raise ValueError("forgetting_factor must be between 0 and 1")
        self.forgetting_factor = forgetting_factor

    

