import threading
import time

from pylsl import StreamInlet, resolve_byprop
import numpy as np
from filter_utils import EEGSignalProcessor
from pylsl import resolve_streams
from orica_processor import ORICAProcessor
from asrpy import ASR
import mne
from scipy.signal import medfilt

class LSLStreamReceiver:
    def __init__(self, stream_type='EEG', time_range=5):
        self.stream_type = stream_type
        self.time_range = time_range
        self.inlet = None
        self.srate = None
        self.nbchan = None
        self.buffer = None
        self.chan_labels = []
        self.channel_range = []

        self.channel_manager=None
        self.cutoff = (0.5, 45)

        # ASR
        self.use_asr = False
        self.asr_calibrated = False
        self.asr_calibration_buffer = None
        self.prep_reference = None

        self.raw_buffer = None  # å­˜æ”¾æœª ASR çš„ bandpass-only å†å²æ•°æ®

        # âœ… ç§»é™¤callbackæœºåˆ¶ï¼Œæ”¹ä¸ºçº¯æ•°æ®æ¥å£æ¨¡å¼
        # self.analysis_callbacks = []  # å­˜æ”¾æ‰€æœ‰å›è°ƒåˆ†æå‡½æ•°

        #ORICA
        self.orica = None
        self.latest_sources = None
        self.latest_eog_indices = None

        #å½“æˆ‘åœ¨åˆ‡æ¢é€šé“çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè®©icçš„ä¸ªæ•°å‘ç”Ÿæ”¹å˜ï¼Œä½†æ˜¯æ­¤æ—¶bufferè¿˜åœ¨è¿è¡Œï¼Œä¼šå¯¼è‡´å¡æ­»ï¼Œ
        #æ‰€ä»¥æˆ‘éœ€è¦æŠŠé€šé“åˆ‡æ¢è¿‡ç¨‹é”ä½
        self.lock = threading.Lock()
        
        # âœ… æ–°å¢ï¼šæ•°æ®æ›´æ–°çº¿ç¨‹æ§åˆ¶
        self.data_update_thread = None
        self.is_running = False
        self.update_interval = 0.1  # 100msæ›´æ–°é—´éš”
        
        # âœ… æ–°å¢ï¼šæ•°æ®æ¥å£ç›¸å…³
        self.last_unclean_chunk = None  # æœ€æ–°çš„åŸå§‹æ•°æ®å—
        self.last_processed_chunk = None  # æœ€æ–°çš„å¤„ç†åæ•°æ®å—
        self.data_timestamp = 0  # æ•°æ®æ—¶é—´æˆ³ï¼Œç”¨äºæ£€æµ‹æ•°æ®æ›´æ–°

        #ç”¨äºç”»å›¾æ—¶ï¼Œä¿è¯å¤„ç†åçš„æ•°æ®å’Œå¤„ç†å‰çš„èƒ½å¤Ÿåœ¨æ—¶é—´ä¸Šå»åˆ
        self.chunk_pairs = []  # [(timestamp, unclean, processed)]

    def find_and_open_stream(self):

        #check the whole stream
        streams = resolve_streams()
        print("ğŸ” å½“å‰å¯ç”¨çš„ LSL æµï¼š")
        for i, stream in enumerate(streams):
            print(
                f"[{i}] Name: {stream.name()}, Type: {stream.type()}, Channels: {stream.channel_count()}, ID: {stream.source_id()}")
        #--------------------------------------

        print(f"Searching for LSL stream with type = '{self.stream_type}'...")
        #streams = resolve_byprop('type', self.stream_type, timeout=5)

        #æš‚æ—¶ä½¿ç”¨nameç­›é€‰stream
        stream_name = 'mybrain'
        streams = resolve_byprop('name', stream_name, timeout=5)

        if not streams:
            raise RuntimeError(f"No LSL stream with type '{self.stream_type}' found.")

        #æˆ‘ä½¿ç”¨RESTåšLSLçš„æ—¶å€™æœ‰ä¸¤ä¸ªlsl,éƒ½æ˜¯eegç±»å‹ï¼Œè¿™é‡Œåº”è¯¥ä¼šé»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªï¼Œä½†æ˜¯ç¬¬ä¸€ä¸ªä¸æ˜¯lsl outputçš„ï¼Œä¼šå¡æ­»
        #è¿™é‡Œæš‚æ—¶ä½¿ç”¨1ï¼Œå› ä¸º0ç”¨ä¸äº†è€æ˜¯å¡æ­»
        self.inlet = StreamInlet(streams[0])
        info = self.inlet.info()

        print("=== StreamInfo XML description ===")
        print(self.inlet.info().as_xml())

        info = self.inlet.info()
        self.channel_manager = ChannelManager(info)

        self.srate = int(info.nominal_srate())
        self.nbchan = info.channel_count()

        # chs = info.desc().child('channels').child('channel')
        # all_labels = []
        # for _ in range(self.nbchan):
        #     label = chs.child_value('label')
        #     all_labels.append(label if label else f"Ch {_+1}")
        #     chs = chs.next_sibling()
        #
        # # self.chan_labels = all_labels.copy()
        # # self.enabled = [True] * len(self.chan_labels)  # â† æ·»åŠ è¿™è¡Œï¼Œæ ‡è®°æ¯ä¸ªé€šé“æ˜¯å¦å¯ç”¨
        #
        # exclude_keywords = ['TRIGGER', 'ACC', 'ExG', 'Packet', 'A2','O2','Oz']
        # for i, label in enumerate(all_labels):
        #     if not any(keyword in label for keyword in exclude_keywords):
        #         self.chan_labels.append(label)
        #         self.channel_range.append(i)


        # æˆ–è€…è‡ªå®šä¹‰æ’é™¤æŸäº›å…³é”®è¯
#         channel_all = [
#     'AF7',      # 0
#     'Fpz',      # 1
#     'F7',       # 2
#     'Fz',       # 3
#     'T7',       # 4
#     'FC6',      # 5
#     'Fp1',      # 6
#     'F4',       # 7
#     'C4',       # 8
#     'Oz',       # 9
#     'CP6',      # 10
#     'Cz',       # 11
#     'PO8',      # 12
#     'CP5',      # 13
#     'O2',       # 14
#     'O1',       # 15
#     'P3',       # 16
#     'P4',       # 17
#     'P7',       # 18
#     'P8',       # 19
#     'Pz',       # 20
#     'PO7',      # 21
#     'T8',       # 22
#     'C3',       # 23
#     'Fp2',      # 24
#     'F3',       # 25
#     'F8',       # 26
#     'FC5',      # 27
#     'AF8',      # 28
#     'A2',       # 29
#     'ExG 1',    # 30
#     'ExG 2'     # 31
# ]

        exclude = [
            'AF7',      # 0
            'Fpz',      # 1
            'F7',       # 2
            #'Fz',       # 3
            #'T7',       # 4
            'FC6',      # 5
            'Fp1',      # 6
            #'F4',       # 7
            'C4',       # 8
            'Oz',       # 9
            'CP6',      # 10
            'Cz',       # 11
            'PO8',      # 12
            'CP5',      # 13
            #'O2',       # 14
            #'O1',       # 15
            'P3',       # 16
            'P4',       # 17
            'P7',       # 18
            'P8',       # 19
            #'Pz',       # 20
            'PO7',      # 21
            #'T8',       # 22
            'C3',       # 23
            'Fp2',      # 24
            #'F3',       # 25
            'F8',       # 26
            'FC5',      # 27
            'AF8',      # 28
            'A2',       # 29
            'ExG 1',    # 30
            'ExG 2'     # 31
            'TRIGGER',
            'ACC34',
            'ACC33',
            'ACC32',
            'Packet Counter',
            'ACC',
        ]
        
        #å‰é¢çš„5ä¸ªé€šé“
        #exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','ACC','A2','Oz','P3','F8','PO8','F7','Fz', 'T7', 'FC6', 'F4', 'C4', 'CP6', 'Cz', 'CP5', 'O2', 'O1', 'P4', 'P7', 'P8', 'Pz', 'PO7', 'T8', 'C3', 'F3', 'FC5']

        #exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','ACC','A2','Oz','P3','F8','PO8','F7']
        self.chan_labels = self.channel_manager.get_labels_excluding_keywords(exclude)
        self.channel_range = self.channel_manager.get_indices_excluding_keywords(exclude)

        # print(self.chan_labels)
        # print(self.channel_range)
        #è¿™é‡Œçš„self.channel_range å¯¹åº”äº†æ¯ä¸€ä¸ªself.chan_labelsæ ‡ç­¾çš„åºå·
        #å‡å¦‚æˆ‘åœ¨ä¸Šé¢çš„excludeä¸­å»æ‰äº†O2,é‚£ä¹ˆO2è¿™ä¸ªlabelä»¥åŠä»–çš„åºå·éƒ½ä¼šè¢«åˆ é™¤ã€‚

        self.nbchan = len(self.channel_range)
        self.buffer = np.zeros((info.channel_count(), self.srate * self.time_range))

        #for the comparing stream
        self.raw_buffer = np.zeros((info.channel_count(), self.srate * self.time_range))

        print(f"Stream opened: {info.channel_count()} channels at {self.srate} Hz")
        print(f"Using {self.nbchan} EEG channels: {self.chan_labels}")



        # âœ… åˆå§‹åŒ– ORICA
        self.reinitialize_orica()



    def process_orica(self, chunk):
        """
        å¯¹è¾“å…¥çš„chunkè¿›è¡ŒORICAä¼ªå½±å»é™¤å¤„ç†ã€‚
        è¾“å…¥ï¼šchunkï¼ˆshape: é€šé“æ•°, æ ·æœ¬æ•°ï¼‰ï¼Œåªå¤„ç†self.channel_rangeå¯¹åº”çš„é€šé“ã€‚
        è¾“å‡ºï¼š
            cleaned_chunk: ä¼ªå½±å»é™¤åçš„chunkï¼ˆåªå¯¹self.channel_rangeéƒ¨åˆ†åšäº†ä¿®æ”¹ï¼Œå…¶ä½™é€šé“ä¸å˜ï¼‰
            ica_sources: ICAæºä¿¡å·ï¼ˆcomponents, samplesï¼‰ï¼Œå¯ç”¨äºå¯è§†åŒ–
            eog_indices: EOGä¼ªå½±æˆåˆ†ç´¢å¼•
            A: ICA mixing matrix (é€šé“æ•°, æˆåˆ†æ•°)
            spectrum: dictï¼ŒåŒ…å«æ‰€æœ‰ICåˆ†é‡çš„é¢‘è°±ï¼ˆ'freqs': é¢‘ç‡, 'powers': shape=(n_components, n_freqs)ï¼‰
        """
        import numpy as np
        from scipy.signal import welch
        cleaned_chunk = chunk.copy()
        ica_sources = None
        eog_indices = None
        A = None
        spectrum = None
        # ORICAå¤„ç†
        if self.orica is not None:
            if self.orica.update_buffer(chunk[self.channel_range, :]):
                if self.orica.fit(self.orica.data_buffer, self.channel_range, self.chan_labels, self.srate):
                    #classify
                    # ic_probs, ic_labels = self.orica.classify(chunk[self.channel_range, :],self.chan_labels, self.srate)
                    # if ic_probs is not None and ic_labels is not None:
                    #     print('ICLabelæ¦‚ç‡:', ic_probs)
                    #     print('ICLabelæ ‡ç­¾:', ic_labels)


                    cleaned = self.orica.transform(chunk[self.channel_range, :])
                    cleaned_chunk[self.channel_range, :] = cleaned
                    ica_sources = self.orica.ica.transform(self.orica.data_buffer.T).T  # (components, samples)
                    eog_indices = self.orica.eog_indices
                    # è·å–mixing matrix A
                    try:
                        A = np.linalg.pinv(self.orica.ica.W)
                    except Exception:
                        A = None
                    # è·å–æ‰€æœ‰ICåˆ†é‡çš„spectrum
                    if ica_sources is not None:
                        powers = []
                        freqs = None
                        for ic in range(ica_sources.shape[0]):
                            f, Pxx = welch(ica_sources[ic], fs=self.srate)
                            if freqs is None:
                                freqs = f
                            powers.append(Pxx)
                        powers = np.array(powers)  # shape: (n_components, n_freqs)
                        spectrum = {'freqs': freqs, 'powers': powers}
        return cleaned_chunk, ica_sources, eog_indices, A, spectrum

    def pull_and_update_buffer(self):
        samples, timestamps = self.inlet.pull_chunk(timeout=0.0)
        if timestamps:
            chunk = np.array(samples).T  # shape: (channels, samples)
            #print("test",chunk.shape) # 

            # Step 1: Bandpass or highpass filter
            chunk = EEGSignalProcessor.eeg_filter(chunk, self.srate, cutoff=self.cutoff)

            # âœ… æ›´æ–°åŸå§‹æ»¤æ³¢åçš„æ•°æ®æ¥å£
            self.last_unclean_chunk = chunk.copy()
            if self.raw_buffer is not None:
                self.raw_buffer = np.roll(self.raw_buffer, -chunk.shape[1], axis=1)
                self.raw_buffer[:, -chunk.shape[1]:] = self.last_unclean_chunk


            #âœ… Step X: ORICA å»çœ¼åŠ¨ä¼ªå½±ï¼ˆé‡æ„ä¸ºç‹¬ç«‹å‡½æ•°ï¼‰
            chunk, ica_sources, eog_indices,A,spectrum = self.process_orica(chunk)
            if ica_sources is not None:
                self.latest_sources = ica_sources
            if eog_indices is not None:
                self.latest_eog_indices = eog_indices

            # Step 2: ASRå¤„ç†
            if self.use_asr:
                chunk = self.apply_pyprep_asr(chunk)

            # Step 3: Update ring buffer
            num_new = chunk.shape[1]
            self.buffer = np.roll(self.buffer, -num_new, axis=1)
            self.buffer[:, -num_new:] = chunk
            
            # âœ… æ›´æ–°å¤„ç†åæ•°æ®æ¥å£
            self.last_processed_chunk = chunk.copy()
            self.data_timestamp = time.time()


            
                # 3. å­˜æˆä¸€å¯¹
            timestamp = time.time()
            self.chunk_pairs.append((timestamp, self.last_unclean_chunk, self.last_processed_chunk))
            # åªä¿ç•™æœ€è¿‘Nå¯¹
            if len(self.chunk_pairs) > 1:
                self.chunk_pairs.pop(0)

            # âœ… Step 4: å›è°ƒåˆ†æå‡½æ•°
            # for fn in self.analysis_callbacks: # ç§»é™¤æ­¤è¡Œ
            #     try: # ç§»é™¤æ­¤è¡Œ
            #         thread = threading.Thread( # ç§»é™¤æ­¤è¡Œ
            #             target=fn, # ç§»é™¤æ­¤è¡Œ
            #             kwargs=dict( # ç§»é™¤æ­¤è¡Œ
            #                 chunk=self.buffer[self.channel_range, :], # ç§»é™¤æ­¤è¡Œ
            #                 raw=self.raw_buffer[self.channel_range, :], # ç§»é™¤æ­¤è¡Œ
            #                 srate=self.srate, # ç§»é™¤æ­¤è¡Œ
            #                 labels=self.chan_labels # ç§»é™¤æ­¤è¡Œ
            #             ) # ç§»é™¤æ­¤è¡Œ
            #         ) # ç§»é™¤æ­¤è¡Œ
            #         thread.start() # ç§»é™¤æ­¤è¡Œ
            #     except Exception as e: # ç§»é™¤æ­¤è¡Œ
            #         print(f"âŒ å›è°ƒåˆ†æå‡½æ•°é”™è¯¯: {e}") # ç§»é™¤æ­¤è¡Œ


    


    #Selected channel indices: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]
    #Selected channel labels: ['AF7', 'Fpz', 'F7', 'Fz', 'T7', 'FC6', 'F4', 'C4', 'Oz', 'CP6', 'Cz', 'PO8', 'CP5', 'O2', 'O1', 'P3', 'P4', 'P7', 'P8', 'Pz', 'PO7', 'T8', 'C3', 'Fp2', 'F3', 'F8', 'FC5', 'AF8']
    #ä¸Šé¢å°±æ˜¯channel_rangeå’Œchannel_labelsçš„æ ¼å¼ï¼Œè¦è°ƒç”¨å‡½æ•°å°±ä¼ å…¥è¿™æ ·çš„list
    def set_channel_range_and_labels(self, new_range, new_labels):
        with self.lock:
            self.channel_range = new_range
            self.chan_labels = new_labels
            self.nbchan = len(new_range)
            self.reinitialize_orica()
            print(f"ğŸ” é€šé“æ›´æ–°: {self.chan_labels}")

    def register_analysis_callback(self, callback_fn):
        """æ³¨å†Œä¸€ä¸ªå‡½æ•°ç”¨äºå¤„ç†æ¯æ¬¡æ›´æ–°åçš„æ•°æ®æ®µ chunk"""
        # self.analysis_callbacks.append(callback_fn) # ç§»é™¤æ­¤è¡Œ
        pass # ç§»é™¤æ­¤è¡Œ

    def reinitialize_orica(self):
        self.orica = ORICAProcessor(
            n_components=len(self.channel_range),
            max_samples=self.srate * 10,
            srate=self.srate
        )
        print("ğŸ” ORICA processor re-initialized with new channel range.")

    def start(self):
        """å¯åŠ¨æ•°æ®æµå’Œæ•°æ®æ›´æ–°çº¿ç¨‹"""
        if hasattr(self, 'is_running') and self.is_running:
            print("âš ï¸ æ•°æ®æµå·²åœ¨è¿è¡Œ")
            return
        self.find_and_open_stream()
        self.is_running = True
        self.data_update_thread = threading.Thread(target=self._data_update_loop, daemon=True)
        self.data_update_thread.start()
        print("âœ… æ•°æ®æµå’Œæ•°æ®æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢æ•°æ®æ›´æ–°çº¿ç¨‹"""
        self.is_running = False
        if hasattr(self, 'data_update_thread') and self.data_update_thread and self.data_update_thread.is_alive():
            self.data_update_thread.join(timeout=1.0)
        print("ğŸ›‘ æ•°æ®æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def _data_update_loop(self):
        """æ•°æ®æ›´æ–°å¾ªç¯ - åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ"""
        while self.is_running:
            try:
                self.pull_and_update_buffer()
                time.sleep(self.update_interval)
            except Exception as e:
                print(f"âŒ æ•°æ®æ›´æ–°é”™è¯¯: {e}")
                time.sleep(0.1)  # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…

    # âœ… æ–°å¢ï¼šæ•°æ®æ¥å£æ–¹æ³•
    def get_raw_data(self):
        """è·å–æœ€æ–°çš„åŸå§‹æ•°æ®ï¼ˆä»…å¸¦é€šæ»¤æ³¢ï¼‰"""
        return self.last_unclean_chunk.copy() if self.last_unclean_chunk is not None else None
    
    def get_processed_data(self):
        """è·å–æœ€æ–°çš„å¤„ç†åæ•°æ®ï¼ˆORICA + ASRï¼‰"""
        return self.last_processed_chunk.copy() if self.last_processed_chunk is not None else None

    def get_pair_data(self, data_type='processed'):
        if data_type == 'raw':
            return self.chunk_pairs.copy()[0][1][self.channel_range, :] if self.chunk_pairs is not None else None
        else:
            return self.chunk_pairs.copy()[0][2][self.channel_range, :] if self.chunk_pairs is not None else None
        #return self.chunk_pairs.copy() if self.chunk_pairs is not None else None
    
    def get_buffer_data(self, data_type='processed'):
        """è·å–ç¼“å†²åŒºæ•°æ®
        
        Args:
            data_type: 'raw' æˆ– 'processed'
        """
        if data_type == 'raw':
            return self.raw_buffer[self.channel_range, :] if self.raw_buffer is not None else None
        else:
            return self.buffer[self.channel_range, :] if self.buffer is not None else None
    
    
    def get_ica_sources(self):
        """è·å–æœ€æ–°çš„ICAæºä¿¡å·"""
        return self.latest_sources.copy() if self.latest_sources is not None else None
    
    def get_eog_indices(self):
        """è·å–EOGä¼ªå½±æˆåˆ†ç´¢å¼•"""
        return self.latest_eog_indices.copy() if self.latest_eog_indices is not None else None
    
    def get_channel_info(self):
        """è·å–é€šé“ä¿¡æ¯"""
        return {
            'labels': self.chan_labels.copy() if self.chan_labels else [],
            'indices': self.channel_range.copy() if self.channel_range else [],
            'count': len(self.channel_range) if self.channel_range else 0,
            'sampling_rate': self.srate
        }
    
    def is_data_available(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•°æ®"""
        return (self.last_unclean_chunk is not None and 
                self.last_processed_chunk is not None and 
                self.buffer is not None)
    
    def get_data_timestamp(self):
        """è·å–æ•°æ®æ—¶é—´æˆ³ï¼Œç”¨äºæ£€æµ‹æ•°æ®æ›´æ–°"""
        return self.data_timestamp





    def print_latest_channel_values(self):
        if self.buffer is None:
            print("âš ï¸ Buffer å°šæœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰“å°é€šé“å€¼")
            return

        # print("--- EEG Channel Values (Last Sample) ---")
        # for i, ch_idx in enumerate(self.channel_range):
        #     label = self.chan_labels[i]
        #     last_value = self.buffer[ch_idx, -1]
        #     rms = np.sqrt(np.mean(self.buffer[ch_idx] ** 2))
        #     print(f"{label:>4}: {last_value:>8.2f} Î¼V | RMS: {rms:.2f}")



    def apply_pyprep_asr(self, chunk):
        try:
            if not self.asr_calibrated:
                # ğŸ”„ Step 1: æ”¶é›†é™æ¯æ•°æ®è¿›è¡Œæ ¡å‡†
                if self.asr_calibration_buffer is None:
                    self.asr_calibration_buffer = chunk.copy()
                else:
                    self.asr_calibration_buffer = np.concatenate(
                        (self.asr_calibration_buffer, chunk), axis=1
                    )

                if self.asr_calibration_buffer.shape[1] >= self.srate * 20:
                    print("â³ Calibrating ASR...")

                    # â• åˆ›å»º Raw å¯¹è±¡ç”¨äºæ ¡å‡†
                    info = mne.create_info(
                        ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                        sfreq=self.srate,
                        ch_types=["eeg"] * len(self.channel_range)
                    )
                    x=self.channel_manager.get_labels_by_indices(self.channel_range)
                    # print("X" * 30)
                    # print(x)
                    # print("X" * 30)

                    raw = mne.io.RawArray(
                        self.asr_calibration_buffer[self.channel_range, :], info
                    )

                    #
                    # print(self.asr_calibration_buffer[self.channel_range, :])
                    # print("Selected shape:", self.buffer[self.channel_range, :].shape)
                    # print("Selected labels:", self.chan_labels)

                    raw.set_montage("standard_1020")

                    # ğŸ”§ åˆå§‹åŒ–å¹¶æ ¡å‡† ASR å®ä¾‹
                    self.asr_instance = ASR(
                        sfreq=self.srate,

                        cutoff=20,
                        win_len=2,
                        win_overlap=0.8,
                        blocksize=self.srate
                    )

                    self.asr_instance.fit(raw)

                    self.asr_calibrated = True
                    self.asr_calibration_buffer = None
                    print("âœ… ASRpy calibrated successfully.")

            else:
                # ğŸ”„ Step 2: å®æ—¶æ¸…æ´—æ•°æ®
                info = mne.create_info(
                    ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                    sfreq=self.srate,
                    ch_types=["eeg"] * len(self.channel_range)
                )
                raw_chunk = mne.io.RawArray(chunk[self.channel_range, :], info)
                raw_chunk.set_montage("standard_1020")

                cleaned_raw = self.asr_instance.transform(raw_chunk)
                chunk[self.channel_range, :] = cleaned_raw.get_data()



                # åœ¨ ASR ååŠ ä¸ªä¸­å€¼æ»¤æ³¢å¤„ç†ï¼Œå¹³æ»‘
                cleaned_chunk = cleaned_raw.get_data()
                cleaned_chunk = medfilt(cleaned_chunk, kernel_size=(1, 5))  # ä¿é€šé“ä¸å˜ï¼Œä»…æ—¶é—´å¹³æ»‘
                chunk[self.channel_range, :] = cleaned_chunk


        except Exception as e:
            print("âŒ Error in apply_pyprep_asr:", e)

        return chunk



class ChannelManager:
    def __init__(self, lsl_info):
        """
        ä» pylsl.StreamInfo æå–å¹¶ä¿å­˜æ‰€æœ‰æœ‰æ„ä¹‰çš„ä¿¡æ¯
        åŒ…æ‹¬å…¨å±€å±æ€§å’Œé€šé“ç»“æ„
        """
        # === å…¨å±€æµä¿¡æ¯ ===
        self.name = lsl_info.name()
        self.type = lsl_info.type()
        self.channel_count = lsl_info.channel_count()
        self.srate = int(lsl_info.nominal_srate())
        self.uid = lsl_info.uid()
        self.hostname = lsl_info.hostname()
        self.source_id = lsl_info.source_id()
        self.version = lsl_info.version()
        self.created_at = lsl_info.created_at()

        # === æ‰€æœ‰é€šé“ä¿¡æ¯ ===
        #è¿™ä¸ªç±»çš„å®ä¾‹ä¸­æœ‰ç€æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸€äº›éEEGï¼Œä½†æ˜¯å®ƒæœ‰æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼Œåç»­è¿˜èƒ½ä½¿ç”¨ã€‚
        self.channels = []  # æ¯ä¸ªå…ƒç´ æ˜¯ dictï¼šlabel, index, type, unit

        ch = lsl_info.desc().child('channels').child('channel')
        index = 0
        while ch.name() == "channel":
            label = ch.child_value("label")
            ch_type = ch.child_value("type")
            unit = ch.child_value("unit")

            self.channels.append({
                "label": label,
                "index": index,
                "type": ch_type,
                "unit": unit
            })

            ch = ch.next_sibling()
            index += 1

    # === é€šé“ç­›é€‰æ–¹æ³• ===
    def get_all_labels(self):
        return [ch["label"] for ch in self.channels]

    def get_all_indices(self):
        return [ch["index"] for ch in self.channels]

    def get_labels_by_type(self, desired_type="EEG"):
        return [ch["label"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_type(self, desired_type="EEG"):
        return [ch["index"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_labels(self, labels):
        label_set = set(labels)
        return [ch["index"] for ch in self.channels if ch["label"] in label_set]

    def get_labels_excluding_keywords(self, keywords):
        return [ch["label"] for ch in self.channels
                if not any(kw == ch["label"] for kw in keywords)]

    def get_indices_excluding_keywords(self, keywords):
        return [ch["index"] for ch in self.channels
                if not any(kw == ch["label"] for kw in keywords)]

    def get_labels_by_indices(self, indices):
        """
        æ ¹æ®ç´¢å¼•åˆ—è¡¨è·å–å¯¹åº”çš„é€šé“ååˆ—è¡¨
        """
        index_set = set(indices)
        return [ch["label"] for ch in self.channels if ch["index"] in index_set]

    # === ä¿¡æ¯æ‰“å°æ–¹æ³• ===
    def print_summary(self):
        print("=== Stream Info ===")
        print(f"Name      : {self.name}")
        print(f"Type      : {self.type}")
        print(f"Channels  : {self.channel_count}")
        print(f"Sampling  : {self.srate} Hz")
        print(f"UID       : {self.uid}")
        print(f"Hostname  : {self.hostname}")
        print(f"Source ID : {self.source_id}")
        print(f"Version   : {self.version}")
        print(f"Created   : {self.created_at}")
        print("\n=== Channel List ===")
        for ch in self.channels:
            print(f"[{ch['index']:02}] {ch['label']} | Type: {ch['type']} | Unit: {ch['unit']}")