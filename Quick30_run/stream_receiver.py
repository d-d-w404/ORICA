import threading
import time

from pylsl import StreamInlet, resolve_byprop
import numpy as np
from filter_utils import EEGSignalProcessor

from filter_utils_fir import example_usage
from pylsl import resolve_streams
from orica_processor import ORICAProcessor
from asrpy import ASR
import mne
from scipy.signal import medfilt
from meegkit import asr
import scipy.io

import numpy as np
from mne.filter import filter_data
from FirFilter import rest_fir_filter

class LSLStreamReceiver:
    def __init__(self, stream_type='EEG', time_range=5):
        self.stream_type = stream_type
        self.time_range = time_range
        self.inlet = None
        self.srate = None
        self.nbchan = None
        self.fixed_chunk_len = None  # ä½ æƒ³è¦çš„å›ºå®šæ ·æœ¬æ•°
        self._stash = None

        self.buffer = None#è¿™ä¸ªbufferæš‚æ—¶åªæœ‰viewé‡Œé¢ä½¿ç”¨ç”¨æ¥ç»˜å›¾
        self.chan_labels = []
        self.channel_range = []

        self.channel_manager=None
        self.cutoff = (1, 50)

        # ASR
        self.use_asr = False
        self.asr_calibrated = False
        self.asr_calibration_buffer = None
        self.prep_reference = None
        self.asr_filter = None  # âœ… å­˜å‚¨å·²æ ¡å‡†çš„ASRå®ä¾‹

        self.raw_buffer = None  # å­˜æ”¾æœª ASR çš„ bandpass-only å†å²æ•°æ®
        self.buffer_real = None

        self.samples_buffer = None


        self.pair_buffer = None

        # âœ… ç§»é™¤callbackæœºåˆ¶ï¼Œæ”¹ä¸ºçº¯æ•°æ®æ¥å£æ¨¡å¼
        # self.analysis_callbacks = []  # å­˜æ”¾æ‰€æœ‰å›è°ƒåˆ†æå‡½æ•°

        # âœ… æ–°å¢ï¼šCARè®¾ç½®
        self.use_car = False  # æ˜¯å¦å¯ç”¨CAR

        #ORICA
        self.orica = None
        self.latest_sources = None
        self.latest_eog_indices = None


        #å½“æˆ‘åœ¨åˆ‡æ¢é€šé“çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè®©icçš„ä¸ªæ•°å‘ç”Ÿæ”¹å˜ï¼Œä½†æ˜¯æ­¤æ—¶bufferè¿˜åœ¨è¿è¡Œï¼Œä¼šå¯¼è‡´å¡æ­»ï¼Œ
        #æ‰€ä»¥æˆ‘éœ€è¦æŠŠé€šé“åˆ‡æ¢è¿‡ç¨‹é”ä½
        self.lock = threading.Lock()
        
        # âœ… æ–°å¢ï¼šæ•°æ®æ›´æ–°çº¿ç¨‹æ§åˆ¶
        self.data_update_thread = None
        self.is_running = False
        self.update_interval = 0.1  # 100msæ›´æ–°é—´éš”
        
        # âœ… æ–°å¢ï¼šæ•°æ®æ¥å£ç›¸å…³
        self.last_unclean_chunk = None  # æœ€æ–°çš„åŸå§‹æ•°æ®å—
        self.last_processed_chunk = None  # æœ€æ–°çš„å¤„ç†åæ•°æ®å—
        self.data_timestamp = 0  # æ•°æ®æ—¶é—´æˆ³ï¼Œç”¨äºæ£€æµ‹æ•°æ®æ›´æ–°

        #ç”¨äºç”»å›¾æ—¶ï¼Œä¿è¯å¤„ç†åçš„æ•°æ®å’Œå¤„ç†å‰çš„èƒ½å¤Ÿåœ¨æ—¶é—´ä¸Šå»åˆ
        self.chunk_pairs = []  # [(timestamp, unclean, processed)]


    def find_and_open_stream(self):

        #check the whole stream
        streams = resolve_streams()
        print("ğŸ” å½“å‰å¯ç”¨çš„ LSL æµï¼š")
        for i, stream in enumerate(streams):
            print(
                f"[{i}] Name: {stream.name()}, Type: {stream.type()}, Channels: {stream.channel_count()}, ID: {stream.source_id()}")
        #--------------------------------------

        print(f"Searching for LSL stream with type = '{self.stream_type}'...")
        #streams = resolve_byprop('type', self.stream_type, timeout=5)

        # #æš‚æ—¶ä½¿ç”¨nameç­›é€‰stream
        stream_name = 'mybrain'
        streams = resolve_byprop('name', stream_name, timeout=60)

        if not streams:
            raise RuntimeError(f"No LSL stream with type '{self.stream_type}' found.")

        #æˆ‘ä½¿ç”¨RESTåšLSLçš„æ—¶å€™æœ‰ä¸¤ä¸ªlsl,éƒ½æ˜¯eegç±»å‹ï¼Œè¿™é‡Œåº”è¯¥ä¼šé»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªï¼Œä½†æ˜¯ç¬¬ä¸€ä¸ªä¸æ˜¯lsl outputçš„ï¼Œä¼šå¡æ­»
        #è¿™é‡Œæš‚æ—¶ä½¿ç”¨1ï¼Œå› ä¸º0ç”¨ä¸äº†è€æ˜¯å¡æ­»
        self.inlet = StreamInlet(streams[0])
        info = self.inlet.info()

        print("=== StreamInfo XML description ===")
        print(self.inlet.info().as_xml())

        info = self.inlet.info()
        self.channel_manager = ChannelManager(info)

        self.srate = int(info.nominal_srate())
        self.nbchan = info.channel_count()

        # chs = info.desc().child('channels').child('channel')
        # all_labels = []
        # for _ in range(self.nbchan):
        #     label = chs.child_value('label')
        #     all_labels.append(label if label else f"Ch {_+1}")
        #     chs = chs.next_sibling()
        #
        # # self.chan_labels = all_labels.copy()
        # # self.enabled = [True] * len(self.chan_labels)  # â† æ·»åŠ è¿™è¡Œï¼Œæ ‡è®°æ¯ä¸ªé€šé“æ˜¯å¦å¯ç”¨
        #
        # exclude_keywords = ['TRIGGER', 'ACC', 'ExG', 'Packet', 'A2','O2','Oz']
        # for i, label in enumerate(all_labels):
        #     if not any(keyword in label for keyword in exclude_keywords):
        #         self.chan_labels.append(label)
        #         self.channel_range.append(i)

        
        #å‰é¢çš„5ä¸ªé€šé“
        #exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','ACC','A2','Oz','P3','F8','PO8','F7','Fz', 'T7', 'FC6', 'F4', 'C4', 'CP6', 'Cz', 'CP5', 'O2', 'O1', 'P4', 'P7', 'P8', 'Pz', 'PO7', 'T8', 'C3', 'F3', 'FC5']

        exclude = ['TRIGGER', 'ACC34','ACC33','ACC32', 'Packet Counter', 'ExG 2','ExG 1','ACC']#,'F7','F8'
        #exclude =[]
        self.chan_labels = self.channel_manager.get_labels_excluding_keywords(exclude)
        self.channel_range = self.channel_manager.get_indices_excluding_keywords(exclude)

        # print(self.chan_labels)
        # print(self.channel_range)
        #è¿™é‡Œçš„self.channel_range å¯¹åº”äº†æ¯ä¸€ä¸ªself.chan_labelsæ ‡ç­¾çš„åºå·
        #å‡å¦‚æˆ‘åœ¨ä¸Šé¢çš„excludeä¸­å»æ‰äº†O2,é‚£ä¹ˆO2è¿™ä¸ªlabelä»¥åŠä»–çš„åºå·éƒ½ä¼šè¢«åˆ é™¤ã€‚

        self.nbchan = len(self.channel_range)

        self._stash = np.empty((info.channel_count(), 0))
        self.fixed_chunk_len = 100  # ä½ æƒ³è¦çš„å›ºå®š chunk é•¿åº¦

        self.buffer = np.zeros((info.channel_count(), self.srate * self.time_range))

        #for the comparing stream
        self.raw_buffer = np.zeros((info.channel_count(), self.srate * self.time_range))
        self.buffer_real = np.zeros((info.channel_count(), self.srate * self.time_range))

        print(f"Stream opened: {info.channel_count()} channels at {self.srate} Hz")
        print(f"Using {self.nbchan} EEG channels: {self.chan_labels}")



        # âœ… åˆå§‹åŒ– ORICA
        self.reinitialize_orica()



    def process_orica(self, chunk):
        """
        å¯¹è¾“å…¥çš„chunkè¿›è¡ŒORICAä¼ªå½±å»é™¤å¤„ç†ã€‚
        è¾“å…¥ï¼šchunkï¼ˆshape: é€šé“æ•°, æ ·æœ¬æ•°ï¼‰ï¼Œåªå¤„ç†self.channel_rangeå¯¹åº”çš„é€šé“ã€‚
        è¾“å‡ºï¼š
            cleaned_chunk: ä¼ªå½±å»é™¤åçš„chunkï¼ˆåªå¯¹self.channel_rangeéƒ¨åˆ†åšäº†ä¿®æ”¹ï¼Œå…¶ä½™é€šé“ä¸å˜ï¼‰
            ica_sources: ICAæºä¿¡å·ï¼ˆcomponents, samplesï¼‰ï¼Œå¯ç”¨äºå¯è§†åŒ–
            eog_indices: EOGä¼ªå½±æˆåˆ†ç´¢å¼•
            A: ICA mixing matrix (é€šé“æ•°, æˆåˆ†æ•°)
            spectrum: dictï¼ŒåŒ…å«æ‰€æœ‰ICåˆ†é‡çš„é¢‘è°±ï¼ˆ'freqs': é¢‘ç‡, 'powers': shape=(n_components, n_freqs)ï¼‰
        """
        import numpy as np
        from scipy.signal import welch
        cleaned_chunk = chunk.copy()
        ica_sources = None
        eog_indices = None
        A = None
        spectrum = None
        # ORICAå¤„ç†
        if self.orica is not None:
            if self.orica.update_buffer(chunk[self.channel_range, :]):
            #è¿™ä¸€å¥è¯å®é™…ä¸Šå°±ï¼Œè¿™ä¸ªupdata_bufferå°±ä¿è¯äº†ä¸€ä¸ªç¨³å®šé•¿åº¦çš„bufferç”¨äºoricaçš„å¤„ç†ï¼Œè™½ç„¶chunkå¤§å°ä¸ä¸€ï¼Œä½†æ˜¯æ²¡æœ‰å…³ç³»
                if self.orica.fit(self.orica.data_buffer, self.channel_range, self.chan_labels, self.srate):
                    # âœ… ä» ORICAProcessor å–å‡º ICLabel ç»“æœï¼Œä¾› GUI ä½¿ç”¨
                    ic_probs, ic_labels = self.orica.get_iclabel_results()
                    self.latest_ic_probs = ic_probs
                    self.latest_ic_labels = ic_labels


                    cleaned = self.orica.transform(chunk[self.channel_range, :])
                    cleaned_chunk[self.channel_range, :] = cleaned
                    ica_sources = self.orica.ica.transform(self.orica.data_buffer.T).T  # (components, samples)
                    eog_indices = self.orica.eog_indices
                    
                    # è·å–mixing matrix A
                    try:
                        A = np.linalg.pinv(self.orica.ica.W)
                    except Exception:
                        A = None
                    # è·å–æ‰€æœ‰ICåˆ†é‡çš„spectrum
                    if ica_sources is not None:
                        powers = []
                        freqs = None
                        for ic in range(ica_sources.shape[0]):
                            f, Pxx = welch(ica_sources[ic], fs=self.srate)
                            if freqs is None:
                                freqs = f
                            powers.append(Pxx)
                        powers = np.array(powers)  # shape: (n_components, n_freqs)
                        spectrum = {'freqs': freqs, 'powers': powers}
                    
        return cleaned_chunk, ica_sources, eog_indices, A, spectrum

    def pull_and_update_buffer(self):
        # ç›®æ ‡é•¿åº¦
        # target = self.fixed_chunk_len

        # # æ‹‰å–å°½é‡æ¥è¿‘ç›®æ ‡é•¿åº¦çš„ä¸€æ¬¡æ•°æ®
        # samples, timestamps = self.inlet.pull_chunk(max_samples=target, timeout=0.0)
        # if timestamps:
        #     new = np.asarray(samples, dtype=float).T  # (channels, samples)
        #     print("test1",new.shape)


        #     # æ‹¼æ¥è¿›ç¼“å­˜
        #     buf = np.concatenate([self._stash, new], axis=1)

        #     if buf.shape[1] >= target:
        #         # æˆªå–å›ºå®šé•¿åº¦ä½œä¸ºæœ¬æ¬¡ chunk
        #         chunk = buf[:, :target]
        #         # å‰©ä½™ç•™ä½œä¸‹æ¬¡
        #         self._stash = buf[:, target:]
        #     else:
        #         # ä¸è¶³åˆ™é›¶å¡«å……åˆ°å›ºå®šé•¿åº¦
        #         pad = np.zeros((self._stash.shape[0], target - buf.shape[1]), dtype=buf.dtype)
        #         chunk = np.concatenate([buf, pad], axis=1)
        #         self._stash = np.empty((self._stash.shape[0], 0), dtype=buf.dtype)

        #     # åç»­å¤„ç†ç»§ç»­ç”¨ chunkï¼ˆshape: channels x targetï¼‰
        #     # chunk = EEGSignalProcessor.eeg_filter(chunk, self.srate, cutoff=self.cutoff)
        #     # ... ä½ çš„åç»­é€»è¾‘
        #     print("test",chunk.shape)
        # é‡‡é›†ï¼ˆä¿æŒä½å»¶è¿Ÿï¼‰


        # samples, timestamps = self.inlet.pull_chunk(timeout=0.0)
        # if timestamps:
        #     new = np.asarray(samples, dtype=float).T
        #     if new.shape[0] != 37:
        #         new = new[:37, :]
            
        #     # ç´¯ç§¯åˆ° stash
        #     if self._stash is None:
        #         self._stash = new
        #     else:
        #         self._stash = np.concatenate([self._stash, new], axis=1)
            
        #     # åªæœ‰å½“ stash è¶³å¤Ÿæ—¶æ‰å¤„ç†
        #     if self._stash.shape[1] >= self.fixed_chunk_len:
        #         # å–å›ºå®šé•¿åº¦å¤„ç†
        #         chunk = self._stash[:, :self.fixed_chunk_len]
        #         # å‰©ä½™éƒ¨åˆ†ä¿ç•™
        #         self._stash = self._stash[:, self.fixed_chunk_len:]
        #         print("chunk",chunk.shape)
        #     else:
        #         print("nothing")
        #         return

        '''
        æš‚æ—¶å…ˆä¸ç”¨è¿™ä¸ªï¼Œå› ä¸ºæˆ‘å‘ç°åœ¨orica_processor.pyä¸­ï¼Œupdata_bufferä¼šä¿æŒä¸€ä¸ªç¨³å®šçš„é•¿åº¦
        æ‰€ä»¥è™½ç„¶chunké•¿åº¦ä¸ä¸€è‡´ï¼Œä½†æ˜¯æˆ‘èƒ½å¤Ÿä¿è¯æˆ‘åç»­åœ¨ä½¿ç”¨oricaçš„æ—¶å€™èƒ½å¤Ÿä»ç¨³å®šé•¿åº¦çš„bufferä¸­å–æ•°æ®
        
        '''






        # samples, timestamps = self.inlet.pull_chunk(timeout=0.0)
        # if timestamps:

        #     new = np.asarray(samples, dtype=float).T  # (channels, samples)
        #     print("new1",new.shape)
        #     if new.shape[0] != 37:
        #         new = new[:37, :]

        #     print("new",new.shape)

        #     # å†™å…¥åŸå§‹ç¯å½¢ç¼“å†²ï¼ˆå®æ—¶ï¼‰
        #     self.buffer_real = np.roll(self.buffer_real, -new.shape[1], axis=1)
        #     #self.buffer_real[:, -new.shape[1]:] = EEGSignalProcessor.eeg_filter(new, self.srate, cutoff=self.cutoff)
        #     self.buffer_real[:, -new.shape[1]:] = new

        #     print("buffer_real",self.buffer_real.shape)
        #     # å¤„ç†/ç»˜å›¾ç”¨å›ºå®šå¸§é•¿ï¼ˆä¸ç­‰å¾…ï¼‰ï¼šç›´æ¥ä»ç¯å½¢ç¼“å†²å–â€œæœ€è¿‘ target åˆ—â€
        #     target = self.fixed_chunk_len  # ä¾‹å¦‚ int(self.srate / self.refresh_rate) æˆ– 50
        #     print("target",target)
        #     take = min(target, self.buffer_real.shape[1])
        #     print("take",take)
        #     chunk = self.buffer_real[:, -take:]  # chunk åˆ—æ•°<=targetï¼Œä½†ä¸ä¸­æ–­ã€ä¸å¡«å……
        #     print("chunk",chunk.shape)

        #     # å¦‚æœä½ â€œå¿…é¡»â€å–‚å›ºå®šåˆ—æ•°ç»™ç®—æ³•ï¼šä»…åœ¨è¶³å¤Ÿæ—¶æ‰å¤„ç†ï¼›ä¸å¤Ÿæ—¶è·³è¿‡æœ¬å¸§
        #     if take < target:
        #         print("take < target")
        #         return  # æœ¬å¸§è·³è¿‡å¤„ç†ï¼Œç»§ç»­ä¿æŒå®æ—¶é‡‡é›†ä¸æ˜¾ç¤º

        #samples, timestamps = self.inlet.pull_chunk(timeout=0.0)
        samples_random, timestamps = self.inlet.pull_chunk(timeout=0.0)
        #samples, timestamps = self.inlet.pull_chunk(max_samples=100, timeout=0.0)#

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if not timestamps:
            return
            
        # è½¬æ¢samples_randomä¸ºæ­£ç¡®çš„æ ¼å¼ (channels, samples)
        samples_random = np.array(samples_random).T
        
        if samples_random is not None:
            print("y"*20)
            print(samples_random.shape)
            print(samples_random)
            print("y"*20) 

        # #è¿™ä¸ªæ˜¯ç”¨äºéªŒè¯çš„æ—¶å€™ï¼Œä¿è¯æ¯æ¬¡ä¼ å…¥éƒ½æ˜¯å›ºå®šçš„size
        # print("samples_random",samples_random.shape)
        # if self.samples_buffer is None:
        #     self.samples_buffer = samples_random.copy()
        # else:
        #     self.samples_buffer = np.concatenate([self.samples_buffer, samples_random], axis=1)
        
        # if self.samples_buffer.shape[1] >= 20:
        #     print("sampleså·²ç»æ»¡äº†",self.samples_buffer.shape)

        #     # å–å‰é¢çš„100ä¸ªæ ·æœ¬ä½œä¸ºsamples
        #     samples = self.samples_buffer[:, :20]
            
        #     # æŠŠå‰©ä½™çš„æ ·æœ¬æ”¾åˆ°æ–°çš„samples_bufferçš„æœ€å‰é¢
        #     remaining_samples = self.samples_buffer[:, 20:]
        #     if remaining_samples.shape[1] > 0:
        #         self.samples_buffer = remaining_samples
        #     else:
        #         print("åˆç†=============================")
        #         self.samples_buffer = None

        # else:
        #     #print("samplesè¿˜æ²¡æœ‰æ»¡",self.samples_buffer.shape)
        #     return
    
        #è¿™é‡Œæ˜¯ä¸åœ¨ä¹sampleså¤§å°çš„ï¼Œå®é™…ä¸­å°±æ˜¯è¿™æ ·çš„
        samples=samples_random
        print("xxx")
        print("samplesxxxxx",samples.shape)
        '''
        timestampes æœ‰çš„æ—¶å€™å¯èƒ½æ˜¯(0,),è¿™ç§æƒ…å†µå°±æ˜¯æ²¡æœ‰æ•°æ®ï¼Œä¸‹é¢çš„ifåˆ¤å®šå°±ä¸ä¼šæ‰§è¡Œã€‚
        timestampes æœ‰æ•°æ®çš„æ—¶å€™å°±ä¼šæ˜¯(samplesçš„size,0)è¿™æ ·çš„æ•°æ®ï¼Œä»£è¡¨äº†æ¯ä¸€ä¸ªsampleéƒ½æœ‰ä¸€ä¸ªæ—¶é—´æˆ³
        '''
        if timestamps:
            chunk = np.array(samples)  # shape: (channels, samples)è¿™é‡Œçš„samplesçš„å¤§å°æ˜¯ä¸å›ºå®šçš„
            print("FIR filter in")
            print("testin",chunk.shape) # test (14, 36)
            print("testin",chunk[0:3,0:3])




            # # âœ… æ›´æ–°åŸå§‹æ»¤æ³¢åçš„æ•°æ®æ¥å£
            # self.last_unclean_chunk = chunk.copy()
            # if self.raw_buffer is not None:
            #     self.raw_buffer = np.roll(self.raw_buffer, -chunk.shape[1], axis=1)
            #     self.raw_buffer[:, -chunk.shape[1]:] = self.last_unclean_chunk


            # Step 1: ä½¿ç”¨ MNE çš„ä¸“ä¸š FIR æ»¤æ³¢å™¨
            chunk = self.apply_mne_iir_filter(chunk)
            #chunk = self.apply_scipy_fir_filter(chunk)
            # chunk = EEGSignalProcessor.eeg_filter(chunk, self.srate, cutoff=self.cutoff)
            #chunk = rest_fir_filter(chunk, srate=self.srate, cutoff=self.cutoff)

            
            # filtered = filter_data(
            #     data=chunk,
            #     sfreq=self.srate,
            #     l_freq=1.0,
            #     h_freq=50.0,
            #     method='fir',
            #     fir_design='firwin',
            #     fir_window='hamming',       # æ›´æ˜“æ»¡è¶³é˜»å¸¦è¡°å‡éœ€æ±‚
            #     phase='minimum',           # æœ€å°ç›¸ä½ï¼Œå¯¹åº” flt_fir 'minimum-phase'
            #     l_trans_bandwidth=0.5,     # å¯¹åº” 0.5â†’1 Hz çš„ä½ç«¯è¿‡æ¸¡å¸¦
            #     h_trans_bandwidth=5.0,     # å¯¹åº” 50â†’55 Hz çš„é«˜ç«¯è¿‡æ¸¡å¸¦
            #     filter_length='auto',      # è‹¥éœ€æ›´å¼ºé˜»å¸¦ï¼Œå¯æ‰‹åŠ¨åŠ é•¿ï¼Œå¦‚ '20s' æˆ– 8191
            #     verbose=False
            # )
            # chunk = filtered

            # print("testout",chunk.shape)
            # print("testout",chunk[0:3,0:3])


            # print("FIR filter out")

            # # âœ… æ›´æ–°åŸå§‹æ»¤æ³¢åçš„æ•°æ®æ¥å£
            # self.last_unclean_chunk = chunk.copy()
            # if self.raw_buffer is not None:
            #     self.raw_buffer = np.roll(self.raw_buffer, -chunk.shape[1], axis=1)
            #     self.raw_buffer[:, -chunk.shape[1]:] = self.last_unclean_chunk


            # # # âœ… æ–°å¢ï¼šCARå¤„ç†
            # # if self.use_car:  # éœ€è¦æ·»åŠ è¿™ä¸ªæ ‡å¿—
            # #     chunk = self.apply_car(chunk)

            # # Step 2: ASRå¤„ç†
            # # if self.use_asr:
            # #     chunk = self.apply_pyprep_asr(chunk)

            # print("ASR in")
            # # pip install asrpy
            # from asrpy import ASR
            # # å‡è®¾ï¼š
            # # calib: (n_channels, n_samples) æ ¡å‡†æ•°æ®ï¼ˆå°½é‡â‰¥60ç§’ï¼‰ï¼Œä¸åœ¨çº¿æ•°æ®åŒé«˜é€šç­–ç•¥
            # # srate: é‡‡æ ·ç‡ (Hz)
            # # stream() äº§å‡ºåœ¨çº¿åˆ†å— chunk: (n_channels, n_chunk)
            # raw_cali = mne.io.read_raw_eeglab(r'D:\work\Python_Project\ORICA\temp_txt\Demo_EmotivEPOC_EyeOpen.set', preload=True)
            # # åªä¿ç•™ EEG é€šé“ï¼ˆå»æ‰ EOG/stim/miscï¼‰
            # raw_cali.pick_types(eeg=True, eog=False, stim=False, misc=False)

            # # 2) è·å–æ ¡å‡†æ•°æ® calib å’Œé‡‡æ ·ç‡
            # calib = raw_cali.get_data()      
            #         # å½¢çŠ¶ (n_channels, n_samples)
            # print("raw calib")
            # print(calib[0:3,0:3])

            
            # #å»æ‰åé€šé“æ•°æ®
            # calib=self.select_clean_reference(calib,self.srate)
            # print(calib[0:3,0:3])

            # # # 1) åˆå§‹åŒ– ASRï¼ˆå‚æ•°æ˜ å°„è‡ª flt_repair_burstsï¼‰
            # # asr = ASR(
            # #     sfreq=self.srate,
            # #     cutoff=10.0,           # stddev_cutoff
            # #     win_len=0.5,           # window_len
            # #     step_size=0.3333,      # block_size -> stats update step
            # #     lookahead=0.125,       # processing_delay
            # #     max_dims_ratio=0.66,   # max_dimensions (æ¯”ä¾‹)
            # #     spectral_weighting=False,  # è‹¥è¦å¤åˆ»é¢‘è°±åŠ æƒï¼Œè¿™é‡Œæ”¹æˆ True å¹¶æä¾›IIR
            # #     use_gpu=False
            # #     # å¦‚æœåº“æ”¯æŒï¼šdecim=10  # å¯¹åº” calib_precision
            # # )
            # asr = ASR(
            #     sfreq=self.srate,
            #     cutoff=10.0,        # å…¸å‹ï¼šstddev_cutoff
            #     win_len=0.5,        # å…¸å‹ï¼šwindow_len
            # )
            # print("done")

            # # 2) æ ‡å®šï¼šç”¨ MNE RawArray åŒ…è£… calib å¹¶æ‹Ÿåˆ
            # cal_C, cal_S = calib.shape
            # cal_ch_names = [f"EEG{i+1}" for i in range(cal_C)]
            # info_cal = mne.create_info(ch_names=cal_ch_names, sfreq=self.srate, ch_types='eeg')
            # ref_raw = mne.io.RawArray(calib, info_cal, verbose=False)
            # asr.fit(ref_raw)

            # # 3) åœ¨çº¿å¤„ç†ï¼šåŒæ ·ç”¨ RawArray åŒ…è£… chunk å† transform
            # print("ok")
            # ch_C, ch_S = chunk.shape
            # ch_ch_names = [f"EEG{i+1}" for i in range(ch_C)]
            # info_chunk = mne.create_info(ch_names=ch_ch_names, sfreq=self.srate, ch_types='eeg')
            # chunk_raw = mne.io.RawArray(chunk, info_chunk, verbose=False)
            # clean_raw = asr.transform(chunk_raw)
            # chunk = clean_raw.get_data()   # (channels, samples)
            # # å¦‚æœåº“æ”¯æŒåˆ†ç¦»å™ªå£°ï¼Œå¯ï¼š
            # # clean_chunk, noise_chunk = asr.transform(chunk, return_noise=True)
            # # ä½ çš„åç»­å¤„ç†...

            #step 2: ASR
            # âœ… ä½¿ç”¨å°è£…çš„ ASR åˆå§‹åŒ–å‡½æ•°ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ ¡å‡†ï¼Œä¹‹åç›´æ¥å¤ç”¨ï¼‰
            if self.asr_filter is None:
                self.initialize_asr_from_mat()
            
            # åº”ç”¨ ASR æ¸…ç†ï¼ˆå¦‚æœå·²æ ¡å‡†ï¼‰
            if self.asr_filter is not None:
                chunk = self.asr_filter.transform(chunk)


            # âœ… æ›´æ–°åŸå§‹æ»¤æ³¢åçš„æ•°æ®æ¥å£
            self.last_unclean_chunk = chunk.copy()
            if self.raw_buffer is not None:
                self.raw_buffer = np.roll(self.raw_buffer, -chunk.shape[1], axis=1)
                self.raw_buffer[:, -chunk.shape[1]:] = self.last_unclean_chunk




            #âœ… Step X: ORICA å»çœ¼åŠ¨ä¼ªå½±ï¼ˆé‡æ„ä¸ºç‹¬ç«‹å‡½æ•°ï¼‰
            chunk, ica_sources, eog_indices,A,spectrum = self.process_orica(chunk)
            if ica_sources is not None:
                self.latest_sources = ica_sources
            if eog_indices is not None:
                self.latest_eog_indices = eog_indices



            # Step 3: Update ring buffer
            num_new = chunk.shape[1]
            self.buffer = np.roll(self.buffer, -num_new, axis=1)
            self.buffer[:, -num_new:] = chunk
            
            # âœ… æ›´æ–°å¤„ç†åæ•°æ®æ¥å£
            self.last_processed_chunk = chunk.copy()
            self.data_timestamp = time.time()


            
                # 3. å­˜æˆä¸€å¯¹
            timestamp = time.time()
            self.chunk_pairs.append((timestamp, self.last_unclean_chunk, self.last_processed_chunk))
            # åªä¿ç•™æœ€è¿‘Nå¯¹
            if len(self.chunk_pairs) > 1:
                self.chunk_pairs.pop(0)

            self.pair_buffer = (self.raw_buffer, self.buffer)

            # âœ… Step 4: å›è°ƒåˆ†æå‡½æ•°
            # for fn in self.analysis_callbacks: # ç§»é™¤æ­¤è¡Œ
            #     try: # ç§»é™¤æ­¤è¡Œ
            #         thread = threading.Thread( # ç§»é™¤æ­¤è¡Œ
            #             target=fn, # ç§»é™¤æ­¤è¡Œ
            #             kwargs=dict( # ç§»é™¤æ­¤è¡Œ
            #                 chunk=self.buffer[self.channel_range, :], # ç§»é™¤æ­¤è¡Œ
            #                 raw=self.raw_buffer[self.channel_range, :], # ç§»é™¤æ­¤è¡Œ
            #                 srate=self.srate, # ç§»é™¤æ­¤è¡Œ
            #                 labels=self.chan_labels # ç§»é™¤æ­¤è¡Œ
            #             ) # ç§»é™¤æ­¤è¡Œ
            #         ) # ç§»é™¤æ­¤è¡Œ
            #         thread.start() # ç§»é™¤æ­¤è¡Œ
            #     except Exception as e: # ç§»é™¤æ­¤è¡Œ
            #         print(f"âŒ å›è°ƒåˆ†æå‡½æ•°é”™è¯¯: {e}") # ç§»é™¤æ­¤è¡Œ


    


    #Selected channel indices: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]
    #Selected channel labels: ['AF7', 'Fpz', 'F7', 'Fz', 'T7', 'FC6', 'F4', 'C4', 'Oz', 'CP6', 'Cz', 'PO8', 'CP5', 'O2', 'O1', 'P3', 'P4', 'P7', 'P8', 'Pz', 'PO7', 'T8', 'C3', 'Fp2', 'F3', 'F8', 'FC5', 'AF8']
    #ä¸Šé¢å°±æ˜¯channel_rangeå’Œchannel_labelsçš„æ ¼å¼ï¼Œè¦è°ƒç”¨å‡½æ•°å°±ä¼ å…¥è¿™æ ·çš„list
    def set_channel_range_and_labels(self, new_range, new_labels):
        with self.lock:
            self.channel_range = new_range
            self.chan_labels = new_labels
            self.nbchan = len(new_range)
            self.reinitialize_orica()
            print(f"ğŸ” é€šé“æ›´æ–°: {self.chan_labels}")


    def register_analysis_callback(self, callback_fn):
        """æ³¨å†Œä¸€ä¸ªå‡½æ•°ç”¨äºå¤„ç†æ¯æ¬¡æ›´æ–°åçš„æ•°æ®æ®µ chunk"""
        # self.analysis_callbacks.append(callback_fn) # ç§»é™¤æ­¤è¡Œ
        pass # ç§»é™¤æ­¤è¡Œ

    def reinitialize_orica(self):
        self.orica = ORICAProcessor(
            n_components=len(self.channel_range),
            max_samples=self.srate * 10,
            srate=self.srate
        )
        print("ğŸ” ORICA processor re-initialized with new channel range.")
    
    def apply_mne_fir_filter(self, data):
        """
        ä½¿ç”¨ MNE-Python çš„ä¸“ä¸š FIR æ»¤æ³¢å™¨
        ä¸“ä¸º EEG æ•°æ®è®¾è®¡ï¼Œæ•ˆæœæ›´å¥½
        """
        try:
            from mne.filter import filter_data
            
            # ä½¿ç”¨ MNE çš„ä¸“ä¸š FIR æ»¤æ³¢å™¨ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
            filtered_data = filter_data(
                data=data,
                sfreq=self.srate,
                l_freq=self.cutoff[0],      # ä½é¢‘æˆªæ­¢
                h_freq=self.cutoff[1],      # é«˜é¢‘æˆªæ­¢
                method='fir',               # ä½¿ç”¨ FIR æ»¤æ³¢å™¨
                phase='zero-double',        # é›¶ç›¸ä½ï¼ŒåŒå‘æ»¤æ³¢å‡å°‘å»¶è¿Ÿ
                l_trans_bandwidth=0.25,     # æ›´çª„çš„ä½é¢‘è¿‡æ¸¡å¸¦
                h_trans_bandwidth=2.5,      # æ›´çª„çš„é«˜é¢‘è¿‡æ¸¡å¸¦
                filter_length='10s',        # å›ºå®šæ»¤æ³¢å™¨é•¿åº¦ï¼Œé¿å…è¿‡é•¿
                fir_window='hamming',       # ä½¿ç”¨ Hamming çª—
                verbose=False
            )
            
            print(f"âœ… MNE FIR æ»¤æ³¢å®Œæˆ: {self.cutoff[0]}-{self.cutoff[1]} Hz")
            return filtered_data
            
        except Exception as e:
            print(f"âŒ MNE FIR æ»¤æ³¢å¤±è´¥: {e}")
            print("âš ï¸ å›é€€åˆ°åŸå§‹æ•°æ®")
            return data

    def apply_mne_iir_filter(self, data):
        """
        ä½¿ç”¨ MNE-Python çš„ IIR æ»¤æ³¢å™¨ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        å»¶è¿Ÿæ›´å°ï¼Œé€‚åˆå®æ—¶å¤„ç†
        """
        try:
            from mne.filter import filter_data
            
            # ä½¿ç”¨ IIR æ»¤æ³¢å™¨ï¼Œå»¶è¿Ÿæ›´å°
            filtered_data = filter_data(
                data=data,
                sfreq=self.srate,
                l_freq=self.cutoff[0],      # ä½é¢‘æˆªæ­¢
                h_freq=self.cutoff[1],      # é«˜é¢‘æˆªæ­¢
                method='iir',               # ä½¿ç”¨ IIR æ»¤æ³¢å™¨
                iir_params={'order': 4, 'ftype': 'butter'},  # 4é˜¶ Butterworth
                verbose=False
            )
            
            print(f"âœ… MNE IIR æ»¤æ³¢å®Œæˆ: {self.cutoff[0]}-{self.cutoff[1]} Hz")
            return filtered_data
            
        except Exception as e:
            print(f"âŒ MNE IIR æ»¤æ³¢å¤±è´¥: {e}")
            print("âš ï¸ å›é€€åˆ°åŸå§‹æ•°æ®")
            return data

    def apply_scipy_fir_filter(self, data):
        """
        ä½¿ç”¨ SciPy çš„ FIR æ»¤æ³¢å™¨ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        æ›´è½»é‡çº§ï¼Œé€‚åˆå®æ—¶å¤„ç†
        """
        try:
            from scipy import signal
            
            # è®¾è®¡ FIR å¸¦é€šæ»¤æ³¢å™¨
            nyquist = self.srate / 2
            low = self.cutoff[0] / nyquist
            high = self.cutoff[1] / nyquist
            
            # ä½¿ç”¨ window æ–¹æ³•è®¾è®¡ FIR æ»¤æ³¢å™¨
            taps = signal.firwin(
                numtaps=101,           # æ»¤æ³¢å™¨é•¿åº¦
                cutoff=[low, high],    # æˆªæ­¢é¢‘ç‡
                window='hann',         # çª—å‡½æ•°
                pass_zero=False,       # å¸¦é€šæ»¤æ³¢å™¨
                scale=True
            )
            
            # åº”ç”¨æ»¤æ³¢å™¨
            filtered_data = np.array([
                signal.lfilter(taps, 1.0, ch) for ch in data
            ])
            
            print(f"âœ… SciPy FIR æ»¤æ³¢å®Œæˆ: {self.cutoff[0]}-{self.cutoff[1]} Hz")
            return filtered_data
            
        except Exception as e:
            print(f"âŒ SciPy FIR æ»¤æ³¢å¤±è´¥: {e}")
            print("âš ï¸ å›é€€åˆ°åŸå§‹æ•°æ®")
            return data

    def initialize_asr_from_mat(self, mat_file_path=r"D:\work\Python_Project\ORICA\temp_txt\cleaned_data_quick30.mat"):
        """
        ä» MATLAB æ–‡ä»¶åŠ è½½æ ¡å‡†æ•°æ®å¹¶åˆå§‹åŒ– ASRï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        
        Args:
            mat_file_path: æ ¡å‡†æ•°æ®çš„ .mat æ–‡ä»¶è·¯å¾„
        """
        if self.asr_filter is not None:
            print("â© ASR å·²æ ¡å‡†ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
            return self.asr_filter
        
        try:
            from meegkit import asr
            import scipy.io
            
            # åŠ è½½ MATLAB æ–‡ä»¶
            mat_data = scipy.io.loadmat(mat_file_path)
            
            # æå–æ ¡å‡†æ•°æ®ï¼ˆEEGLAB æ ¼å¼ï¼‰
            calibration_data = None
            if 'cleaned_data' in mat_data:
                eeg_struct = mat_data['cleaned_data'][0, 0]
                if 'data' in eeg_struct.dtype.names:
                    calibration_data = eeg_struct['data']
            elif 'data' in mat_data:
                calibration_data = mat_data['data']
            
            if calibration_data is None:
                print(f"âŒ æ— æ³•æå–æ ¡å‡†æ•°æ®ï¼Œå¯ç”¨å­—æ®µ: {mat_data.keys()}")
                return None
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ•°ç»„
            calibration_data = np.asarray(calibration_data, dtype=np.float64)
            print(f"âœ… æ ¡å‡†æ•°æ®åŠ è½½æˆåŠŸ - åŸå§‹å½¢çŠ¶: {calibration_data.shape}")
            
            # åªé€‰æ‹©å½“å‰ä½¿ç”¨çš„é€šé“
            if calibration_data.shape[0] != len(self.channel_range):
                print(f"âš ï¸ é€šé“æ•°ä¸åŒ¹é…ï¼šæ ¡å‡† {calibration_data.shape[0]} é€šé“ï¼Œåœ¨çº¿ {len(self.channel_range)} é€šé“")
                calibration_data = calibration_data[self.channel_range, :]
                print(f"âœ… å·²è°ƒæ•´æ ¡å‡†æ•°æ®å½¢çŠ¶: {calibration_data.shape}")
            
            # åˆå§‹åŒ–å¹¶æ‹Ÿåˆ ASR
            self.asr_filter = asr.ASR(
                sfreq=self.srate,
                cutoff=5,
            )
            self.asr_filter.fit(calibration_data)
            print(f"âœ… ASR å·²æ ¡å‡†å®Œæˆï¼Œé€šé“æ•°: {calibration_data.shape[0]}")
            
            return self.asr_filter
            
        except Exception as e:
            print(f"âŒ ASR åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def start(self):
        """å¯åŠ¨æ•°æ®æµå’Œæ•°æ®æ›´æ–°çº¿ç¨‹"""
        if hasattr(self, 'is_running') and self.is_running:
            print("âš ï¸ æ•°æ®æµå·²åœ¨è¿è¡Œ")
            return
        self.find_and_open_stream()
        self.is_running = True
        self.data_update_thread = threading.Thread(target=self._data_update_loop, daemon=True)
        self.data_update_thread.start()
        print("âœ… æ•°æ®æµå’Œæ•°æ®æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢æ•°æ®æ›´æ–°çº¿ç¨‹"""
        self.is_running = False
        if hasattr(self, 'data_update_thread') and self.data_update_thread and self.data_update_thread.is_alive():
            self.data_update_thread.join(timeout=1.0)
        print("ğŸ›‘ æ•°æ®æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def _data_update_loop(self):
        """æ•°æ®æ›´æ–°å¾ªç¯ - åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ"""
        while self.is_running:
            try:
                self.pull_and_update_buffer()
                time.sleep(self.update_interval)
            except Exception as e:
                print(f"âŒ æ•°æ®æ›´æ–°é”™è¯¯: {e}")
                time.sleep(0.1)  # é”™è¯¯æ—¶çŸ­æš‚ç­‰å¾…

    # âœ… æ–°å¢ï¼šæ•°æ®æ¥å£æ–¹æ³•
    def get_raw_data(self):
        """è·å–æœ€æ–°çš„åŸå§‹æ•°æ®ï¼ˆä»…å¸¦é€šæ»¤æ³¢ï¼‰"""
        return self.last_unclean_chunk.copy() if self.last_unclean_chunk is not None else None
    
    def get_processed_data(self):
        """è·å–æœ€æ–°çš„å¤„ç†åæ•°æ®ï¼ˆORICA + ASRï¼‰"""
        return self.last_processed_chunk.copy() if self.last_processed_chunk is not None else None

    def get_pair_data(self):
        return self.pair_buffer[0][self.channel_range, :], self.pair_buffer[1][self.channel_range, :] if self.pair_buffer is not None else None

    def get_pair_data_old(self, data_type='processed'):
        if data_type == 'raw':
            return self.chunk_pairs.copy()[0][1][self.channel_range, :] if self.chunk_pairs is not None else None
        else:
            return self.chunk_pairs.copy()[0][2][self.channel_range, :] if self.chunk_pairs is not None else None
        #return self.chunk_pairs.copy() if self.chunk_pairs is not None else None
    
    def get_buffer_data(self, data_type='processed'):
        """è·å–ç¼“å†²åŒºæ•°æ®
        
        Args:
            data_type: 'raw' æˆ– 'processed'
        """
        if data_type == 'raw':
            return self.raw_buffer[self.channel_range, :] if self.raw_buffer is not None else None
        else:
            return self.buffer[self.channel_range, :] if self.buffer is not None else None
    
    
    def get_ica_sources(self):
        """è·å–æœ€æ–°çš„ICAæºä¿¡å·"""
        return self.latest_sources.copy() if self.latest_sources is not None else None
    
    def get_eog_indices(self):
        """è·å–EOGä¼ªå½±æˆåˆ†ç´¢å¼•"""
        return self.latest_eog_indices.copy() if self.latest_eog_indices is not None else None
    
    def get_channel_info(self):
        """è·å–é€šé“ä¿¡æ¯"""
        return {
            'labels': self.chan_labels.copy() if self.chan_labels else [],
            'indices': self.channel_range.copy() if self.channel_range else [],
            'count': len(self.channel_range) if self.channel_range else 0,
            'sampling_rate': self.srate
        }
    
    def is_data_available(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•°æ®"""
        return (self.last_unclean_chunk is not None and 
                self.last_processed_chunk is not None and 
                self.buffer is not None)
    
    def get_data_timestamp(self):
        """è·å–æ•°æ®æ—¶é—´æˆ³ï¼Œç”¨äºæ£€æµ‹æ•°æ®æ›´æ–°"""
        return self.data_timestamp





    def print_latest_channel_values(self):
        if self.buffer is None:
            print("âš ï¸ Buffer å°šæœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰“å°é€šé“å€¼")
            return

        # print("--- EEG Channel Values (Last Sample) ---")
        # for i, ch_idx in enumerate(self.channel_range):
        #     label = self.chan_labels[i]
        #     last_value = self.buffer[ch_idx, -1]
        #     rms = np.sqrt(np.mean(self.buffer[ch_idx] ** 2))
        #     print(f"{label:>4}: {last_value:>8.2f} Î¼V | RMS: {rms:.2f}")




    def apply_car(self, chunk):
        """ä½¿ç”¨MNEåŒ…å®ç°CAR"""
        try:
            # åˆ›å»ºä¸´æ—¶çš„MNE Rawå¯¹è±¡
            info = mne.create_info(
                ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                sfreq=self.srate,
                ch_types=["eeg"] * len(self.channel_range)
            )
            
            raw = mne.io.RawArray(chunk[self.channel_range, :], info)      
            # åº”ç”¨CAR
            raw.set_eeg_reference('average')
            
            # è·å–å¤„ç†åçš„æ•°æ®
            chunk[self.channel_range, :] = raw.get_data()
            
            return chunk
        
        except Exception as e:
            print(f"âš ï¸ MNE CARå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨ç®€å•å®ç°: {e}")
            return self.apply_car(chunk)  # å›é€€åˆ°ç®€å•å®ç°

    def apply_pyprep_asr(self, chunk):
        try:
            if not self.asr_calibrated:
                # ğŸ”„ Step 1: æ”¶é›†é™æ¯æ•°æ®è¿›è¡Œæ ¡å‡†
                if self.asr_calibration_buffer is None:
                    self.asr_calibration_buffer = chunk.copy()
                else:
                    self.asr_calibration_buffer = np.concatenate(
                        (self.asr_calibration_buffer, chunk), axis=1
                    )

                if self.asr_calibration_buffer.shape[1] >= self.srate * 20:
                    print("â³ Calibrating ASR...")

                    # â• åˆ›å»º Raw å¯¹è±¡ç”¨äºæ ¡å‡†
                    info = mne.create_info(
                        ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                        sfreq=self.srate,
                        ch_types=["eeg"] * len(self.channel_range)
                    )
                    x=self.channel_manager.get_labels_by_indices(self.channel_range)
                    # print("X" * 30)
                    # print(x)
                    # print("X" * 30)

                    raw = mne.io.RawArray(
                        self.asr_calibration_buffer[self.channel_range, :], info
                    )

                    #
                    # print(self.asr_calibration_buffer[self.channel_range, :])
                    # print("Selected shape:", self.buffer[self.channel_range, :].shape)
                    # print("Selected labels:", self.chan_labels)

                    raw.set_montage("standard_1020")

                    # ğŸ”§ åˆå§‹åŒ–å¹¶æ ¡å‡† ASR å®ä¾‹
                    self.asr_instance = ASR(
                        sfreq=self.srate,

                        cutoff=20,
                        win_len=2,
                        win_overlap=0.8,
                        blocksize=self.srate
                    )

                    self.asr_instance.fit(raw)

                    self.asr_calibrated = True
                    self.asr_calibration_buffer = None
                    print("âœ… ASRpy calibrated successfully.")

            else:
                # ğŸ”„ Step 2: å®æ—¶æ¸…æ´—æ•°æ®
                info = mne.create_info(
                    ch_names=self.channel_manager.get_labels_by_indices(self.channel_range),
                    sfreq=self.srate,
                    ch_types=["eeg"] * len(self.channel_range)
                )
                raw_chunk = mne.io.RawArray(chunk[self.channel_range, :], info)
                raw_chunk.set_montage("standard_1020")

                cleaned_raw = self.asr_instance.transform(raw_chunk)
                chunk[self.channel_range, :] = cleaned_raw.get_data()



                # åœ¨ ASR ååŠ ä¸ªä¸­å€¼æ»¤æ³¢å¤„ç†ï¼Œå¹³æ»‘
                cleaned_chunk = cleaned_raw.get_data()
                cleaned_chunk = medfilt(cleaned_chunk, kernel_size=(1, 5))  # ä¿é€šé“ä¸å˜ï¼Œä»…æ—¶é—´å¹³æ»‘
                chunk[self.channel_range, :] = cleaned_chunk


        except Exception as e:
            print("âŒ Error in apply_pyprep_asr:", e)

        return chunk

    def select_clean_reference(
        self,
        calib: np.ndarray,
        srate: float,
        window_len: float = 0.5,          # çª—é•¿ï¼ˆç§’ï¼‰
        window_overlap: float = 0.66,     # é‡å æ¯”ä¾‹
        zthresholds: tuple = (-3.5, 5.0), # Z åˆ†æ•°é˜ˆå€¼ [ä¸‹é™, ä¸Šé™]
        max_bad_channels: float = 0.15    # å•çª—å…è®¸çš„åé€šé“æ¯”ä¾‹ï¼ˆæˆ–ç»å¯¹æ•°ï¼‰
    ):

        """
        åŸºäº REST/BCILAB flt_clean_windows çš„é»˜è®¤é€»è¾‘ç­›é€‰â€œå¹²å‡€å‚è€ƒæ®µâ€ã€‚
        è¾“å…¥:
        - calib: (n_channels, n_samples) æ ¡å‡†æ•°æ®ï¼ˆå·²åšä¸åœ¨çº¿ä¸€è‡´çš„é«˜é€šï¼‰
        - srate: é‡‡æ ·ç‡(Hz)
        å‚æ•°:
        - window_len: çª—é•¿(ç§’)ï¼Œé»˜è®¤ 0.5
        - window_overlap: çª—é‡å æ¯”ä¾‹ï¼Œé»˜è®¤ 0.66ï¼ˆæ­¥é•¿ â‰ˆ 0.17sï¼‰
        - zthresholds: çª—å£ RMS çš„ç¨³å¥ Z é˜ˆå€¼ï¼ˆç›¸å¯¹â€œå¹²å‡€ EEGâ€åˆ†å¸ƒï¼‰ï¼Œé»˜è®¤ [-3.5, 5]
        - max_bad_channels: å•çª—å…è®¸çš„â€œåé€šé“â€ä¸Šé™ï¼ˆæ¯”ä¾‹æˆ–ç»å¯¹æ•°ï¼‰ï¼Œé»˜è®¤ 0.15
        è¿”å›:
        - ref: (n_channels, n_kept_samples) æ‹¼æ¥çš„å‚è€ƒæ®µ
        - sample_mask: (n_samples,) å¸ƒå°”æ©ç ï¼ŒTrue è¡¨ç¤ºä¿ç•™
        - kept_slices: list[ slice ] ä¿ç•™çš„çª—å£åˆ‡ç‰‡åˆ—è¡¨
        """
        C, S = calib.shape
        N = int(round(window_len * srate))
        if N <= 1 or N > S:
            raise ValueError("window_len å¯¼è‡´çª—å£å¤§å°å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ window_len ä¸ srateã€‚")
        # è®¡ç®—æ­¥é•¿ï¼ˆå’Œ BCILAB ä¸€è‡´ï¼šround(N*(1-overlap))ï¼‰
        step = int(round(N * (1 - window_overlap)))
        step = max(1, step)
        # ç”Ÿæˆçª—å£èµ·ç‚¹ï¼ˆå’Œ BCILAB ä¸€è‡´ï¼Œä¸Šé™ä¸º S-Nï¼‰
        offsets = np.arange(0, max(1, S - N + 1), step, dtype=int)
        if len(offsets) == 0:
            offsets = np.array([0], dtype=int)
        W = len(offsets)

        # æ¯é€šé“æ¯çª—å£ RMS: (C, W)
        rms = np.empty((C, W), dtype=float)
        for wi, st in enumerate(offsets):
            seg = calib[:, st:st + N]
            rms[:, wi] = np.sqrt(np.mean(seg * seg, axis=1) + 1e-12)

        # æ¯é€šé“åšç¨³å¥ Zï¼ˆç”¨ median/MAD è¿‘ä¼¼ flt_clean_windows çš„ç¨³å¥æ‹Ÿåˆï¼‰
        med = np.median(rms, axis=1, keepdims=True)
        mad = np.median(np.abs(rms - med), axis=1, keepdims=True) + 1e-12
        # å°† MAD è½¬æ¢ä¸ºç±»ä¼¼æ ‡å‡†å·®çš„å°ºåº¦ï¼ˆå¸¸ç”¨ 1.4826ï¼‰
        robust_std = 1.4826 * mad
        wz = (rms - med) / robust_std  # (C, W)

        # çª—å£å±‚é¢çš„â€œåé€šé“è®¡æ•°â€
        bad_low = wz < zthresholds[0]
        bad_high = wz > zthresholds[1]
        bad_any = np.logical_or(bad_low, bad_high)  # (C, W)
        bad_count = bad_any.sum(axis=0)             # (W,)

        # å…è®¸çš„åé€šé“æ•°ï¼ˆæ¯”ä¾‹ â†’ ç»å¯¹æ•°ï¼‰
        if 0 < max_bad_channels < 1:
            max_bad_abs = int(np.round(C * max_bad_channels))
        else:
            max_bad_abs = int(max_bad_channels)
        max_bad_abs = max(0, min(C - 1, max_bad_abs))  # ä¸å…è®¸ç­‰äºæˆ–è¶…è¿‡ C

        # éœ€è¦ç§»é™¤çš„çª—å£ï¼šåé€šé“æ•° > ä¸Šé™
        remove_mask = bad_count > max_bad_abs
        removed_windows = np.where(remove_mask)[0]
        kept_windows = np.where(~remove_mask)[0]

        # ç”Ÿæˆæ ·æœ¬æ©ç ï¼šç§»é™¤åçª—è¦†ç›–çš„æ ·æœ¬
        sample_mask = np.ones(S, dtype=bool)
        for wi in removed_windows:
            st = offsets[wi]
            sample_mask[st:st + N] = False

        # ä¿ç•™çª—çš„åˆ‡ç‰‡åˆ—è¡¨
        kept_slices = [slice(offsets[wi], offsets[wi] + N) for wi in kept_windows]

        # æ‹¼æ¥å‚è€ƒæ®µ
        ref = calib[:, sample_mask]

        #return ref, sample_mask, kept_slices
        return ref

class ChannelManager:
    def __init__(self, lsl_info):
        """
        ä» pylsl.StreamInfo æå–å¹¶ä¿å­˜æ‰€æœ‰æœ‰æ„ä¹‰çš„ä¿¡æ¯
        åŒ…æ‹¬å…¨å±€å±æ€§å’Œé€šé“ç»“æ„
        """
        # === å…¨å±€æµä¿¡æ¯ ===
        self.name = lsl_info.name()
        self.type = lsl_info.type()
        self.channel_count = lsl_info.channel_count()
        self.srate = int(lsl_info.nominal_srate())
        self.uid = lsl_info.uid()
        self.hostname = lsl_info.hostname()
        self.source_id = lsl_info.source_id()
        self.version = lsl_info.version()
        self.created_at = lsl_info.created_at()

        # === æ‰€æœ‰é€šé“ä¿¡æ¯ ===
        #è¿™ä¸ªç±»çš„å®ä¾‹ä¸­æœ‰ç€æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸€äº›éEEGï¼Œä½†æ˜¯å®ƒæœ‰æ‰€æœ‰é€šé“çš„ä¿¡æ¯ï¼Œåç»­è¿˜èƒ½ä½¿ç”¨ã€‚
        self.channels = []  # æ¯ä¸ªå…ƒç´ æ˜¯ dictï¼šlabel, index, type, unit

        ch = lsl_info.desc().child('channels').child('channel')
        index = 0
        while ch.name() == "channel":
            label = ch.child_value("label")
            ch_type = ch.child_value("type")
            unit = ch.child_value("unit")

            self.channels.append({
                "label": label,
                "index": index,
                "type": ch_type,
                "unit": unit
            })
            print(self.channels)

            ch = ch.next_sibling()
            index += 1

    # === é€šé“ç­›é€‰æ–¹æ³• ===
    def get_all_labels(self):
        return [ch["label"] for ch in self.channels]

    def get_all_indices(self):
        return [ch["index"] for ch in self.channels]

    def get_labels_by_type(self, desired_type="EEG"):
        return [ch["label"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_type(self, desired_type="EEG"):
        return [ch["index"] for ch in self.channels if ch["type"] == desired_type]

    def get_indices_by_labels(self, labels):
        label_set = set(labels)
        return [ch["index"] for ch in self.channels if ch["label"] in label_set]

    def get_labels_excluding_keywords(self, keywords):
        return [ch["label"] for ch in self.channels
                if not any(kw in ch["label"] for kw in keywords)]

    def get_indices_excluding_keywords(self, keywords):
        return [ch["index"] for ch in self.channels
                if not any(kw in ch["label"] for kw in keywords)]

    def get_labels_by_indices(self, indices):
        """
        æ ¹æ®ç´¢å¼•åˆ—è¡¨è·å–å¯¹åº”çš„é€šé“ååˆ—è¡¨
        """
        index_set = set(indices)
        return [ch["label"] for ch in self.channels if ch["index"] in index_set]

    # === ä¿¡æ¯æ‰“å°æ–¹æ³• ===
    def print_summary(self):
        print("=== Stream Info ===")
        print(f"Name      : {self.name}")
        print(f"Type      : {self.type}")
        print(f"Channels  : {self.channel_count}")
        print(f"Sampling  : {self.srate} Hz")
        print(f"UID       : {self.uid}")
        print(f"Hostname  : {self.hostname}")
        print(f"Source ID : {self.source_id}")
        print(f"Version   : {self.version}")
        print(f"Created   : {self.created_at}")
        print("\n=== Channel List ===")
        for ch in self.channels:
            print(f"[{ch['index']:02}] {ch['label']} | Type: {ch['type']} | Unit: {ch['unit']}")