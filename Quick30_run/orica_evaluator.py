import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import kurtosis
from scipy.signal import welch
import seaborn as sns

class ORICAEvaluator:
    """ORICAåˆ†ç¦»æ•ˆæœè¯„ä¼°å·¥å…·"""
    
    def __init__(self):
        self.evaluation_history = []
    
    def comprehensive_evaluation(self, sources, original_data, srate, ica_model):
        """ç»¼åˆè¯„ä¼°ORICAåˆ†ç¦»æ•ˆæœ"""
        
        # 1. ç»Ÿè®¡æŒ‡æ ‡è¯„ä¼°
        stats_eval = self._evaluate_statistical_metrics(sources)
        
        # 2. é¢‘è°±åˆ†æè¯„ä¼°
        spectral_eval = self._evaluate_spectral_quality(sources, srate)
        
        # 3. ä¼ªå½±è¯†åˆ«è¯„ä¼°
        artifact_eval = self._evaluate_artifact_separation(sources, srate)
        
        # 4. é‡æ„è´¨é‡è¯„ä¼°
        reconstruction_eval = self._evaluate_reconstruction_quality(sources, original_data, ica_model)
        
        # 5. ç»¼åˆè¯„åˆ†
        overall_score = self._calculate_overall_score(stats_eval, spectral_eval, artifact_eval, reconstruction_eval)
        
        # 6. ä¿å­˜è¯„ä¼°å†å²
        evaluation_result = {
            'stats': stats_eval,
            'spectral': spectral_eval,
            'artifact': artifact_eval,
            'reconstruction': reconstruction_eval,
            'overall_score': overall_score,
            'timestamp': np.datetime64('now')
        }
        self.evaluation_history.append(evaluation_result)
        
        return evaluation_result
    
    def _evaluate_statistical_metrics(self, sources):
        """è¯„ä¼°ç»Ÿè®¡æŒ‡æ ‡"""
        # å³°åº¦è¯„ä¼°
        kurtosis_values = kurtosis(sources, axis=1, fisher=False)
        avg_kurtosis = np.mean(np.abs(kurtosis_values))
        max_kurtosis = np.max(np.abs(kurtosis_values))
        
        # äº’ä¿¡æ¯è¯„ä¼°ï¼ˆä½¿ç”¨ç›¸å…³æ€§è¿‘ä¼¼ï¼‰
        n_components = sources.shape[0]
        correlations = []
        for i in range(n_components):
            for j in range(i+1, n_components):
                corr = np.corrcoef(sources[i], sources[j])[0, 1]
                correlations.append(abs(corr))
        
        avg_correlation = np.mean(correlations) if correlations else 0
        max_correlation = np.max(correlations) if correlations else 0
        
        return {
            'avg_kurtosis': avg_kurtosis,
            'max_kurtosis': max_kurtosis,
            'avg_correlation': avg_correlation,
            'max_correlation': max_correlation,
            'kurtosis_values': kurtosis_values
        }
    
    def _evaluate_spectral_quality(self, sources, srate):
        """è¯„ä¼°é¢‘è°±è´¨é‡"""
        spectral_ratios = []
        
        for i, source in enumerate(sources):
            # è®¡ç®—åŠŸç‡è°±å¯†åº¦
            freqs, psd = welch(source, fs=srate)
            
            # è®¡ç®—ä¸åŒé¢‘æ®µçš„åŠŸç‡æ¯”ä¾‹
            delta_power = np.sum(psd[(freqs >= 0.5) & (freqs <= 4)])
            theta_power = np.sum(psd[(freqs >= 4) & (freqs <= 8)])
            alpha_power = np.sum(psd[(freqs >= 8) & (freqs <= 13)])
            beta_power = np.sum(psd[(freqs >= 13) & (freqs <= 30)])
            gamma_power = np.sum(psd[(freqs >= 30) & (freqs <= 100)])
            
            total_power = np.sum(psd)
            
            spectral_ratios.append({
                'component': i,
                'delta_ratio': delta_power / total_power,
                'theta_ratio': theta_power / total_power,
                'alpha_ratio': alpha_power / total_power,
                'beta_ratio': beta_power / total_power,
                'gamma_ratio': gamma_power / total_power,
                'total_power': total_power
            })
        
        return {
            'spectral_ratios': spectral_ratios,
            'avg_alpha_ratio': np.mean([r['alpha_ratio'] for r in spectral_ratios]),
            'avg_beta_ratio': np.mean([r['beta_ratio'] for r in spectral_ratios])
        }
    
    def _evaluate_artifact_separation(self, sources, srate):
        """è¯„ä¼°ä¼ªå½±åˆ†ç¦»æ•ˆæœ"""
        artifact_scores = []
        
        for i, source in enumerate(sources):
            # è®¡ç®—çœ¨çœ¼ä¼ªå½±ç‰¹å¾
            fft_vals = np.abs(np.fft.rfft(source))
            freqs = np.fft.rfftfreq(source.shape[0], 1/srate)
            
            # ä½é¢‘åŠŸç‡æ¯”ä¾‹ï¼ˆçœ¨çœ¼ç‰¹å¾ï¼‰
            low_freq_power = np.sum(fft_vals[(freqs >= 0.1) & (freqs <= 4)])
            total_power = np.sum(fft_vals)
            low_freq_ratio = low_freq_power / total_power
            
            # é«˜é¢‘åŠŸç‡æ¯”ä¾‹ï¼ˆè‚Œç”µä¼ªå½±ç‰¹å¾ï¼‰
            high_freq_power = np.sum(fft_vals[freqs >= 50])
            high_freq_ratio = high_freq_power / total_power
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºä¼ªå½±
            is_artifact = low_freq_ratio > 0.15 or high_freq_ratio > 0.1
            
            artifact_scores.append({
                'component': i,
                'low_freq_ratio': low_freq_ratio,
                'high_freq_ratio': high_freq_ratio,
                'is_artifact': is_artifact,
                'artifact_type': 'blink' if low_freq_ratio > 0.15 else ('emg' if high_freq_ratio > 0.1 else 'brain')
            })
        
        artifact_count = sum(1 for score in artifact_scores if score['is_artifact'])
        brain_count = len(artifact_scores) - artifact_count
        
        return {
            'artifact_scores': artifact_scores,
            'artifact_count': artifact_count,
            'brain_count': brain_count,
            'artifact_ratio': artifact_count / len(artifact_scores)
        }
    
    def _evaluate_reconstruction_quality(self, sources, original_data, ica_model):
        """è¯„ä¼°é‡æ„è´¨é‡"""
        try:
            W = ica_model.get_W()
            A = np.linalg.pinv(W)
            reconstructed = A @ sources
            reconstruction_error = np.mean((original_data - reconstructed)**2)
            
            # è®¡ç®—ä¿¡å™ªæ¯”
            signal_power = np.mean(original_data**2)
            noise_power = np.mean((original_data - reconstructed)**2)
            snr = 10 * np.log10(signal_power / (noise_power + 1e-10))
            
        except Exception as e:
            reconstruction_error = float('inf')
            snr = float('-inf')
        
        return {
            'reconstruction_error': reconstruction_error,
            'snr_db': snr
        }
    
    def _calculate_overall_score(self, stats_eval, spectral_eval, artifact_eval, reconstruction_eval):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        # å³°åº¦å¾—åˆ† (0-1)
        kurtosis_score = min(stats_eval['avg_kurtosis'] / 5.0, 1.0)
        
        # ç‹¬ç«‹æ€§å¾—åˆ† (0-1)
        independence_score = max(0, 1 - stats_eval['avg_correlation'] / 0.1)
        
        # ä¼ªå½±åˆ†ç¦»å¾—åˆ† (0-1)
        artifact_score = 1 - artifact_eval['artifact_ratio']
        
        # é‡æ„è´¨é‡å¾—åˆ† (0-1)
        reconstruction_score = max(0, 1 - reconstruction_eval['reconstruction_error'] / 0.01)
        
        # ç»¼åˆè¯„åˆ†
        overall_score = (kurtosis_score * 0.3 + 
                        independence_score * 0.3 + 
                        artifact_score * 0.2 + 
                        reconstruction_score * 0.2)
        
        return overall_score
    
    def print_evaluation_report(self, evaluation_result):
        """æ‰“å°è¯„ä¼°æŠ¥å‘Š"""
        print("\n" + "="*50)
        print("ORICAåˆ†ç¦»æ•ˆæœè¯„ä¼°æŠ¥å‘Š")
        print("="*50)
        
        # ç»Ÿè®¡æŒ‡æ ‡
        stats = evaluation_result['stats']
        print(f"\nğŸ“Š ç»Ÿè®¡æŒ‡æ ‡:")
        print(f"  å¹³å‡å³°åº¦: {stats['avg_kurtosis']:.3f} (ç›®æ ‡: >3.0)")
        print(f"  æœ€å¤§å³°åº¦: {stats['max_kurtosis']:.3f}")
        print(f"  å¹³å‡ç›¸å…³æ€§: {stats['avg_correlation']:.3f} (ç›®æ ‡: <0.1)")
        print(f"  æœ€å¤§ç›¸å…³æ€§: {stats['max_correlation']:.3f}")
        
        # é¢‘è°±è´¨é‡
        spectral = evaluation_result['spectral']
        print(f"\nğŸ“ˆ é¢‘è°±è´¨é‡:")
        print(f"  å¹³å‡Î±æ³¢æ¯”ä¾‹: {spectral['avg_alpha_ratio']:.3f}")
        print(f"  å¹³å‡Î²æ³¢æ¯”ä¾‹: {spectral['avg_beta_ratio']:.3f}")
        
        # ä¼ªå½±åˆ†ç¦»
        artifact = evaluation_result['artifact']
        print(f"\nğŸ‘ï¸ ä¼ªå½±åˆ†ç¦»:")
        print(f"  ä¼ªå½±æˆåˆ†æ•°: {artifact['artifact_count']}")
        print(f"  è„‘ç”µæˆåˆ†æ•°: {artifact['brain_count']}")
        print(f"  ä¼ªå½±æ¯”ä¾‹: {artifact['artifact_ratio']:.2%}")
        
        # é‡æ„è´¨é‡
        recon = evaluation_result['reconstruction']
        print(f"\nğŸ”„ é‡æ„è´¨é‡:")
        print(f"  é‡æ„è¯¯å·®: {recon['reconstruction_error']:.6f} (ç›®æ ‡: <0.01)")
        print(f"  ä¿¡å™ªæ¯”: {recon['snr_db']:.2f} dB")
        
        # ç»¼åˆè¯„åˆ†
        overall = evaluation_result['overall_score']
        print(f"\nğŸ† ç»¼åˆè¯„åˆ†: {overall:.3f}")
        
        if overall > 0.8:
            print("âœ… åˆ†ç¦»è´¨é‡: ä¼˜ç§€")
        elif overall > 0.6:
            print("âœ… åˆ†ç¦»è´¨é‡: è‰¯å¥½")
        elif overall > 0.4:
            print("âš ï¸ åˆ†ç¦»è´¨é‡: ä¸€èˆ¬")
        else:
            print("âŒ åˆ†ç¦»è´¨é‡: éœ€è¦æ”¹è¿›")
        
        print("="*50)
    
    def plot_evaluation_summary(self, evaluation_result, save_path=None):
        """ç»˜åˆ¶è¯„ä¼°æ€»ç»“å›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. å³°åº¦åˆ†å¸ƒ
        stats = evaluation_result['stats']
        axes[0, 0].bar(range(len(stats['kurtosis_values'])), np.abs(stats['kurtosis_values'])
        axes[0, 0].set_title('Component Kurtosis Distribution')
        axes[0, 0].set_xlabel('Component')
        axes[0, 0].set_ylabel('|Kurtosis|')
        axes[0, 0].axhline(y=3, color='r', linestyle='--', label='Target (3.0)')
        axes[0, 0].legend()
        
        # 2. é¢‘è°±æ¯”ä¾‹
        spectral = evaluation_result['spectral']
        ratios = spectral['spectral_ratios']
        alpha_ratios = [r['alpha_ratio'] for r in ratios]
        beta_ratios = [r['beta_ratio'] for r in ratios]
        
        x = range(len(ratios))
        width = 0.35
        axes[0, 1].bar([i - width/2 for i in x], alpha_ratios, width, label='Alpha')
        axes[0, 1].bar([i + width/2 for i in x], beta_ratios, width, label='Beta')
        axes[0, 1].set_title('Spectral Power Ratios')
        axes[0, 1].set_xlabel('Component')
        axes[0, 1].set_ylabel('Power Ratio')
        axes[0, 1].legend()
        
        # 3. ä¼ªå½±åˆ†å¸ƒ
        artifact = evaluation_result['artifact']
        artifact_types = [score['artifact_type'] for score in artifact['artifact_scores']]
        type_counts = {'brain': 0, 'blink': 0, 'emg': 0}
        for t in artifact_types:
            type_counts[t] += 1
        
        axes[1, 0].pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%')
        axes[1, 0].set_title('Component Type Distribution')
        
        # 4. è¯„åˆ†é›·è¾¾å›¾
        categories = ['Kurtosis', 'Independence', 'Artifact Separation', 'Reconstruction']
        values = [
            min(stats['avg_kurtosis'] / 5.0, 1.0),
            max(0, 1 - stats['avg_correlation'] / 0.1),
            1 - artifact['artifact_ratio'],
            max(0, 1 - recon['reconstruction_error'] / 0.01)
        ]
        
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        values += values[:1]  # é—­åˆå›¾å½¢
        angles += angles[:1]
        
        axes[1, 1].plot(angles, values, 'o-', linewidth=2)
        axes[1, 1].fill(angles, values, alpha=0.25)
        axes[1, 1].set_xticks(angles[:-1])
        axes[1, 1].set_xticklabels(categories)
        axes[1, 1].set_ylim(0, 1)
        axes[1, 1].set_title('Quality Metrics Radar')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"è¯„ä¼°å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()
        
        plt.close() 