#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ORICAè¿ç»­ä¿å­˜åŠŸèƒ½çš„è„šæœ¬
"""

import os
import json
import csv
from datetime import datetime
import numpy as np

def test_continuous_saving():
    """æµ‹è¯•è¿ç»­ä¿å­˜åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ORICAè¿ç»­ä¿å­˜åŠŸèƒ½")
    
    # ç¡®ä¿Resultsç›®å½•å­˜åœ¨
    os.makedirs('./Results', exist_ok=True)
    
    # æµ‹è¯•æ•°æ®
    test_data = [
        {
            'timestamp': '2025-01-27T10:00:00',
            'kurtosis_mean': 3.5,
            'mi_mean': 0.03,
            'n_components': 25,
            'n_samples': 5000
        },
        {
            'timestamp': '2025-01-27T10:01:00',
            'kurtosis_mean': 3.8,
            'mi_mean': 0.02,
            'n_components': 25,
            'n_samples': 5000
        },
        {
            'timestamp': '2025-01-27T10:02:00',
            'kurtosis_mean': 4.1,
            'mi_mean': 0.01,
            'n_components': 25,
            'n_samples': 5000
        }
    ]
    
    # æµ‹è¯•JSONè¿½åŠ 
    json_filename = './Results/orica_evaluation_continuous.json'
    print(f"\nğŸ“ æµ‹è¯•JSONè¿½åŠ åˆ°: {json_filename}")
    
    for i, data in enumerate(test_data):
        print(f"  æ·»åŠ æ•°æ® {i+1}: kurtosis={data['kurtosis_mean']:.1f}, MI={data['mi_mean']:.2f}")
        
        # æ¨¡æ‹Ÿè¿½åŠ è¿‡ç¨‹
        if not os.path.exists(json_filename):
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump([data], f, ensure_ascii=False, indent=2)
        else:
            try:
                with open(json_filename, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except (json.JSONDecodeError, FileNotFoundError):
                existing_data = []
            
            if isinstance(existing_data, list):
                existing_data.append(data)
            else:
                existing_data = [existing_data, data]
            
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
    
    # æµ‹è¯•CSVè¿½åŠ 
    csv_filename = './Results/orica_evaluation_continuous.csv'
    print(f"\nğŸ“ æµ‹è¯•CSVè¿½åŠ åˆ°: {csv_filename}")
    
    for i, data in enumerate(test_data):
        print(f"  æ·»åŠ æ•°æ® {i+1}: kurtosis={data['kurtosis_mean']:.1f}, MI={data['mi_mean']:.2f}")
        
        if not os.path.exists(csv_filename):
            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=data.keys())
                writer.writeheader()
                writer.writerow(data)
        else:
            with open(csv_filename, 'a', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=data.keys())
                writer.writerow(data)
    
    # éªŒè¯ç»“æœ
    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ JSONæ–‡ä»¶: {json_filename}")
    print(f"ğŸ“ CSVæ–‡ä»¶: {csv_filename}")
    
    # æ˜¾ç¤ºJSONå†…å®¹
    if os.path.exists(json_filename):
        with open(json_filename, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        print(f"\nğŸ“Š JSONæ–‡ä»¶åŒ…å« {len(loaded_data)} æ¡è®°å½•")
        for i, item in enumerate(loaded_data):
            print(f"  è®°å½• {i+1}: {item['timestamp']} - kurtosis={item['kurtosis_mean']:.1f}, MI={item['mi_mean']:.2f}")
    
    # æ˜¾ç¤ºCSVå†…å®¹
    if os.path.exists(csv_filename):
        with open(csv_filename, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        print(f"\nğŸ“Š CSVæ–‡ä»¶åŒ…å« {len(lines)-1} æ¡è®°å½•ï¼ˆä¸åŒ…æ‹¬è¡¨å¤´ï¼‰")

if __name__ == "__main__":
    test_continuous_saving()


















































































